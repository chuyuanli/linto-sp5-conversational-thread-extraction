{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "\n",
    "I) version base\n",
    "- (done)  reprendre classifieur de chat hiérarchique, remplacer encodeur seq2vec par un seq2seq (stacked lstm eg)\n",
    "    cf HierarchicalChatSequenceClassification\n",
    "- (done)  ajouter séquence de labels / comme si arbre ou forêt (possible ds graph_parser ?)\n",
    "\n",
    "- sousclasser graph_parser / modifs\n",
    "    plus facile en forcant label unique sur les arcs ? à voir\n",
    "- brancher données réelles\n",
    "\n",
    "/home/muller/anaconda3/envs/allennlp/lib/python3.7/site-packages/allennlp/data/dataset_readers/semantic_dependency_parsing.py\n",
    "\n",
    "\n",
    "améliorations: \n",
    "- encodeur tour -> bert\n",
    "- graphe de labels -> AdjacencyMatrixField\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import logging\n",
    "from typing import Any, Tuple, Dict, List, Iterable\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
    "from allennlp.data.fields import Field, LabelField, TextField, ListField, SequenceLabelField\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token, Tokenizer, WordTokenizer, PretrainedTransformerTokenizer\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "\n",
    "from allennlp.modules import Seq2VecEncoder, Seq2SeqEncoder\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "\n",
    "from allennlp.training.trainer import Trainer\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.common import Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dummy_chat_reader import ChatReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 1033.08it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 20164.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance with fields:\n",
      " \t lines: ListField of 3 TextFields : \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[this, is, a, turn, in, a, chat]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 2 with text: \n",
      " \t\t[another, one]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[but, this, is, different]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \n",
      " \t label: AdjacencyField of length 3\n",
      "\t\twith indices:\n",
      " \t\t[(0, 2), (1, 2), (2, 2)]\n",
      "\n",
      "\t\tand labels:\n",
      " \t\tNone\n",
      " \t\tin namespace: 'labels'. \n",
      "\n",
      "{'num_fields': 3, 'list_num_tokens': 7, 'list_tokens_length': 7}\n",
      "Instance with fields:\n",
      " \t lines: ListField of 4 TextFields : \n",
      " \t TextField of length 3 with text: \n",
      " \t\t[another, chat, starts]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[is, it, different, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[well, a, little, bit]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[but, we, need, a, different, number, of, turns, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \n",
      " \t label: AdjacencyField of length 4\n",
      "\t\twith indices:\n",
      " \t\t[(0, 3), (1, 3), (2, 3), (3, 3)]\n",
      "\n",
      "\t\tand labels:\n",
      " \t\tNone\n",
      " \t\tin namespace: 'labels'. \n",
      "\n",
      "{'num_fields': 4, 'list_num_tokens': 9, 'list_tokens_length': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "token_indexers = {\"tokens\": SingleIdTokenIndexer()}\n",
    "\n",
    "tokenizer_cfg = Params({\"word_splitter\": {\"language\": \"en\"}})\n",
    "\n",
    "tokenizer = Tokenizer.from_params(tokenizer_cfg)\n",
    "\n",
    "\n",
    "reader = ChatReader(\n",
    "    tokenizer=tokenizer,\n",
    "    token_indexers=token_indexers,\n",
    "    )\n",
    "train_instances = reader.read(\"./train_dummy.tsv\")\n",
    "vocab = Vocabulary.from_instances(train_instances)\n",
    "\n",
    "\n",
    "for i in train_instances:\n",
    "    print(i)\n",
    "    i[\"lines\"].index(vocab)\n",
    "    i[\"label\"].index(vocab)\n",
    "    print(i[\"lines\"].get_padding_lengths())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance with fields:\n",
      " \t lines: ListField of 4 TextFields : \n",
      " \t TextField of length 3 with text: \n",
      " \t\t[another, chat, starts]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[is, it, different, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[well, a, little, bit]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[but, we, need, a, different, number, of, turns, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \n",
      " \t label: AdjacencyField of length 4\n",
      "\t\twith indices:\n",
      " \t\t[(0, 3), (1, 3), (2, 3), (3, 3)]\n",
      "\n",
      "\t\tand labels:\n",
      " \t\tNone\n",
      " \t\tin namespace: 'labels'. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muller/anaconda3/envs/allennlp/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "400000it [00:02, 161796.65it/s]\n"
     ]
    }
   ],
   "source": [
    "turn_encoder_cfg = Params({\"type\":\"gru\",'input_size': 100, 'hidden_size': 50, 'num_layers': 1,\n",
    "                  'dropout': 0.25, 'bidirectional': False\n",
    "})\n",
    "#can be changed dynamically encoder_cfg[\"type\"] = \"lstm\"\n",
    "# warning: if bidirectional, state output dimension is hidden_size x 2 -> model doesn't know that\n",
    "\n",
    "turn_encoder = Seq2VecEncoder.from_params(turn_encoder_cfg)\n",
    "turn_encoder.hidden_size = turn_encoder_cfg[\"hidden_size\"]\n",
    "\n",
    "\n",
    "chat_encoder_cfg = Params({\"type\":\"gru\",'input_size': 50, 'hidden_size': 50, 'num_layers': 1,\n",
    "                  'dropout': 0.25, 'bidirectional': False\n",
    "})\n",
    "chat_encoder = Seq2SeqEncoder.from_params(chat_encoder_cfg)\n",
    "chat_encoder.hidden_size = chat_encoder_cfg[\"hidden_size\"]\n",
    "\n",
    "\n",
    "\n",
    "glove_text_field_embedder = Embedding.from_params(vocab,Params({\"pretrained_file\": \"https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz\",\n",
    "                                                          \"embedding_dim\": 100,\n",
    "                                                          \"trainable\": False\n",
    "}))\n",
    "\n",
    "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "                            embedding_dim=100)\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchSeq2SeqWrapper(\n",
       "  (_module): GRU(50, 50, batch_first=True, dropout=0.25)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from biaffine parser, another config (not used)\n",
    "chat_encoder_cfg =  {\n",
    "            \"type\": \"stacked_bidirectional_lstm\",\n",
    "            \"hidden_size\": 400,\n",
    "            \"input_size\": 200,\n",
    "            \"num_layers\": 3,\n",
    "            \"recurrent_dropout_probability\": 0.3,\n",
    "            \"use_highway\": True\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models import Model\n",
    "from typing import Dict, List, Iterable\n",
    "from allennlp.modules import TimeDistributed\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models import Model\n",
    "from allennlp.common.checks import check_dimensions_match, ConfigurationError\n",
    "from allennlp.data import Vocabulary\n",
    "from allennlp.modules import Seq2SeqEncoder, TextFieldEmbedder, Embedding, InputVariationalDropout\n",
    "from allennlp.modules.matrix_attention.bilinear_matrix_attention import BilinearMatrixAttention\n",
    "from allennlp.modules import FeedForward\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.nn import InitializerApplicator, Activation\n",
    "#???? TODO from allennlp.nn.util import min_value_of_dtype -> only allennlp >= 1.0\n",
    "def min_value_of_dtype(dtype: torch.dtype):\n",
    "    \"\"\"\n",
    "    Returns the minimum value of a given PyTorch data type. Does not allow torch.bool.\n",
    "    \"\"\"\n",
    "    return info_value_of_dtype(dtype).min\n",
    "def info_value_of_dtype(dtype: torch.dtype):\n",
    "    \"\"\"\n",
    "    Returns the `finfo` or `iinfo` object of a given PyTorch data type. Does not allow torch.bool.\n",
    "    \"\"\"\n",
    "    if dtype == torch.bool:\n",
    "        raise TypeError(\"Does not support torch.bool\")\n",
    "    elif dtype.is_floating_point:\n",
    "        return torch.finfo(dtype)\n",
    "    else:\n",
    "        return torch.iinfo(dtype)\n",
    "\n",
    "\n",
    "from allennlp.nn.util import get_text_field_mask\n",
    "from allennlp.nn.util import get_lengths_from_binary_sequence_mask\n",
    "from allennlp.training.metrics import F1Measure\n",
    "\n",
    "import copy\n",
    "from overrides import overrides\n",
    "import torch\n",
    "from torch.nn.modules import Dropout\n",
    "import numpy\n",
    "\n",
    "class ChatGraphParser(Model):\n",
    "    \"\"\"\n",
    "    A Parser for arbitrary graph structures.\n",
    "\n",
    "    Registered as a `Model` with name \"graph_parser\".\n",
    "\n",
    "    # Parameters\n",
    "\n",
    "    vocab : `Vocabulary`, required\n",
    "        A Vocabulary, required in order to compute sizes for input/output projections.\n",
    "    text_field_embedder : `TextFieldEmbedder`, required\n",
    "        Used to embed the `tokens` `TextField` we get as input to the model.\n",
    "    encoder : `Seq2SeqEncoder`\n",
    "        The encoder (with its own internal stacking) that we will use to generate representations\n",
    "        of tokens.\n",
    "    tag_representation_dim : `int`, required.\n",
    "        The dimension of the MLPs used for arc tag prediction.\n",
    "    arc_representation_dim : `int`, required.\n",
    "        The dimension of the MLPs used for arc prediction.\n",
    "    tag_feedforward : `FeedForward`, optional, (default = None).\n",
    "        The feedforward network used to produce tag representations.\n",
    "        By default, a 1 layer feedforward network with an elu activation is used.\n",
    "    arc_feedforward : `FeedForward`, optional, (default = None).\n",
    "        The feedforward network used to produce arc representations.\n",
    "        By default, a 1 layer feedforward network with an elu activation is used.\n",
    "    pos_tag_embedding : `Embedding`, optional.\n",
    "        Used to embed the `pos_tags` `SequenceLabelField` we get as input to the model.\n",
    "    dropout : `float`, optional, (default = 0.0)\n",
    "        The variational dropout applied to the output of the encoder and MLP layers.\n",
    "    input_dropout : `float`, optional, (default = 0.0)\n",
    "        The dropout applied to the embedded text input.\n",
    "    edge_prediction_threshold : `int`, optional (default = 0.5)\n",
    "        The probability at which to consider a scored edge to be 'present'\n",
    "        in the decoded graph. Must be between 0 and 1.\n",
    "    initializer : `InitializerApplicator`, optional (default=`InitializerApplicator()`)\n",
    "        Used to initialize the model parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab: Vocabulary,\n",
    "        text_field_embedder: TextFieldEmbedder,\n",
    "        turn_encoder: Seq2VecEncoder, \n",
    "        chat_encoder: Seq2SeqEncoder,\n",
    "        arc_representation_dim: int,\n",
    "        arc_feedforward: FeedForward = None,\n",
    "        dropout: float = 0.0,\n",
    "        input_dropout: float = 0.0,\n",
    "        edge_prediction_threshold: float = 0.5,\n",
    "        initializer: InitializerApplicator = InitializerApplicator(),\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(vocab, **kwargs)\n",
    "        \n",
    "        self.text_field_embedder = text_field_embedder\n",
    "        self.turn_encoder = TimeDistributed(turn_encoder)\n",
    "        self.chat_encoder = chat_encoder\n",
    "        \n",
    "        self.edge_prediction_threshold = edge_prediction_threshold\n",
    "        if not 0 < edge_prediction_threshold < 1:\n",
    "            raise ConfigurationError(\n",
    "                f\"edge_prediction_threshold must be between \"\n",
    "                f\"0 and 1 (exclusive) but found {edge_prediction_threshold}.\"\n",
    "            )\n",
    "\n",
    "        encoder_dim = chat_encoder.get_output_dim()\n",
    "\n",
    "        self.head_arc_feedforward = arc_feedforward or FeedForward(\n",
    "            encoder_dim, 1, arc_representation_dim, Activation.by_name(\"elu\")()\n",
    "        )\n",
    "        self.child_arc_feedforward = copy.deepcopy(self.head_arc_feedforward)\n",
    "\n",
    "        self.arc_attention = BilinearMatrixAttention(\n",
    "            arc_representation_dim, arc_representation_dim, use_input_biases=True\n",
    "        )\n",
    "\n",
    "        self._dropout = InputVariationalDropout(dropout)\n",
    "        self._input_dropout = Dropout(input_dropout)\n",
    "\n",
    "        representation_dim = turn_encoder.get_output_dim()\n",
    "\n",
    "        self._unlabelled_f1 = F1Measure(positive_label=1)\n",
    "        self._arc_loss = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "        initializer(self)\n",
    "        # useful for debugging\n",
    "        self.iter_count = 0 \n",
    "        \n",
    "    # init done\n",
    "        \n",
    "    # todo \n",
    "    @overrides\n",
    "    def forward(\n",
    "        self,  # type: ignore\n",
    "        lines,\n",
    "        label: torch.LongTensor = None,\n",
    "        metadata: List[Dict[str, Any]] = None,\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "\n",
    "        \"\"\"\n",
    "        # Parameters\n",
    "\n",
    "        lines: the chat as a list of turns, each being a list of token\n",
    "        TODO: add metadata to instances\n",
    "        metadata : List[Dict[str, Any]], optional (default = None)\n",
    "            A dictionary of metadata for each batch element which has keys:\n",
    "                tokens : `List[str]`, required.\n",
    "                    The original string tokens in the sentence.\n",
    "        label : a tensor containing the adjacency matrix for the instance dependencies between turns\n",
    "            Has shape `(batch_size, sequence_length, sequence_length)`.\n",
    "\n",
    "        # Returns\n",
    "\n",
    "        An output dictionary.\n",
    "        \"\"\"\n",
    "        #########\n",
    "        # this is the part where chat is encoded as sequence of turn encodings\n",
    "        #########\n",
    "        # mask for each turn of each chat of the batch: shape = (batch_size x max_turns x tokens)\n",
    "        token_mask = get_text_field_mask(lines,num_wrapping_dims=1)\n",
    "\n",
    "        # chat turns fetching embedding\n",
    "        # turns_embedding tensor is (batch_size x turns x max tokens x token embedding size)\n",
    "        turns_embeddings = self.text_field_embedder(lines,num_wrapping_dims=1)\n",
    "      \n",
    "        # encoding turns\n",
    "        # turn_h has shape (batch_size x turns x encoder_output_size) \n",
    "        turn_h = self.turn_encoder(turns_embeddings,token_mask)\n",
    "        \n",
    "        # mask for chats is now nb of turns; beware weird return type of torch.max (tuple) \n",
    "        chat_mask = token_mask.max(axis=2)[0]\n",
    "        \n",
    "        # renaming to mask -> easier to transpose the rest of graph_parser\n",
    "        mask = chat_mask\n",
    "        \n",
    "        # graph parser goes on\n",
    "        # leave input dropout for now\n",
    "        # embedded_text_input = turn_h equivalent in hierarchical sequence -> renaming \n",
    "        #embedded_text_input = self._input_dropout(embedded_text_input)\n",
    "        embedded_text_input = turn_h\n",
    "        # we keep graph parser original name for now\n",
    "        # encoded_text = encoded chat = self.chat_encoder(turn_h,chat_mask) equivalent in hierarchical sequence\n",
    "        encoded_text = self.chat_encoder(embedded_text_input, mask)\n",
    "\n",
    "        encoded_text = self._dropout(encoded_text)\n",
    "\n",
    "        # shape (batch_size, sequence_length, arc_representation_dim)\n",
    "        head_arc_representation = self._dropout(self.head_arc_feedforward(encoded_text))\n",
    "        child_arc_representation = self._dropout(self.child_arc_feedforward(encoded_text))\n",
    "\n",
    "        # shape (batch_size, sequence_length, tag_representation_dim)\n",
    "        #head_tag_representation = self._dropout(self.head_tag_feedforward(encoded_text))\n",
    "        #child_tag_representation = self._dropout(self.child_tag_feedforward(encoded_text))\n",
    "        \n",
    "        # shape (batch_size, sequence_length, sequence_length)\n",
    "        arc_scores = self.arc_attention(head_arc_representation, child_arc_representation)\n",
    "        \n",
    "        # shape (batch_size, num_tags, sequence_length, sequence_length)\n",
    "        #arc_tag_logits = self.tag_bilinear(head_tag_representation, child_tag_representation)\n",
    "        # Switch to (batch_size, sequence_length, sequence_length, num_tags)\n",
    "        #arc_tag_logits = arc_tag_logits.permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "        # Since we'll be doing some additions, using the min value will cause underflow\n",
    "        # CHAT: unncessary since we dont have a loss for labels\n",
    "        #minus_mask = ~mask * min_value_of_dtype(arc_scores.dtype) / 10\n",
    "        #arc_scores = arc_scores + minus_mask.unsqueeze(2) + minus_mask.unsqueeze(1)\n",
    "\n",
    "        \n",
    "        #breakpoint()\n",
    "        arc_probs = self._greedy_decode(arc_scores, mask)\n",
    "\n",
    "        output_dict = {\"arc_probs\": arc_probs, \"mask\": mask}\n",
    "\n",
    "        if metadata:\n",
    "            output_dict[\"tokens\"] = [meta[\"tokens\"] for meta in metadata]\n",
    "\n",
    "        arc_tags = label # gold labels -> here just the adjacency matrix 0/1 ? \n",
    "        if arc_tags is not None:\n",
    "            arc_nll= self._construct_loss(\n",
    "                arc_scores=arc_scores, arc_tags=arc_tags, mask=mask\n",
    "            )\n",
    "            # same here with no arc relations ; keep all anyway to prevent ubgs downstream (TODO: coherent renaming)\n",
    "            output_dict[\"loss\"] = arc_nll \n",
    "            output_dict[\"arc_loss\"] = arc_nll\n",
    "        \n",
    "\n",
    "            # Make the arc tags not have negative values anywhere\n",
    "            # (by default, no edge is indicated with -1).\n",
    "            # NB re chat: probably not useful, but kept as a precaution\n",
    "            arc_indices = (arc_tags != -1).float()\n",
    "            tag_mask = mask.unsqueeze(1) & mask.unsqueeze(2)\n",
    "            one_minus_arc_probs = 1 - arc_probs\n",
    "            # We stack scores here because the f1 measure expects a\n",
    "            # distribution, rather than a single value.\n",
    "            self._unlabelled_f1(\n",
    "                torch.stack([one_minus_arc_probs, arc_probs], -1), arc_indices, tag_mask\n",
    "            )\n",
    "        self.iter_count += 1\n",
    "        if False and self.get_metrics()[\"f1\"]>=0.6:\n",
    "            breakpoint()\n",
    "        return output_dict\n",
    "    # modified / untested\n",
    "    \n",
    "    def _construct_loss(\n",
    "        self,\n",
    "        arc_scores: torch.Tensor,\n",
    "        arc_tags: torch.Tensor,\n",
    "        mask: torch.BoolTensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Computes the arc and tag loss for an adjacency matrix.\n",
    "\n",
    "        # Parameters\n",
    "\n",
    "        arc_scores : `torch.Tensor`, required.\n",
    "            A tensor of shape (batch_size, sequence_length, sequence_length) used to generate a\n",
    "            binary classification decision for whether an edge is present between two words.\n",
    "        #####arc_tag_logits : `torch.Tensor`, required.\n",
    "        #####    A tensor of shape (batch_size, sequence_length, sequence_length, num_tags) used to generate\n",
    "        #####    a distribution over edge tags for a given edge.\n",
    "        arc_tags : `torch.Tensor`, required.\n",
    "            A tensor of shape (batch_size, sequence_length, sequence_length).\n",
    "            The labels for every arc.\n",
    "        mask : `torch.BoolTensor`, required.\n",
    "            A mask of shape (batch_size, sequence_length), denoting unpadded\n",
    "            elements in the sequence.\n",
    "\n",
    "        # Returns\n",
    "\n",
    "        arc_nll : `torch.Tensor`, required.\n",
    "            The negative log likelihood from the arc loss.\n",
    "        tag_nll : `torch.Tensor`, required.\n",
    "            The negative log likelihood from the arc tag loss.\n",
    "        \"\"\"\n",
    "        arc_indices = (arc_tags != -1).float()\n",
    "        # Make the arc tags not have negative values anywhere\n",
    "        # (by default, no edge is indicated with -1).\n",
    "        arc_tags = arc_tags * arc_indices\n",
    "        arc_nll = self._arc_loss(arc_scores, arc_indices) * mask.unsqueeze(1) * mask.unsqueeze(2)\n",
    "        # We want the mask for the tags to only include the unmasked words\n",
    "        # and we only care about the loss with respect to the gold arcs.\n",
    "        tag_mask = mask.unsqueeze(1) * mask.unsqueeze(2) * arc_indices\n",
    "\n",
    "        #batch_size, sequence_length, _, num_tags = arc_tag_logits.size()\n",
    "        #original_shape = [batch_size, sequence_length, sequence_length]\n",
    "        #reshaped_logits = arc_tag_logits.view(-1, num_tags)\n",
    "        reshaped_tags = arc_tags.view(-1)\n",
    "        #tag_nll = (\n",
    "        #    self._tag_loss(reshaped_logits, reshaped_tags.long()).view(original_shape) * tag_mask\n",
    "        #)\n",
    "\n",
    "        valid_positions = tag_mask.sum()\n",
    "\n",
    "        arc_nll = arc_nll.sum() / valid_positions.float()\n",
    "        #tag_nll = tag_nll.sum() / valid_positions.float()\n",
    "        return arc_nll#, tag_nll\n",
    "    # modified/untested\n",
    "\n",
    "    @staticmethod\n",
    "    def _greedy_decode(\n",
    "        arc_scores: torch.Tensor, mask: torch.BoolTensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Decodes the head and head tag predictions by decoding the unlabeled arcs\n",
    "        independently for each word and then again, predicting the head tags of\n",
    "        these greedily chosen arcs independently.\n",
    "\n",
    "        # Parameters\n",
    "\n",
    "        arc_scores : `torch.Tensor`, required.\n",
    "            A tensor of shape (batch_size, sequence_length, sequence_length) used to generate\n",
    "            a distribution over attachments of a given word to all other words.\n",
    "        ###arc_tag_logits : `torch.Tensor`, required.\n",
    "        ###    A tensor of shape (batch_size, sequence_length, sequence_length, num_tags) used to\n",
    "        ###    generate a distribution over tags for each arc.\n",
    "        mask : `torch.BoolTensor`, required.\n",
    "            A mask of shape (batch_size, sequence_length).\n",
    "\n",
    "        # Returns\n",
    "\n",
    "        arc_probs : `torch.Tensor`\n",
    "            A tensor of shape (batch_size, sequence_length, sequence_length) representing the\n",
    "            probability of an arc being present for this edge.\n",
    "        ####arc_tag_probs : `torch.Tensor`\n",
    "        ####    A tensor of shape (batch_size, sequence_length, sequence_length, sequence_length)\n",
    "        ####    representing the distribution over edge tags for a given edge.\n",
    "        \"\"\"\n",
    "        # Mask the diagonal, because we don't self edges.\n",
    "        # WARNING: might not be the case for chats ? \n",
    "        inf_diagonal_mask = torch.diag(arc_scores.new(mask.size(1)).fill_(-numpy.inf))\n",
    "        arc_scores = arc_scores + inf_diagonal_mask\n",
    "        # shape (batch_size, sequence_length, sequence_length, num_tags)\n",
    "        #arc_tag_logits = arc_tag_logits + inf_diagonal_mask.unsqueeze(0).unsqueeze(-1)\n",
    "        # Mask padded tokens, because we only want to consider actual word -> word edges.\n",
    "        # CHAT: this is the wrong torch version lol this does not work/ confusion int/bools\n",
    "        # minus_mask = ~mask.unsqueeze(2)\n",
    "        # CHAT: this should work with torch>1.4\n",
    "        minus_mask = (mask<1).unsqueeze(2)\n",
    "        \n",
    "        arc_scores.masked_fill_(minus_mask, -numpy.inf)\n",
    "        # but shouldn'it mask both padded lines/columns ? just does lines\n",
    "        \n",
    "        #arc_tag_logits.masked_fill_(minus_mask.unsqueeze(-1), -numpy.inf)\n",
    "        # shape (batch_size, sequence_length, sequence_length)\n",
    "        arc_probs = arc_scores.sigmoid()\n",
    "        # shape (batch_size, sequence_length, sequence_length, num_tags)\n",
    "        #arc_tag_probs = torch.nn.functional.softmax(arc_tag_logits, dim=-1)\n",
    "        return arc_probs#, arc_tag_probs\n",
    "    # modified / untested\n",
    "    \n",
    "    @overrides\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        metrics = {}\n",
    "        precision, recall, f1_measure = self._unlabelled_f1.get_metric(reset)\n",
    "        metrics[\"precision\"] = precision\n",
    "        metrics[\"recall\"] = recall\n",
    "        metrics[\"f1\"] = f1_measure\n",
    "        return metrics\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 1406.30it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 21509.25it/s]\n"
     ]
    }
   ],
   "source": [
    "#model = HierarchicalChatSequenceClassification(vocab,word_embeddings,turn_encoder,chat_encoder)\n",
    "\n",
    "\n",
    "\n",
    "train_instances = reader.read(\"./train_dummy.tsv\")\n",
    "vocab = Vocabulary.from_instances(train_instances)\n",
    "\n",
    "\n",
    "arc_representation_dim = 50 \n",
    "model = ChatGraphParser(vocab,word_embeddings,\n",
    "                        turn_encoder,chat_encoder,arc_representation_dim,\n",
    "                       edge_prediction_threshold=0.5)\n",
    "\n",
    "\n",
    "from allennlp.training.optimizers import Optimizer \n",
    "trainer_cfg = {\n",
    "        \"cuda_device\": -1,\n",
    "        \"grad_norm\": 5,\n",
    "        \"num_epochs\": 100,\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"dense_sparse_adam\",\n",
    "            \"betas\": [\n",
    "                0.9,\n",
    "                0.9\n",
    "            ]\n",
    "        },\n",
    "        \"patience\": 50,\n",
    "}\n",
    "\n",
    "\n",
    "opt_cfg = trainer_cfg.pop(\"optimizer\")\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "#does not work cos needs model parameters too\n",
    "#optimizer = Optimizer.from_params(opt_cfg)\n",
    "\n",
    "iterator = BucketIterator(batch_size=2,sorting_keys=[(\"lines\",\"list_num_tokens\")])\n",
    "iterator.index_with(vocab)\n",
    "trainer = Trainer(model=model,\n",
    "                  optimizer=optimizer,\n",
    "                  iterator=iterator,\n",
    "                  num_epochs=500,\n",
    "                  patience=20,\n",
    "                  train_dataset=train_instances,\n",
    "                  should_log_parameter_statistics = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision: 0.0000, recall: 0.0000, f1: 0.0000, loss: 2.3443 ||: 100%|██████████| 1/1 [00:00<00:00, 117.74it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.5348 ||: 100%|██████████| 1/1 [00:00<00:00, 86.81it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0375 ||: 100%|██████████| 1/1 [00:00<00:00, 98.01it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0216 ||: 100%|██████████| 1/1 [00:00<00:00, 85.31it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0157 ||: 100%|██████████| 1/1 [00:00<00:00, 94.60it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0125 ||: 100%|██████████| 1/1 [00:00<00:00, 79.61it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0104 ||: 100%|██████████| 1/1 [00:00<00:00, 92.46it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0090 ||: 100%|██████████| 1/1 [00:00<00:00, 76.52it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0079 ||: 100%|██████████| 1/1 [00:00<00:00, 122.94it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0071 ||: 100%|██████████| 1/1 [00:00<00:00, 109.57it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0064 ||: 100%|██████████| 1/1 [00:00<00:00, 126.80it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0059 ||: 100%|██████████| 1/1 [00:00<00:00, 128.16it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0054 ||: 100%|██████████| 1/1 [00:00<00:00, 89.15it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0050 ||: 100%|██████████| 1/1 [00:00<00:00, 93.62it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0047 ||: 100%|██████████| 1/1 [00:00<00:00, 108.67it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0044 ||: 100%|██████████| 1/1 [00:00<00:00, 85.79it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0042 ||: 100%|██████████| 1/1 [00:00<00:00, 103.62it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0040 ||: 100%|██████████| 1/1 [00:00<00:00, 98.00it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0038 ||: 100%|██████████| 1/1 [00:00<00:00, 89.30it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0036 ||: 100%|██████████| 1/1 [00:00<00:00, 87.37it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0034 ||: 100%|██████████| 1/1 [00:00<00:00, 76.89it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0033 ||: 100%|██████████| 1/1 [00:00<00:00, 85.56it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0031 ||: 100%|██████████| 1/1 [00:00<00:00, 83.97it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0030 ||: 100%|██████████| 1/1 [00:00<00:00, 76.05it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0029 ||: 100%|██████████| 1/1 [00:00<00:00, 80.63it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0028 ||: 100%|██████████| 1/1 [00:00<00:00, 107.98it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0027 ||: 100%|██████████| 1/1 [00:00<00:00, 111.52it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0026 ||: 100%|██████████| 1/1 [00:00<00:00, 102.84it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0025 ||: 100%|██████████| 1/1 [00:00<00:00, 87.51it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0024 ||: 100%|██████████| 1/1 [00:00<00:00, 89.15it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0024 ||: 100%|██████████| 1/1 [00:00<00:00, 83.54it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0023 ||: 100%|██████████| 1/1 [00:00<00:00, 122.09it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0022 ||: 100%|██████████| 1/1 [00:00<00:00, 104.50it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0022 ||: 100%|██████████| 1/1 [00:00<00:00, 90.76it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0021 ||: 100%|██████████| 1/1 [00:00<00:00, 97.74it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0020 ||: 100%|██████████| 1/1 [00:00<00:00, 95.99it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0020 ||: 100%|██████████| 1/1 [00:00<00:00, 107.09it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0019 ||: 100%|██████████| 1/1 [00:00<00:00, 89.24it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0019 ||: 100%|██████████| 1/1 [00:00<00:00, 97.07it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0018 ||: 100%|██████████| 1/1 [00:00<00:00, 101.96it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0018 ||: 100%|██████████| 1/1 [00:00<00:00, 99.93it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0018 ||: 100%|██████████| 1/1 [00:00<00:00, 99.74it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0017 ||: 100%|██████████| 1/1 [00:00<00:00, 95.72it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0017 ||: 100%|██████████| 1/1 [00:00<00:00, 125.89it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0016 ||: 100%|██████████| 1/1 [00:00<00:00, 110.72it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0016 ||: 100%|██████████| 1/1 [00:00<00:00, 95.31it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0016 ||: 100%|██████████| 1/1 [00:00<00:00, 100.07it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0015 ||: 100%|██████████| 1/1 [00:00<00:00, 114.07it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0015 ||: 100%|██████████| 1/1 [00:00<00:00, 98.00it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0015 ||: 100%|██████████| 1/1 [00:00<00:00, 115.41it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0015 ||: 100%|██████████| 1/1 [00:00<00:00, 86.75it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0014 ||: 100%|██████████| 1/1 [00:00<00:00, 97.94it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0014 ||: 100%|██████████| 1/1 [00:00<00:00, 102.13it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0014 ||: 100%|██████████| 1/1 [00:00<00:00, 99.03it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0014 ||: 100%|██████████| 1/1 [00:00<00:00, 116.40it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0013 ||: 100%|██████████| 1/1 [00:00<00:00, 91.20it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0013 ||: 100%|██████████| 1/1 [00:00<00:00, 97.06it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0013 ||: 100%|██████████| 1/1 [00:00<00:00, 102.96it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0013 ||: 100%|██████████| 1/1 [00:00<00:00, 100.45it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0012 ||: 100%|██████████| 1/1 [00:00<00:00, 117.76it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0012 ||: 100%|██████████| 1/1 [00:00<00:00, 112.20it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0012 ||: 100%|██████████| 1/1 [00:00<00:00, 102.89it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0012 ||: 100%|██████████| 1/1 [00:00<00:00, 96.69it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0012 ||: 100%|██████████| 1/1 [00:00<00:00, 117.09it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0012 ||: 100%|██████████| 1/1 [00:00<00:00, 116.43it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0011 ||: 100%|██████████| 1/1 [00:00<00:00, 88.52it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0011 ||: 100%|██████████| 1/1 [00:00<00:00, 98.10it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0011 ||: 100%|██████████| 1/1 [00:00<00:00, 91.80it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0011 ||: 100%|██████████| 1/1 [00:00<00:00, 101.27it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0011 ||: 100%|██████████| 1/1 [00:00<00:00, 91.89it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0011 ||: 100%|██████████| 1/1 [00:00<00:00, 104.07it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0010 ||: 100%|██████████| 1/1 [00:00<00:00, 91.80it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0010 ||: 100%|██████████| 1/1 [00:00<00:00, 78.18it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0010 ||: 100%|██████████| 1/1 [00:00<00:00, 84.77it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0010 ||: 100%|██████████| 1/1 [00:00<00:00, 107.49it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0010 ||: 100%|██████████| 1/1 [00:00<00:00, 110.29it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0010 ||: 100%|██████████| 1/1 [00:00<00:00, 117.96it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0010 ||: 100%|██████████| 1/1 [00:00<00:00, 126.17it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0009 ||: 100%|██████████| 1/1 [00:00<00:00, 104.48it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0009 ||: 100%|██████████| 1/1 [00:00<00:00, 112.08it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0009 ||: 100%|██████████| 1/1 [00:00<00:00, 112.51it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0009 ||: 100%|██████████| 1/1 [00:00<00:00, 93.81it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0009 ||: 100%|██████████| 1/1 [00:00<00:00, 102.84it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0009 ||: 100%|██████████| 1/1 [00:00<00:00, 92.93it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0009 ||: 100%|██████████| 1/1 [00:00<00:00, 103.32it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0009 ||: 100%|██████████| 1/1 [00:00<00:00, 85.27it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0009 ||: 100%|██████████| 1/1 [00:00<00:00, 96.86it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0008 ||: 100%|██████████| 1/1 [00:00<00:00, 92.27it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0008 ||: 100%|██████████| 1/1 [00:00<00:00, 112.49it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0008 ||: 100%|██████████| 1/1 [00:00<00:00, 91.43it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0008 ||: 100%|██████████| 1/1 [00:00<00:00, 79.81it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0008 ||: 100%|██████████| 1/1 [00:00<00:00, 109.23it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0008 ||: 100%|██████████| 1/1 [00:00<00:00, 106.57it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0008 ||: 100%|██████████| 1/1 [00:00<00:00, 92.84it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0008 ||: 100%|██████████| 1/1 [00:00<00:00, 75.15it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0008 ||: 100%|██████████| 1/1 [00:00<00:00, 107.85it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0008 ||: 100%|██████████| 1/1 [00:00<00:00, 87.27it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0008 ||: 100%|██████████| 1/1 [00:00<00:00, 86.84it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0008 ||: 100%|██████████| 1/1 [00:00<00:00, 85.26it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0007 ||: 100%|██████████| 1/1 [00:00<00:00, 86.17it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0007 ||: 100%|██████████| 1/1 [00:00<00:00, 89.04it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0007 ||: 100%|██████████| 1/1 [00:00<00:00, 95.38it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0007 ||: 100%|██████████| 1/1 [00:00<00:00, 102.98it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0007 ||: 100%|██████████| 1/1 [00:00<00:00, 93.60it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0007 ||: 100%|██████████| 1/1 [00:00<00:00, 86.85it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0007 ||: 100%|██████████| 1/1 [00:00<00:00, 89.58it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0007 ||: 100%|██████████| 1/1 [00:00<00:00, 78.72it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0007 ||: 100%|██████████| 1/1 [00:00<00:00, 98.07it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0007 ||: 100%|██████████| 1/1 [00:00<00:00, 100.55it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0007 ||: 100%|██████████| 1/1 [00:00<00:00, 82.69it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0007 ||: 100%|██████████| 1/1 [00:00<00:00, 98.72it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0007 ||: 100%|██████████| 1/1 [00:00<00:00, 83.45it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0007 ||: 100%|██████████| 1/1 [00:00<00:00, 108.75it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 91.47it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 94.84it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 78.79it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 101.39it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 86.54it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 96.02it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 86.51it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 92.54it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 98.93it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 89.02it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 109.89it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 95.58it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 101.11it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 92.48it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 97.50it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 87.00it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 108.96it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 88.02it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 92.02it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0006 ||: 100%|██████████| 1/1 [00:00<00:00, 82.46it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 94.09it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 97.71it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 86.59it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 99.51it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 96.12it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 83.27it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 96.32it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 96.01it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 101.46it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 107.01it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 90.94it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 126.89it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 88.28it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 106.77it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 89.77it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 103.19it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 110.01it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 102.41it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 92.29it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 106.56it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 77.90it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 100.09it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 111.09it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 108.21it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 109.81it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 78.47it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0005 ||: 100%|██████████| 1/1 [00:00<00:00, 70.84it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 102.80it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 84.61it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 77.07it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 82.56it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 95.48it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 87.03it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 88.95it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 88.59it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 113.48it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 107.92it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 92.58it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 99.86it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 96.32it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 120.14it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 84.45it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 107.50it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 103.79it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 81.32it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 111.02it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 94.37it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 106.46it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 78.54it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 107.88it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 108.92it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 106.77it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 93.21it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 106.73it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 110.97it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 96.93it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 126.75it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 102.77it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 104.45it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 73.87it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 107.01it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 92.95it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 106.54it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 89.58it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 93.75it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 101.80it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 90.34it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 92.83it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 87.26it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0004 ||: 100%|██████████| 1/1 [00:00<00:00, 87.44it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 103.01it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 110.10it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 108.78it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 104.44it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 96.49it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 100.24it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 94.28it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 109.17it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 93.44it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 81.29it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 111.82it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 97.85it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 101.47it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 91.51it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 102.48it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 103.33it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 86.96it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 109.90it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 96.36it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 115.42it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 97.25it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 104.29it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 93.99it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 94.03it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 92.08it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 91.81it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 87.11it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 98.17it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 103.58it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 108.41it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 98.06it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 96.02it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 73.99it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 112.86it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 107.85it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 111.03it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 90.04it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 88.49it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 86.59it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 107.96it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 91.48it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 109.84it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 100.64it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 98.00it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 95.60it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 99.42it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 107.52it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 94.82it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 102.55it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 104.05it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 107.99it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 110.90it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 112.24it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 96.71it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 101.17it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 100.05it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 95.98it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 114.04it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 109.18it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 91.30it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 109.62it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 103.62it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 91.61it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 109.25it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 83.97it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 98.51it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 110.75it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 96.81it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 113.79it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 88.02it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 99.00it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0003 ||: 100%|██████████| 1/1 [00:00<00:00, 91.59it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 93.10it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 91.60it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 94.14it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 97.16it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 109.70it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 84.46it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 105.58it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 107.98it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 103.69it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 98.12it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 118.71it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 96.79it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 125.04it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 122.79it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 97.13it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 97.76it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 107.39it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 98.96it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 102.57it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 105.71it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 96.80it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 106.84it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 97.48it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 92.64it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 107.92it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 76.56it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 98.32it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 96.81it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 103.33it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 106.67it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 92.26it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 92.96it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 87.34it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 105.81it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 98.99it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 83.27it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 103.65it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 100.35it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 83.23it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 99.24it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 109.56it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 118.24it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 69.54it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 115.13it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 112.50it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 89.76it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 111.97it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 85.47it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 88.40it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 76.84it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 96.61it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 92.11it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 109.31it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 89.50it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 82.76it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 88.61it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 93.04it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 104.12it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 96.49it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 87.87it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 105.44it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 113.96it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 84.40it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 102.10it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 94.18it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 77.30it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 84.54it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 81.87it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 85.96it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 91.38it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 93.37it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 82.86it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 86.24it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 96.09it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 100.48it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 97.67it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 121.58it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 100.12it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 95.42it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 93.29it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 99.56it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 102.59it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 98.16it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 99.70it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 103.17it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 94.84it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 93.51it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 65.63it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 76.50it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 80.89it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 85.56it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 110.02it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 100.38it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 114.45it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 100.11it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 101.45it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 103.99it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 86.94it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 104.47it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 92.71it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 92.61it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 95.42it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 78.67it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 111.04it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 85.08it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 77.86it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 99.71it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 108.96it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 101.87it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 111.19it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 106.76it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 102.26it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 89.82it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 94.91it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 106.08it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 95.81it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 112.28it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 99.60it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 106.59it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 113.26it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 90.06it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 91.60it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 91.54it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 112.79it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 108.45it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 110.30it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 93.55it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 93.83it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 77.32it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 98.93it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 93.72it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 90.28it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 118.73it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 98.26it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 87.83it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 91.16it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 80.34it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 90.66it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 94.18it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 91.08it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 112.05it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 117.27it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 85.17it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 97.73it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 83.41it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 100.07it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 102.17it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 92.84it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 97.73it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 101.86it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 98.73it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 93.49it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 95.27it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 104.81it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 92.26it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 102.58it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 107.20it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 101.54it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 85.06it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 81.72it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0002 ||: 100%|██████████| 1/1 [00:00<00:00, 92.34it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 87.32it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 89.38it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 87.12it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 76.98it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 92.60it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 77.33it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 105.46it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 85.73it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 102.85it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 96.02it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 117.06it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 94.30it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 96.15it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 95.90it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 97.97it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 90.00it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 97.20it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 79.08it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 88.79it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 84.04it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 79.95it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 77.49it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 85.80it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 90.92it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 87.55it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 82.96it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 98.76it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 110.72it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 128.66it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 90.55it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 96.52it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 91.87it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 89.91it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 92.24it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 98.87it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 101.30it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 105.67it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 100.52it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 95.61it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 83.73it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 89.02it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 87.08it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 107.10it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 114.22it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 100.88it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 76.69it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 97.69it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 81.00it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 106.00it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 82.72it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 86.76it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 118.07it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 97.73it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 92.34it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 77.84it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 83.54it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 86.43it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 86.97it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 118.97it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 95.58it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 88.61it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 93.96it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 100.58it/s]\n",
      "precision: 1.0000, recall: 0.7143, f1: 0.8333, loss: 0.0001 ||: 100%|██████████| 1/1 [00:00<00:00, 83.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 499,\n",
       " 'peak_cpu_memory_MB': 334.824,\n",
       " 'peak_gpu_0_memory_MB': 960,\n",
       " 'training_duration': '0:00:15.471880',\n",
       " 'training_start_epoch': 0,\n",
       " 'training_epochs': 499,\n",
       " 'epoch': 499,\n",
       " 'training_precision': 1.0,\n",
       " 'training_recall': 0.7142857313156128,\n",
       " 'training_f1': 0.8333333730697632,\n",
       " 'training_loss': 0.0001285533217014745,\n",
       " 'training_cpu_memory_MB': 334.824,\n",
       " 'training_gpu_0_memory_MB': 960}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'dense_sparse_adam', 'betas': [0.9, 0.9]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocabulary with namespaces:  tokens, Size: 24 || Non Padded Namespaces: {'*labels', '*tags'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor([[1, 1, 1, 0],\n",
    "        [1, 1, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = numpy.inf \n",
    "arc_scores = torch.tensor([[[  -inf, 0.1252, 0.1161, 0.0475],\n",
    "         [0.0977,   -inf, 0.1015, 0.0373],\n",
    "         [0.1541, 0.1673,   -inf, 0.0934],\n",
    "         [0.0563, 0.0730, 0.0623,   -inf]],\n",
    "\n",
    "        [[  -inf, 0.0947, 0.1048, 0.1114],\n",
    "         [0.1385,   -inf, 0.1681, 0.1755],\n",
    "         [0.1114, 0.1310,   -inf, 0.1448],\n",
    "         [0.1274, 0.1454, 0.1537,   -inf]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  -inf, 0.1252, 0.1161, 0.0475],\n",
       "         [0.0977,   -inf, 0.1015, 0.0373],\n",
       "         [0.1541, 0.1673,   -inf, 0.0934],\n",
       "         [  -inf,   -inf,   -inf,   -inf]],\n",
       "\n",
       "        [[  -inf, 0.0947, 0.1048, 0.1114],\n",
       "         [0.1385,   -inf, 0.1681, 0.1755],\n",
       "         [0.1114, 0.1310,   -inf, 0.1448],\n",
       "         [0.1274, 0.1454, 0.1537,   -inf]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minus_mask = (mask<1).unsqueeze(2)    \n",
    "arc_scores.masked_fill_(minus_mask, -numpy.inf)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_probs = arc_scores.sigmoid()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 0],\n",
       "        [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_mask = (mask.unsqueeze(1) & mask.unsqueeze(2))<1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
