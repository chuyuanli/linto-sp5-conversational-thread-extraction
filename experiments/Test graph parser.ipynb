{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "\n",
    "I) version base\n",
    "- (done)  reprendre classifieur de chat hiérarchique, remplacer encodeur seq2vec par un seq2seq (stacked lstm eg)\n",
    "    cf HierarchicalChatSequenceClassification\n",
    "- (done)  ajouter séquence de labels / comme si arbre ou forêt (possible ds graph_parser ?)\n",
    "\n",
    "- (done) sousclasser graph_parser / modifs\n",
    "    [pas la peine] plus facile en forcant label unique sur les arcs ? à voir\n",
    "- (done/untested) brancher données réelles\n",
    "      \n",
    "      \n",
    "/home/muller/anaconda3/envs/allennlp/lib/python3.7/site-packages/allennlp/data/dataset_readers/semantic_dependency_parsing.py\n",
    "\n",
    "\n",
    "améliorations: \n",
    "- [done] déséquilibre class -> mettre poids dans la loss BCEwithlogitsloss \n",
    "- capacité modèle\n",
    "- encodeur tour -> bert\n",
    "- preprocessing des chats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import logging\n",
    "from typing import Any, Tuple, Dict, List, Iterable\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
    "from allennlp.data.fields import Field, LabelField, TextField, ListField, SequenceLabelField\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token, Tokenizer, WordTokenizer, PretrainedTransformerTokenizer\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "\n",
    "from allennlp.modules import Seq2VecEncoder, Seq2SeqEncoder\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "\n",
    "from allennlp.training.trainer import Trainer\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.common import Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from dummy_chat_reader import ChatReader\n",
    "from irc_chat_reader import ChatReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 13.79it/s]\u001b[A\n",
      "4it [00:00, 15.16it/s]\u001b[A\n",
      "6it [00:00, 14.83it/s]\u001b[A\n",
      "8it [00:00, 14.32it/s]\u001b[A\n",
      "11it [00:00, 16.24it/s]\u001b[A\n",
      "13it [00:00, 16.58it/s]\u001b[A\n",
      "15it [00:01, 12.74it/s]\u001b[A\n",
      "17it [00:01, 13.13it/s]\u001b[A\n",
      "19it [00:01, 13.75it/s]\u001b[A\n",
      "21it [00:01, 10.81it/s]\u001b[A\n",
      "23it [00:01,  9.98it/s]\u001b[A\n",
      "25it [00:02,  9.20it/s]\u001b[A\n",
      "27it [00:02,  8.93it/s]\u001b[A\n",
      "28it [00:02,  9.19it/s]\u001b[A\n",
      "29it [00:02,  8.95it/s]\u001b[A\n",
      "31it [00:02,  9.16it/s]\u001b[A\n",
      "33it [00:02, 10.35it/s]\u001b[A\n",
      "35it [00:03, 11.20it/s]\u001b[A\n",
      "37it [00:03,  9.68it/s]\u001b[A\n",
      "39it [00:03,  8.84it/s]\u001b[A\n",
      "40it [00:03,  8.76it/s]\u001b[A\n",
      "42it [00:03,  9.78it/s]\u001b[A\n",
      "44it [00:04,  9.27it/s]\u001b[A\n",
      "46it [00:04, 10.23it/s]\u001b[A\n",
      "48it [00:04, 10.54it/s]\u001b[A\n",
      "50it [00:04, 10.99it/s]\u001b[A\n",
      "53it [00:04, 12.12it/s]\u001b[A\n",
      "55it [00:04, 10.70it/s]\u001b[A\n",
      "57it [00:05,  8.60it/s]\u001b[A\n",
      "59it [00:05,  7.55it/s]\u001b[A\n",
      "60it [00:05,  7.70it/s]\u001b[A\n",
      "62it [00:05,  8.71it/s]\u001b[A\n",
      "63it [00:06,  8.73it/s]\u001b[A\n",
      "64it [00:06,  8.77it/s]\u001b[A\n",
      "65it [00:06,  8.48it/s]\u001b[A\n",
      "66it [00:06,  8.49it/s]\u001b[A\n",
      "67it [00:06,  8.37it/s]\u001b[A\n",
      "68it [00:06,  8.30it/s]\u001b[A\n",
      "70it [00:06,  9.24it/s]\u001b[A\n",
      "72it [00:07,  9.33it/s]\u001b[A\n",
      "74it [00:07,  9.56it/s]\u001b[A\n",
      "75it [00:07,  5.60it/s]\u001b[A\n",
      "76it [00:07,  6.21it/s]\u001b[A\n",
      "78it [00:07,  7.36it/s]\u001b[A\n",
      "79it [00:07,  7.73it/s]\u001b[A\n",
      "80it [00:08,  8.10it/s]\u001b[A\n",
      "81it [00:08,  8.01it/s]\u001b[A\n",
      "82it [00:08,  8.18it/s]\u001b[A\n",
      "84it [00:08,  9.10it/s]\u001b[A\n",
      "85it [00:08,  9.07it/s]\u001b[A\n",
      "86it [00:08,  8.86it/s]\u001b[A\n",
      "87it [00:08,  8.60it/s]\u001b[A\n",
      "88it [00:08,  8.67it/s]\u001b[A\n",
      "89it [00:09,  8.63it/s]\u001b[A\n",
      "90it [00:09,  8.63it/s]\u001b[A\n",
      "91it [00:09,  8.68it/s]\u001b[A\n",
      "92it [00:09,  8.35it/s]\u001b[A\n",
      "93it [00:09,  7.98it/s]\u001b[A\n",
      "94it [00:09,  8.01it/s]\u001b[A\n",
      "95it [00:09,  7.86it/s]\u001b[A\n",
      "96it [00:10,  6.83it/s]\u001b[A\n",
      "97it [00:10,  7.04it/s]\u001b[A\n",
      "98it [00:10,  5.46it/s]\u001b[A\n",
      "100it [00:10,  6.70it/s]\u001b[A\n",
      "101it [00:10,  7.12it/s]\u001b[A\n",
      "102it [00:10,  7.51it/s]\u001b[A\n",
      "103it [00:10,  7.82it/s]\u001b[A\n",
      "104it [00:11,  6.90it/s]\u001b[A\n",
      "105it [00:11,  7.24it/s]\u001b[A\n",
      "106it [00:11,  7.46it/s]\u001b[A\n",
      "107it [00:11,  7.86it/s]\u001b[A\n",
      "108it [00:11,  8.04it/s]\u001b[A\n",
      "111it [00:11,  9.50it/s]\u001b[A\n",
      "113it [00:12,  8.70it/s]\u001b[A\n",
      "114it [00:12,  8.55it/s]\u001b[A\n",
      "115it [00:12,  8.29it/s]\u001b[A\n",
      "116it [00:12,  8.56it/s]\u001b[A\n",
      "117it [00:12,  8.41it/s]\u001b[A\n",
      "118it [00:12,  8.45it/s]\u001b[A\n",
      "119it [00:12,  6.77it/s]\u001b[A\n",
      "120it [00:12,  7.17it/s]\u001b[A\n",
      "121it [00:13,  7.59it/s]\u001b[A\n",
      "122it [00:13,  7.72it/s]\u001b[A\n",
      "123it [00:13,  6.94it/s]\u001b[A\n",
      "124it [00:13,  7.44it/s]\u001b[A\n",
      "127it [00:13,  7.01it/s]\u001b[A\n",
      "128it [00:14,  6.67it/s]\u001b[A\n",
      "129it [00:14,  6.99it/s]\u001b[A\n",
      "130it [00:14,  7.28it/s]\u001b[A\n",
      "131it [00:14,  7.02it/s]\u001b[A\n",
      "132it [00:14,  7.28it/s]\u001b[A\n",
      "133it [00:14,  7.50it/s]\u001b[A\n",
      "134it [00:14,  7.57it/s]\u001b[A\n",
      "135it [00:15,  7.66it/s]\u001b[A\n",
      "136it [00:15,  7.84it/s]\u001b[A\n",
      "137it [00:15,  8.10it/s]\u001b[A\n",
      "138it [00:15,  8.20it/s]\u001b[A\n",
      "139it [00:15,  8.26it/s]\u001b[A\n",
      "141it [00:15,  9.59it/s]\u001b[A\n",
      "143it [00:15, 10.69it/s]\u001b[A\n",
      "145it [00:15, 11.26it/s]\u001b[A\n",
      "147it [00:16, 10.23it/s]\u001b[A\n",
      "149it [00:16,  9.64it/s]\u001b[A\n",
      "151it [00:16, 10.49it/s]\u001b[A\n",
      "153it [00:16, 11.98it/s]\u001b[A\n",
      "\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/dev/2016-12-19_20.raw.annotation.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-10455527eabb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m \u001b[0mtrain_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdev_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/dev\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_instances\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdev_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/allennlp2/lib/python3.7/site-packages/allennlp/data/dataset_readers/dataset_reader.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Then some validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0minstances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minstance\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 raise ConfigurationError(\"No instances were read from the given filepath {}. \"\n",
      "\u001b[0;32m~/miniconda3/envs/allennlp2/lib/python3.7/site-packages/allennlp/data/dataset_readers/dataset_reader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Then some validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0minstances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minstance\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 raise ConfigurationError(\"No instances were read from the given filepath {}. \"\n",
      "\u001b[0;32m~/miniconda3/envs/allennlp2/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Devel/Linto/linto-sp5-conversational-thread-extraction/experiments/irc_chat_reader.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(self, dir_path)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mannotation_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".annotation.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mannotation_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reading instances from lines in file at: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mannotation_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/dev/2016-12-19_20.raw.annotation.txt'"
     ]
    }
   ],
   "source": [
    "token_indexers = {\"tokens\": SingleIdTokenIndexer()}\n",
    "\n",
    "tokenizer_cfg = Params({\"word_splitter\": {\"language\": \"en\"}})\n",
    "\n",
    "tokenizer = Tokenizer.from_params(tokenizer_cfg)\n",
    "\n",
    "\n",
    "reader = ChatReader(\n",
    "    tokenizer=tokenizer,\n",
    "    token_indexers=token_indexers,\n",
    "    raw = True,\n",
    "    #clip = 200\n",
    "    )\n",
    "train_instances = reader.read(\"../data/train\")\n",
    "dev_instances = reader.read(\"../data/dev\")\n",
    "vocab = Vocabulary.from_instances(train_instances+dev_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i in train_instances:\n",
    "#    #print(i)\n",
    "#    i[\"lines\"].index(vocab)\n",
    "#    i[\"arcs\"].index(vocab)\n",
    "#    print(i[\"lines\"].get_padding_lengths())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance with fields:\n",
      " \t lines: ListField of 500 TextFields : \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, rolo, >, shazbotmcnasty, wait]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, DexterLB, >, still, no, effect, ,, home, folder, is, still, displayed, instead, of, ~/Desktop]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, acrobat, >, hi, i, m, new, to, ubuntu, can, smeone, hlepl, me, pls]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, acrobat, >, i, want, to, install, ubuntu, that, has, a, 64bit, compiler, on, a, 1, gb, usb,\n",
      "\t\tstick]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 92 with text: \n",
      " \t\t[<, arooni, -, mobile, _, _, _, >, hi, folks, ..., i, moved, my, karmic, desktop, from, one, side,\n",
      "\t\tof, the, room, to, the, other, ..., and, now, it, wo, nt, give, me, the, graphical, login, ., i,\n",
      "\t\tshould, say, that, only, 188, M, is, free, on, root, partition, ..., and, i, 'm, seeing, messages,\n",
      "\t\tin, /var, /, log, /, messages, like, :, pulseaudio, :, unable, to, contact, d, -, bus, :,\n",
      "\t\torg.freedesktop.DBus.error.spawn.execfailed, :, /bin, /, dbus, -, launch, terminated, abnormally,\n",
      "\t\twith, the, following, error, :, autolaunch, error, :, X11, initliaizatoin, failed]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, acrobat, >, someone, please, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 23 with text: \n",
      " \t\t[<, waldo, _, >, alright, the, error, message, says, \", unable, to, mount, location, ,, failed, to,\n",
      "\t\tretrieve, share, list, from, server, \"]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, ShazbotMcNasty, >, acrobat, ,, download, the, iso, ,, then, get, the, program, called, ',\n",
      "\t\tunetbootin, ']\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, bazhang, >, acrobat, ,, tried, unetbootin, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, ShazbotMcNasty, >, and, then, use, unetbootin, to, easily, put, the, iso, onto, the, usb, drive]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, acrobat, >, bazhang, :, do, you, even, know, what, that, does]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, acrobat, >, ShazbotMcNasty, :, where, do, i, get, the, iso]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, rolo, >, shazbotmcnasty, nevermind]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, bazhang, >, acrobat, ,, sure, do, ,, have, used, it, many, times]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, acrobat, >, i, know, how, to, use, unetbootin, i, ca, n't, find, an, iso, for, it, that, s, sub,\n",
      "\t\t1, gb]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, Ciocc, >, acrobat, simple, buy, a, bigger, stick]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, acrobat, >, ..., with, a, 64bit, toolchain, on, it]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, ShazbotMcNasty, >, acrobat, ,, http://www.ubuntu.com/getubuntu/download]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, mado, >, ok, then, ..., -, >, can, anybody, please, help, me, with, this, problem, ?, ...]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, mado, >, http://pastebin.ubuntu.com/335022/]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, DexterLB, >, acrobat, ,, 1Gb, simply, wo, n't, be, enough]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, mado, >, it, occurs, once, in, a, while, when, i, try, to, start, ubuntu]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, ShazbotMcNasty, >, I, just, downloaded, the, 9.10, iso, a, bit, ago, and, it, 's, like, 680MBs]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, wgrant, >, DexterLB, :, Uh, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, ShazbotMcNasty, >, 690MBs, actually, ..]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, mado, >, and, happened, last, before, i, rebooted, my, computer, and, came, in, here]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, ShazbotMcNasty, >, I, just, checked]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, wgrant, >, DexterLB, :, 1, GB, is, quite, enough, for, a, <, 700, MB, CD, image, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, eddy, >, i, get, an, error, message, when, installing, a, package]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 34 with text: \n",
      " \t\t[<, yang, _, >, Hey, ,, can, someone, help, me, with, a, roll, your, own, kernal, issue, ?, i, got,\n",
      "\t\tit, to, compile, created, deb, but, post, init, script, realate, to, nvida, -, common]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, acrobat, >, you, sure, it, has, a, toolchain]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, eddy, >, Error, :, Dependency, is, not, satisfiable, :, nvidia-71-kernel, -, source, (, >, =,\n",
      "\t\t71.86.08, )]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, oldtopman, >, I, have, the, impossible, request, (, for, laughs(but, its, true, ), )]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, acrobat, >, can, someone, confirm, the, 690, mb, ubuntu, has, a, toolchain, with, gcc, compiler]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, wgrant, >, acrobat, :, Only, the, DVD, images, will, have, the, full, toolchain, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, DaZ, >, wgrant, :, he, does, n't, want, it, from, a, cd, imo, ;, f]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, DexterLB, >, well, yes, but, if, you, installed, ,, add, stuff, ,, as, acrobat, wants, a,\n",
      "\t\ttoolchain]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, wgrant, >, acrobat, :, Do, you, not, have, network, access, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, acrobat, >, wgrant, :, that, was, what, i, was, thinking, too]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, DaZ, >, acrobat, :, create, your, own, iso]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, oldtopman, >, run, ubuntu, 9.10, on, a, ibm, 755cx]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, Takagami, >, oh, man, ..., I, need, some, FPS, action, ...]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, acrobat, >, how]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, DexterLB, >, he, 'll, need, at, least, 1.5, gb]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, acrobat, >, ffs]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, DaZ, >, hm]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, wgrant, >, acrobat, :, Why, do, you, want, to, have, the, toolchain, on, the, ISO, ?, Ca, n't,\n",
      "\t\tyou, just, download, it, afterwards, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, DexterLB, >, correct, me, if, I, 'm, wrong]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, eddy, >, can, someone, help, me, with, my, error, message]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, eddy, >, Error, :, Dependency, is, not, satisfiable, :, nvidia-71-kernel, -, source, (, >, =,\n",
      "\t\t71.86.08, )]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 29 with text: \n",
      " \t\t[<, ShazbotMcNasty, >, I, need, assistance, -, I, did, fsck, and, I, got, an, error, ,, can, anyone,\n",
      "\t\tdecifer, the, error, and, tell, me, what, to, do, ?, http://pastebin.com/m53795adc]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, ShazbotMcNasty, >, eddy, ,, do, sudo, apt, -, get, update, and, try, again]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, oem, >, hi, all]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, DexterLB, >, eddy, :, nvidia-71, that, 's, a, pretty, old, driver]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, oem, >, er]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[=, =, =, oem, is, now, known, as, steev, -, efikamx]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, oldtopman, >, shazbotmcnasty, lemme, checck]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, DexterLB, >, eddy, :, try, reloading, the, package, info]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 34 with text: \n",
      " \t\t[<, yang, _, >, Hey, ,, can, someone, help, me, with, a, roll, your, own, kernal, issue, ?, i, got,\n",
      "\t\tit, to, compile, created, deb, but, post, init, script, realate, to, nvida, -, common]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, Viking667, >, ...., right, ., That, 's, got, the, cooling, sort, of, sorted, out, ., took,\n",
      "\t\tanother, 4, degrees, C, off, the, core, temp]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, DexterLB, >, can, someone, help, me, ?, once, again, ,, my, problem, is, :, nautilus, is,\n",
      "\t\tshowing, ~, on, the, desktop, instead, of, ~/Desktop]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, eddy, >, its, not, really, na, app, ...., its, a, driver, ..., may, include, an, app, with, it]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, DaZ, >, DexterLB, :, do, you, have, ~/desktop, folder, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, oldtopman, >, shazbotmcnasty, yourpastebin, is, expired]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, DexterLB, >, DaZ, :, yes, I, do]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 92 with text: \n",
      " \t\t[<, steev, -, efikamx, >, so, i, have, a, machine, that, had, ubuntu, -, minimal, installed, on, it,\n",
      "\t\t-, openssh, -, server, is, installed, ,, however, it, is, n't, started, at, boot, -, i, 've, tried,\n",
      "\t\tupdate, -, rc.d, ssh, enable, -, and, it, says, its, created, the, files, but, ,, for, whatever,\n",
      "\t\treason, ,, every, time, i, boot, the, machine, ,, sshd, is, not, running, and, i, have, to, blindly,\n",
      "\t\t(, no, monitor, that, i, can, plug, in, to, it, ), -, and, start, ssh, -, am, i, missing, something,\n",
      "\t\t?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, mado, >, oldtopman, ,, pardon, me, ?, ..., such, a, thing, can, expire, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, ShazbotMcNasty, >, oldtopman, ,, http://pastebin.com/m50c3321b]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, mado, >, is, mine, then, still, \", alive, \", ?, oldtopman]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, oldtopman, >, mado, pastebin, is, temporary]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, oldtopman, >, sazbotmcnasty, i, typed, it, in, wrong]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, ShazbotMcNasty, >, the, older, one, is, still, up, ...., but, the, second, one, is, a, new, one]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, ShazbotMcNasty, >, it, 's, okay, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, DexterLB, >, here, 's, the, contents, of, my, home, folder, :, http://pastebin.com/d46cb2d78]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 28 with text: \n",
      " \t\t[<, mado, >, i, see, ..., well, i, 'm, sort, of, an, apprentice, :), ..., i, did, n't, know, that,\n",
      "\t\tbefore, but, ..., yeah, ..., it, makes, sense]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, rolo, >, how, do, I, run, apache, after, I, have, installed, it]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, oldtopman, >, shazbotmcnasty, ,, looks, like, nothing, really, important]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 35 with text: \n",
      " \t\t[<, mado, >, oldtopman, ,, i, do, hope, though, that, i, will, find, a, solution, to, my, problem,\n",
      "\t\t..., but, you, should, help, ShazbotMcNasty, first, ..., i, guess, she, /, he, was, here, before,\n",
      "\t\tme]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, DexterLB, >, rolo, :, it, 's, already, running]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, eddy, >, i, wonder, if, ui, shut, down, &, connect, of, motherboard, video, would, it, find, my,\n",
      "\t\tdriver]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, oldtopman, >, shazbotmcnasty, ,, looks, like, nothing, really, important]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, rolo, >, and, tomcat, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, oldtopman, >, oops]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 30 with text: \n",
      " \t\t[<, timtom, >, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks,\n",
      "\t\tLinux, sucLinux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux,\n",
      "\t\tsuc]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 30 with text: \n",
      " \t\t[<, timtom, >, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks,\n",
      "\t\tLinux, sucLinux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux,\n",
      "\t\tsuc]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 30 with text: \n",
      " \t\t[<, timtom, >, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks,\n",
      "\t\tLinux, sucLinux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux,\n",
      "\t\tsuc]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 30 with text: \n",
      " \t\t[<, timtom, >, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks,\n",
      "\t\tLinux, sucLinux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux, sucks, Linux,\n",
      "\t\tsuc]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, FloodBot1, >, timtom, :, Please, do, n't, flood, ,, use, http://paste.ubuntu.com, to, paste, ,,\n",
      "\t\tdo, n't, use, Enter, as, punctuation, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, iceroot, >, rolo, :, sudo, /etc, /, init.d, /, apache2, start]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 28 with text: \n",
      " \t\t[<, DexterLB, >, rolo, :, if, it, 's, not, ,, try, running, \", sudo, /etc, /, init.d, /, apache2,\n",
      "\t\trestart, \", and, see, if, it, gives, an, error]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, DaZ, >, timtom, :, it, does, :, f]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, oldtopman, >, mado, what, s, your, problem]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, DexterLB, >, timtom, :, why, ?, it, 's, great, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[*, Takagami, loves, his, linux]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 3 with text: \n",
      " \t\t[*, DexterLB, too]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, mado, >, as, i, wrote, a, bit, earlier, ..., -, >, http://pastebin.ubuntu.com/335022/]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, Takagami, >, Stupid, audio]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, eddy, >, timtom, ...., go, back, to, windows, &, virises]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, DaZ, >, DexterLB, :, and, desktop, always, displays, correctly, :, F]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, mado, >, once, in, a, while, i, get, this, message, when, i, try, to, boot, ubuntu]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, mado, >, oldtopman, ,]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[=, =, =, hacker, -, palso, is, now, known, as, hero]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, rolo, >, Could, not, reliably, determine, the, server, 's, fully, qualified, domain, name, ,,\n",
      "\t\tusing, 127.0.1.1, for, ServerName]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, rolo, >, how, do, I, change, this, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, oldtopman, >, mado, what, were, you, doing]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, DexterLB, >, DaZ, :, yeah, ,, but, in, my, case, the, problem, is, in, me, I, spose]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, DaZ, >, DexterLB, :, why, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, DexterLB, >, DaZ, :, you, see, ,, I, ran, the, nonautilus, script]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, mado, >, pardon, me, oldtopman, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, mado, >, what, do, you, mean, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, DaZ, >, DexterLB, :, it, 's, somewhere, in, gconf, but, i, do, n't, have, gnome, right, now]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, ShazbotMcNasty, >, oldtopman, ,, wel, I, ca, n't, boot, any, iso, 's, that, are, on, my,\n",
      "\t\texternal, hard, drive]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, DexterLB, >, DaZ, :, then, I, ran, it, in, reverse, mode]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, mado, >, i, was, just, booting, ubuntu, 9.10, oldtopman]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, DaZ, >, DexterLB, :, what, script, ?, :, f]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, ShazbotMcNasty, >, the, error, is, gives, me, is, do, \", chkdsk, /r, \", on, windows]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, ShazbotMcNasty, >, so, I, do, fdsk, in, linux, ,, and, that, 's, the, error, that, I, 'm,\n",
      "\t\thaving]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, DexterLB, >, https://help.ubuntu.com/community/DefaultFileManager]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, oldtopman, >, hmmmmm]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, ShazbotMcNasty, >, so, I, ca, n't, boot, any, of, my, iso, 's, that, I, have, installed, with,\n",
      "\t\tgrub2]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, Viking667, >, does, grub2, even, support, booting, off, ISO, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, Viking667, >, (, let, alone, CD, -, ROM, ), ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 54 with text: \n",
      " \t\t[<, mado, >, as, you, probably, can, see, oldtopman, i, tried, to, boot, it, again, ..., and, this,\n",
      "\t\ttime, ..., no, error, at, all, :), ..., this, drives, me, a, bit, crazy, ..., because, every, once,\n",
      "\t\tin, a, while, i, get, this, message, ..., and, i, do, n't, want, to, simpy, ignore, it, oldtopman]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, oldtopman, >, mado, ,, I, know, a, bit, of, linux, butmostly, dsl, an, puppy, sorry]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, mado, >, dsl, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, mado, >, this, small, thing, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, mado, >, oldtopman, ,]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, enzotib, >, damn, small, linux]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, DaZ, >, DexterLB, :, you, can, always, reinstall, nautilus, imo]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, oldtopman, >, is, nt, damn, banned]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 23 with text: \n",
      " \t\t[<, mado, >, brill, !, ..., i, could, need, some, hand, there, too, in, the, future, (, as, far, as,\n",
      "\t\ti, know, )]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, DexterLB, >, DaZ, :, how, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, Viking667, >, oldtopman, :, DSL, is, probably, one, of, the, few, places, you, can, use, it]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 26 with text: \n",
      " \t\t[<, mado, >, oldtopman, ,, looks, like, it, 's, not, ..., although, it, 's, a, curse, word, it, 's,\n",
      "\t\talso, a, \", technical, jargon, \", :)]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, Viking667, >, Meanwhile, ,, is, there, any, way, of, getting, those, panels, of, mine, to,\n",
      "\t\tchange, monitors, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, DexterLB, >, DaZ, :, aptitude, reinstall, wo, n't, help, for, gconf, I, guess]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, oldtopman, >, ok, ha]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, DaZ, >, DexterLB, :, it, wo, n't, but, this, script, does, something, in, /usr]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, steev, -, efikamx, >, Viking667, :, you, ca, n't, drag, them, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, Viking667, >, uh, ,, no, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, oldtopman, >, do, you, suppose, icouldrun, ubuntu, aff, of, a, very, old, laptop]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, DexterLB, >, DaZ, :, I, 'll, try, moving, nautilus, gconf, thing, to, a, backup, location, and,\n",
      "\t\tdoing, an, aptitude, reinstall]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, DaZ, >, it, 's, almost, morning, here, so, i, ca, n't, know, what, exactly, ,, but, it, does,\n",
      "\t\tsomething, :, F]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, eddy, >, hod, do, i, install, a, .run, file]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, eddy, >, *, how]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, DexterLB, >, run, it, !, :D]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, ctmjr, >, eddy, :, what, run, file, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, eddy, >, i, mean, what, s, the, terminal, commnad, to, run, it]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, Linux, -, CLI, >, hi]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, DexterLB, >, in, terminal, :, chmod, +, x, yourfile.run, &, &, yourfile.run]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 69 with text: \n",
      " \t\t[<, Linux, -, CLI, >, Please, recommend, a, way, I, can, S, -, Video, to, work, on, my, computer, .,\n",
      "\t\tI, 'm, happy, to, use, any, Operating, System, except, Windows, to, do, this, ., As, long, as, I,\n",
      "\t\tam, able, to, get, that, Operating, System, to, play, WMV, ., I, am, using, a, Dell, Inspiron, 700,\n",
      "\t\tm, ., Which, Operating, System, supports, S, -, Video, for, my, hardware, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, Viking667, >, eddy, :, make, it, executable, first, ., chmod]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, eddy, >, a, driver, for, my, video, card]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, oldtopman, >, hi, linux, -, cli]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, Viking667, >, ah, ., I, see, DexterLB, just, told, you, how]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, bazhang, >, Linux, -, CLI, ,, which, version, of, ubuntu, are, you, running]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, MindVirus, >, How, do, I, find, out, what, process, number, is, using, the, most, amount, of,\n",
      "\t\tbandwidth, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, MindVirus, >, That, is, ,, Internet, bandwidth, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, svinoba, >, eddy, :, ./<file>.run]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, thedarkthoughts, _, >, hello]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, DexterLB, >, eddy, :, installing, the, driver, from, the, nvidia, f***g, site, is, not,\n",
      "\t\trecommended]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 67 with text: \n",
      " \t\t[<, Takagami, >, So, I, installed, 9.04.3, ubuntu, -, minimal, on, my, Dell, Mini, 9, A03, ., I,\n",
      "\t\thave, installed, only, the, xorg, ,, gnome, -, core, and, alsa, -, base, meta, packages, ., My,\n",
      "\t\tsound, hardware, is, detected, correctly, ,, I, can, change, all, volume, levels, and, play, audio,\n",
      "\t\t., I, do, n't, get, any, sound, from, speakers, or, headphones, ..., what, am, I, missing, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, Linux, -, CLI, >, bazhang, :, 9.10]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, thedarkthoughts, _, >, Is, that, channel, for, ubuntu, ?, ?, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, Linux, -, CLI, >, But, am, happy, to, upgrade, or, downgrade]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, wgrant, >, Takagami, :, There, is, no, such, release, ., Do, you, mean, 8.04.3, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 23 with text: \n",
      " \t\t[<, DexterLB, >, eddy, :, in, the, next, kernel, upgrade, it, 'll, fail, and, you, wo, n't, be,\n",
      "\t\table, to, go, into, GUI]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, bazhang, >, thedarkthoughts, _, ,, yes]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 29 with text: \n",
      " \t\t[<, Viking667, >, steev, -, efikamx, :, and, no, ,, I, ca, n't, drag, them, ., This, is, the,\n",
      "\t\tstandard, panels, ya, get, with, Gnome, ,, on, Ubuntu, 9.10]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, thedarkthoughts, _, >, ah, .., great]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, Takagami, >, sorry, ..., no, ..., latest, 9.04]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, greezmunkey, >, MindVirus, ,, get, bmon, ,, it, 's, a, start, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, DexterLB, >, X, restart, ,, brb]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, Takagami, >, I, played, with, 8.04.3, minimal, last, week, for, same, issue]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, MindVirus, >, greezmunkey, :, I, 'll, check, it, out, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, mado, >, oldtopman, ,, thanks, for, your, hand]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, svinoba, >, Takagami, :, is, headphone, unmuted, ?, in, alsamixer, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, oldtopman, >, mado, no, prob]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, eddy, >, i, m, new, to, ubuntu, ., how, do, i, do, the, chmod]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, thedarkthoughts, >, anyone, knows, how, to, install, Snort, on, ubuntu, 9.04]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, Takagami, >, svinoba, :, all, mixers, are, unmuted, and, up, to, 98, or, so, ...]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 35 with text: \n",
      " \t\t[<, DaZ, >, If, set, to, true, ,, then, Nautilus, will, use, the, user, 's, home, folder, as, the,\n",
      "\t\tdesktop, ., If, it, is, false, ,, then, it, will, use, ~/Desktop, as, the, desktop, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, bazhang, >, thedarkthoughts, ,, sudo, apt, -, get, install, snort]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, DaZ, >, damn, ,, he, left, :, F]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, thedarkthoughts, >, ok, thx, ,, bazhand]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, thedarkthoughts, >, *, bazhang, sorry]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, oldtopman, >, eddy, not, sure, chmod, 755, <, file, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, eddy, >, dexter, ..., then, how, do, i, get, my, driver, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 28 with text: \n",
      " \t\t[<, ctmjr, >, eddy, :, there, are, steps, you, need, to, take, too, install, the, drivers, from,\n",
      "\t\tnvidia, 's, website, it, is, not, for, the, faint, of, heart]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, thevishy, >, hi]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, thevishy, >, i, have, installed, ubuntu]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, oldtopman, >, thevishy, welcome]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, DaZ, >, thevishy, :, awesome]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, thevishy, >, why, is, nt, there, a, irc, client, in, ubntu, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, thedarkthoughts, >, great, ,, is, works, thx, a, lod, ,, bazhang]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, thedarkthoughts, >, :D]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, oldtopman, >, thevishy, congrats]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, bazhang, >, thedarkthoughts, ,, you, are, welcome]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, thevishy, >, thanks, :)]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, lstarnes, >, thevishy, :, there, are, irc, clients, in, ubuntu]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, thevishy, >, i, installe, the, alternate, distro, ...]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, eddy, >, thevishy, ...., there, is, irc, in, ubuntu, ., i, m, using, xchat, in, ubuntu]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, lstarnes, >, thevishy, :, you, might, need, to, install, them, from, the, package, manager,\n",
      "\t\tthough]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, thedarkthoughts, >, Anyone, knows, the, system, requirements, for, Compiz, on, Ubuntu, 9.04, ?,\n",
      "\t\t?, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, lstarnes, >, thevishy, :, try, installing, xchat]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, MindVirus, >, greezmunkey, :, How, do, I, see, processes, in, bmon, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, thevishy, >, by, default, dnt, we, have, irc, installed, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, thevishy, >, do, nt, *]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 27 with text: \n",
      " \t\t[<, khelvan, >, Can, someone, please, help, me, figure, out, why, rtorrent, is, not, downloading,\n",
      "\t\tanything, even, though, I, have, the, .torrent, file, ready, to, go, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, DaZ, >, thedarkthoughts, :, worknig, graphic, card]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 69 with text: \n",
      " \t\t[<, Linux, -, CLI, >, Please, recommend, a, way, I, can, S, -, Video, to, work, on, my, computer, .,\n",
      "\t\tI, 'm, happy, to, use, any, Operating, System, except, Windows, to, do, this, ., As, long, as, I,\n",
      "\t\tam, able, to, get, that, Operating, System, to, play, WMV, ., I, am, using, a, Dell, Inspiron, 700,\n",
      "\t\tm, ., Which, Operating, System, supports, S, -, Video, for, my, hardware, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, DaZ, >, processor, and, some, ram, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, wgrant, >, thevishy, :, The, default, IRC, client, in, Ubuntu, 9.10, is, Empathy, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, greezmunkey, >, MindVirus, ,, like, I, said, ,, it, 's, a, start, ,, and, you, ca, n't, ,,\n",
      "\t\tsorry]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, thevishy, >, right, wgrant]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, eddy, >, i, wish, i, could, get, the, driver, installed, to, make, mine, work, better]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, DaZ, >, oh, ,, and, monitor, would, be, good, too, :, f]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, MindVirus, >, Man, ,, I, did, not, need, this, software, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, svinoba, >, thevishy, :, no, i, guess, ., but, as, suggested, install, xchat, or, irssi]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, thedarkthoughts, >, ok, ,, DaZ, thx]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, thevishy, >, now, I, opened, synaptic, to, install, xchat, ,, but, i, do, nt, see, the,\n",
      "\t\tsoftware, ...]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, oldtopman, >, thevishy, xchat, seems, to, work, well, ,, usin, it, from, puppylinux]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, MindVirus, >, Does, anyone, know, how, to, view, which, processes, are, using, the, most,\n",
      "\t\tInternet, bandwidth, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, soreau, >, thedarkthoughts, :, You, can, check, the, wiki, http://wiki.compiz.org/, You, will,\n",
      "\t\tneed, an, intel, ,, ati, or, nvidia, chipset, made, in, this, century]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, svinoba, >, thevishy, :, sudo, apt, -, get, install, xchat, or, sudo, apt, -, get, install,\n",
      "\t\tirssi]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, DaZ, >, soreau, :, lame, ,, kwin, -, composite, works, on, ViRGE, :, F]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, svinoba, >, thevishy, :, btw, ,, its, in, Ubuntu, Software, Center, under, Internet]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, thevishy, >, right]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, soreau, >, DaZ, :, He, asked, about, compiz, ,, not, kompiz]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, greezmunkey, >, MindVirus, ,, check, out, ntop, ...]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 28 with text: \n",
      " \t\t[*, Viking667, blinks, ., Still, nothing, relevant, ,, even, in, gconf, ..., funnily, enough, ,,\n",
      "\t\tthere, 's, a, \", disable_move, \", key, ,, but, no, related, schema, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, strywgr, >, kuch, yaar, nazar, nahin, ata, !]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, thevishy, >, svinoba, :, under, Internet, option, I, can, see, only, Ubuntu, One]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, Viking667, >, ..., and, I, really, do, n't, want, to, have, to, delete, .gconf, just, to, get,\n",
      "\t\tmy, desktop, sane, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, DaZ, >, strywgr, :, ke, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, strywgr, >, daz, :/]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, svinoba, >, thevishy, :, try, it, in, search, ., I, also, installed, from, alternate, cd, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, strywgr, >, the, nick, seems, to, be, familiar, !]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, oldtopman, >, will, ubuntu, or, xubuntu, run, on, a, 2.6ghz, intel, celeron, w/256, mb, of, ram]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, eddy, >, thevishy, ...., at, top, of, screen, ,, click, system, >, help, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, eddy, >, then, it, will, ist, irc, rooms, ., click, a, room, &, it, will, let, u, download,\n",
      "\t\txchat]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, MindVirus, >, greezmunkey, :, I, 'll, check, it, out, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, DaZ, >, oldtopman, :, it, will, but, more, ram, would, be, fine, :, f]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, thevishy, >, what, in, Help, ...]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, thevishy, >, !, codex]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, thevishy, >, !, codec]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 29 with text: \n",
      " \t\t[<, ubottu, >, For, multimedia, issues, ,, this, page, has, useful, information, :,\n",
      "\t\thttps://help.ubuntu.com/community/RestrictedFormats, -, See, also,\n",
      "\t\thttps://help.ubuntu.com/9.04/musicvideophotos/C/video.html, -, But, please, use, free, formats, if,\n",
      "\t\tyou, can, :, https://help.ubuntu.com/community/FreeFormats]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, oldtopman, >, daztoo, old, to, upgrade, *, sobs, *]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, greezmunkey, >, MindVirus, ,, it, 's, pretty, rough, ,, I, 'm, looking, into, it, noe, myself,\n",
      "\t\t.]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, svinoba, >, thevishy, :, not, Internet, option, under, Applications, ., Applications->Ubuntu,\n",
      "\t\tSoftware, Center->Internet]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, oldtopman, >, daz, ,, do, you, want, to, hear, something, slow]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, thevishy, >, thanks, svinoba, will, try, that]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[*, Viking667, shrugs, ,, and, disconnects, ,, at, least, for, the, moment, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, DaZ, >, oldtopman, :, slow, ?, :, f]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, thevishy, >, it, says, not, available, in, current, data]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, ninjah, >, what, 's, the, traceroute, tool, in, ubuntu]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, oldtopman, >, ibm, 755cx]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, thevishy, >, Canonical, does, nt, provide, update, ...]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, eddy, >, thevishy, ..., https://answers.launchpad.net/ubuntu/karmic/+source/yelp/+gethelp]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, Viking667, >, Pentium, III, ,, 600, with, 384, Mb]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, wgrant, >, ninjah, :, Try, ', mtr, ']\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, eddy, >, then, click, on, the, irc, room]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, ninjah, >, wgrant, :, hmmm, ..., Okay]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, oldtopman, >, pentium75, (, 75mhz, ), and, 8, mb, of, ram, (, maxed, at, 40, )]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, ctmjr, >, Linux, -, CLI, :, what, graphic, card, do, you, have]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, Linux, -, CLI, >, Intel]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, Linux, -, CLI, >, I, 'll, get, the, exact, model, ,, brb]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, svinoba, >, thevishy, :, guess, ,, u, didnot, have, internet, connection, during, install, .,\n",
      "\t\tdo, sudo, apt, -, get, update]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, ninjah, >, wgrant, :, cool, Thanks]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, DaZ, >, oldtopman, :, at, least, thinkpads, are, pretty, solid, :, F]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, Viking667, >, ninjah, :, there, 's, also, a, \", traceroute, \", package, you, may, have, to,\n",
      "\t\tinstall]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, thevishy, >, no, i, did, nt, have, internet, during, install, ,, had, to, configure, wireless]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, MacDrunk, >, helllo]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, Linux, -, CLI, >, ctmjr, :, Intel, Extreme, Graphics, 2, (, i855GM, /, GME, )]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, oldtopman, >, daz, sat, idle, for, 10yrs, thru, 1, move, and, fired, right, up]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, svinoba, >, thevishy, :, then, update, apt, sources, ', sudo, apt, -, get, update, ']\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, strywgr, >, oldtopman, ,, you, got, the, link, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, oldtopman, >, ..., intowindows, 95]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, oldtopman, >, strywgr, to, what]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, strywgr, >, system, requirement, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, MacMiller, >, hello]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, oldtopman, >, hmmmm, gimme, a, min]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 26 with text: \n",
      " \t\t[<, ctmjr, >, Linux, -, CLI, :, i, do, not, know, alot, about, intel, cards, but, hold, on, will,\n",
      "\t\tsee, what, i, can, find, for, you]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, polo, >, hello]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, melrockz, >, plz, tell, me, how, to, write, a, gstreamer, pipeline, to, encode, mp3, at,\n",
      "\t\t192kbps]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, oldtopman, >, strywgr, www.ertyu.org/steven_nikkel/thinkpadspecs.html]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, oldtopman, >, exit, ,, stage, left]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, strywgr, >, oldtopman, :, you, can, check, the, minimum, requirements, from, -, >,\n",
      "\t\thttps://help.ubuntu.com/community/Installation/SystemRequirements]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, Linux, -, CLI, >, ctmjr, :, Thanks]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, mado, >, i, 'm, still, trying, to, find, a, solution, to, my, problem, folks, :), -, >,\n",
      "\t\thttp://pastebin.ubuntu.com/335022/]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, melrockz, >, plz, tell, me, how, to, write, a, gstreamer, pipeline, to, encode, mp3, at,\n",
      "\t\t192kbps]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, melrockz, >, using, sound, juicer]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, TheCash, >, my, comptuer, supports, 1280x1024, but, i, can, only, go, to, 1024x768]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, mado, >, as, i, 'm, new, to, ubuntu, i, do, n't, have, an, idea, what, the, problem, is]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, strywgr, >, TheCash, ,, it, is, switching, back, to, 1024x68, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, strywgr, >, 7, *]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, TheCash, >, there, is, no, option, for, 1280x1024, but, on, windows, that, is, what, I, used]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, thevishy, >, ooo, i, am, loving, it, :P]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, melrockz, >, plz, tell, me, how, to, write, a, gstreamer, pipeline, to, encode, mp3, at,\n",
      "\t\t192kbps]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, mado, >, melrockz, ,, i, guess, we, both, have, to, wait, :)]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, TheCash, >, lol]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 34 with text: \n",
      " \t\t[<, DexterLB, >, bah, ,, I, reinstalled, nautilus, ,, installed, the, updates, ,, including, the,\n",
      "\t\tnew, kernel, ,, no, effect, ., I, still, have, the, contents, of, ~, on, the, desktop, instead, of,\n",
      "\t\t~/Desktop]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, strywgr, >, thecash, ,, are, you, using, any, graphics, card, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 32 with text: \n",
      " \t\t[<, ctmjr, >, Linux, -, CLI, :, did, you, try, any, of, the, function, keys, i, have, a, laptop,\n",
      "\t\twith, an, ati, card, and, i, can, switch, with, function, key, +, f8]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, svinoba, >, DexterLB, :, on, Ubuntu, or, Kubuntu, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, TheCash, >, i, m, not, sure, becouse, this, is, a, old, computer, that, was, givin, to, me,\n",
      "\t\tuntil, i, could, get, a, new, one]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, DexterLB, >, Ubuntu]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, DexterLB, >, gnome]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, fahadsadah, >, mado, :, Could, n't, find, your, drive]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, fahadsadah, >, I, 'm, guessing, it, 's, the, initrd, that, could, n't, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, melrockz, >, i, managed, to, get, the, mp3, profile, working, by, installing, ubuntu, -,\n",
      "\t\trestricted, -, extras]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, mado, >, fahadsadah, ,, and, that, means, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, mado, >, i, 'm, new, to, ubuntu, ..., i, do, n't, have, any, clue, fahadsadah]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, fahadsadah, >, mado, :, Please, pastebin, the, output, of, \", ls, /dev, /, disk, /, by, -,\n",
      "\t\tuuid/, \", ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, strywgr, >, try, xrandr, 1280x1024]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, Linux, -, CLI, >, ctmjr, :, Unfortunately, that, does, n't, work, :(]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, TheCash, >, ok]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, melrockz, >, but, how, do, i, set, the, bitrate, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, mado, >, fahadsadah, ,, -, >, http://pastebin.ubuntu.com/335045/]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 51 with text: \n",
      " \t\t[<, mikkelgj, >, So, i, just, installed, the, nVidia, drivers, (, system->admin->hardware, ), .,\n",
      "\t\tAfter, reboot, i, get, :, \", Unable, to, load, NVIDIA, kernel, module, \", and, the, hardware,\n",
      "\t\tdriver, app, tells, me, that, the, NVIDIA, driver, is, activated, but, not, in, use, ., How, do, i,\n",
      "\t\tfix, this, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, fahadsadah, >, Thanks]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, TheCash, >, i, got, a, usage, screen]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, svinoba, >, DexterLB, :, have, u, tried, gconf, -, editor, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, DexterLB, >, yes]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, melrockz, >, plz, tell, me, how, to, write, a, gstreamer, pipeline, to, encode, mp3, at,\n",
      "\t\t192kbps]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, fahadsadah, >, mado, :, Try, typing, exit, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, mado, >, you, 're, welcome, -, >, fahadsadah, ..., were, you, able, to, follow, my,\n",
      "\t\tconversation, with, oldtopman, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, fahadsadah, >, I, just, woke, up, ,, no]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, fahadsadah, >, I, 'll, read, the, logs, now]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, mado, >, ok, :)]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, mado, >, the, thing, is, ...]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 32 with text: \n",
      " \t\t[<, svinoba, >, DexterLB, :, in, terminal, ', gconf, -, editor, ', and, then,\n",
      "\t\tapps->nautilus->preferences, ., here, ,, desktop_is_home_directory, is, ', unchecked, ', for, me, .,\n",
      "\t\tsee, if, urs, is, checked, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, Trailpups, >, DexterLB, ,, edit, .config, /, user, -, dirs.dirs]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, mado, >, i, 'm, no, longer, facing, this, screen]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, mado, >, i, showed, you, fahadsadah]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, mado, >, it, only, occurs, once, in, a, while, when, i, try, to, boot, ubuntu, 9.10, fahadsadah]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, Linux, -, CLI, >, ctmjr, :, Any, ideas, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, fahadsadah, >, mado, :, Oh, !]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, fahadsadah, >, Your, disk, is, too, slow]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, DexterLB, >, svinoba, :, it, 's, unchecked, for, me, too]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, mado, >, so, ..., shortly, after, i, got, this, message, ...]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, DexterLB, >, Trialpups, :, I, 'm, doing, it, now, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 32 with text: \n",
      " \t\t[<, a931bw, >, Dudes, i, need, help, !, !, !, i, installed, openSUSE, on, SDA5, ubuntu, was, SDA1,\n",
      "\t\tbots, OS, have, same, swap, but, ubuntu, wo, nt, load, heres, grub, menu.lst,\n",
      "\t\thttp://pastebin.com/d49e5e5c2]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, mado, >, i, switched, off, the, computer, (, let, it, crash, ), and, then, i, booted, again,\n",
      "\t\t..., this, time, ..., no, errors, fahadsadah]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, fahadsadah, >, http://www.ubuntu.com/getubuntu/releasenotes/810#Boot%20failures%20on%20systems%2\n",
      "\t\t0with%20Intel%20D945%20motherboards]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, fahadsadah, >, mado, :, It, 's, a, boot, time, error]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 32 with text: \n",
      " \t\t[<, a931bw, >, Dudes, i, need, help, !, !, !, i, installed, openSUSE, on, SDA5, ubuntu, was, SDA1,\n",
      "\t\tbots, OS, have, same, swap, but, ubuntu, wo, nt, load, heres, grub, menu.lst,\n",
      "\t\thttp://pastebin.com/d49e5e5c2]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, bazhang, >, !, repeat, |, a931bw]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 36 with text: \n",
      " \t\t[<, ubottu, >, a931bw, :, Do, n't, feel, ignored, and, repeat, your, question, quickly, ;, if,\n",
      "\t\tnobody, knows, your, answer, ,, nobody, will, answer, you, ., You, can, search,\n",
      "\t\thttps://help.ubuntu.com, or, http://ubuntuforums.org, while, you, wait, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 42 with text: \n",
      " \t\t[<, mado, >, oh, !, ..., i, see, fahadsadah, (, not, really, but, now, it, makes, more, sense, ),\n",
      "\t\t..., so, ..., what, should, i, do, about, it, ?, ..., fahadsadah, ..., ..., there, is, no, \",\n",
      "\t\tmenu.lst, \", in, ubuntu, 9.10]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 32 with text: \n",
      " \t\t[<, a931bw, >, Dudes, i, need, help, !, !, !, i, installed, openSUSE, on, SDA5, ubuntu, was, SDA1,\n",
      "\t\tbots, OS, have, same, swap, but, ubuntu, wo, nt, load, heres, grub, menu.lst,\n",
      "\t\thttp://pastebin.com/d49e5e5c2]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, svinoba, >, DexterLB, :, take, a, look, at, .config, /, user, -, dirs.dirs, as, suggested, by,\n",
      "\t\tTrailpups]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, a931bw, >, Help, pleasee]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, fahadsadah, >, mado, :, Oh, ,, forgot, that, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, a931bw, >, i, hate, that, rpm, based, OS, :(]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, bazhang, >, a931bw, ,, do, nt, repeat, ., see, the, message, from, ubottu]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, DexterLB, >, Trailpups, ,, svinoba, :, that, worked, ,, thanks]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, fahadsadah, >, mado, :, /boot, /, grub, /, grub.cfg]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, Trailpups, >, DexterLB, ,, great, !]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, DexterLB, >, :)]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 37 with text: \n",
      " \t\t[<, Linux, -, CLI, >, I, 'm, looking, for, a, CLI, tool, which, can, batch, search, &, replace,\n",
      "\t\tthrough, a, list, of, files, (, as, text, -, files, ,, but, different, extensions, ), ., Any,\n",
      "\t\trecommendations, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, svinoba, >, DexterLB, :, Thanks, to, Trailpups, ,, learnt, a, new, thing, today, ..., :)]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, mado, >, er, fahadsadah, ..., ok, -, >, let, 's, see]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, DexterLB, >, vim, saves, the, day, :D]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, fahadsadah, >, Linux, -, CLI, :, sed]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, mado, >, ok, fahadsadah, ..., i, opened, it]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, mado, >, what, now, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, svinoba, >, GUI, ca, nt, beat, CLI, right, .., :D]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 23 with text: \n",
      " \t\t[<, ctmjr, >, Linux, -, CLI, :, well, lets, start, from, the, beginning, did, you, install, any,\n",
      "\t\tdrivers, for, the, card, yet, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 32 with text: \n",
      " \t\t[<, a931bw, >, Dudes, i, need, help, !, !, !, i, installed, openSUSE, on, SDA5, ubuntu, was, SDA1,\n",
      "\t\tbots, OS, have, same, swap, but, ubuntu, wo, nt, load, heres, grub, menu.lst,\n",
      "\t\thttp://pastebin.com/d49e5e5c2]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, DexterLB, >, svinoba, :, yup]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, fahadsadah, >, mado, :, Find, the, line, beginning, with, \", linux, \"]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, DexterLB, >, svinoba, :, especially, vim, ,, it, 's, gorgeous]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, DexterLB, >, gvim, ,, kvim, etc, suck]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, monestri, >, home, /home, /, safire, vboxsf, uid=1000,gid=1000, 0, 1]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, monestri, >, home, does, n't, seem, to, be, being, mounted, at, boot]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 47 with text: \n",
      " \t\t[<, Linux, -, CLI, >, I, 'm, looking, for, a, CLI, tool, which, can, complete, a, directory,\n",
      "\t\tlisting, (, with, full, path, ,, not, sure, if, ls, can, do, this, ), then, add, File, <, tab, >,\n",
      "\t\tto, the, start, of, each, line, ., Any, recommendations, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, monestri, >, but, mount, home, works]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, Linux, -, CLI, >, ctmjr, :, Nope]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, mado, >, fahadsadah, ,, -, >, i, guess, you, 're, talking, about, this, -, >,\n",
      "\t\thttp://pastebin.ubuntu.com/335047/]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, ctmjr, >, Linux, -, CLI, :, your, using, gnome, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, Linux, -, CLI, >, yep]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, fahadsadah, >, mado, :, Yes, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, svinoba, >, a931bw, :, you, have, ', grub, ', on, 9.10, ,, not, ', grub2, ', ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, Linux, -, CLI, >, Probably, because, of, an, upgrade, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, fahadsadah, >, mado, :, Please, add, \", rootdelay=90, \", to, the, end, of, the, line, beginning,\n",
      "\t\t\", linux, \"]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, Archilles, >, If, you, know, GRUB, you, have, to, relearn, with, GRUB2]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, mado, >, fahadsadah, ,, how, come, this, error, occurs, in, 9.10, again, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, zcat[1, ], >, !, grub2]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, ubottu, >, GRUB2, is, the, default, Ubuntu, boot, manager, in, Karmic, ., For, more,\n",
      "\t\tinformation, and, troubleshooting, on, GRUB2, please, refer, to, https://wiki.ubuntu.com/Grub2]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, a931bw, >, idk, i, m, total, noob, on, these]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, fahadsadah, >, mado, :, I, 'm, not, too, sure, ,, to, be, honest, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 26 with text: \n",
      " \t\t[<, ctmjr, >, Linux, -, CLI, :, look, in, the, main, menu, under, system, >, administrator, >,\n",
      "\t\thardware, drivers, and, see, if, any, thing, is, there]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, mado, >, fahadsadah, ,, -, >, like, this, http://pastebin.ubuntu.com/335050/]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, fahadsadah, >, Yes, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 57 with text: \n",
      " \t\t[<, Razahn, >, I, hate, to, be, a, bother, ,, but, I, just, recently, installed, Windows, 7, and,\n",
      "\t\tUbuntu, 9.10, ., I, am, able, to, boot, to, both, operating, systems, flawlessly, ,, but, in, the,\n",
      "\t\tGRUB, menu, it, shows, Ubuntu, twice, ., Is, there, a, way, to, remove, the, two, un, -, needed,\n",
      "\t\tlistings, of, Ubuntu, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, fahadsadah, >, Save, ,, and, reboot, ,, and, you, wo, n't, see, the, problem, again, :)]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, mado, >, really, ?, fahadsadah]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, Linux, -, CLI, >, ctmjr, :, Nup, ,, nothing, found]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, mado, >, ok, ..., but, what, if, i, want, to, boot, another, kernel, ?, fahadsadah]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, mado, >, then, i, have, to, add, this, \", rootdelay=90, \", again, ..., have, n't, i, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, fahadsadah, >, Yes, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, mado, >, ok, ..., i, will, note, that, ..., just, a, sec]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 23 with text: \n",
      " \t\t[<, fahadsadah, >, Razahn, :, Please, install, the, package, \", startupmanager, \", in, the, Ubuntu,\n",
      "\t\tSoftware, Center, ,, then, go, to, System->Administration->Startup, Manager]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 23 with text: \n",
      " \t\t[<, mado, >, er, fahadsadah, ?, ..., do, i, also, have, to, add, \", rootdelay=90, \", to, the, \",\n",
      "\t\trecovery, mode, \", ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, zenlunatic, _, >, Linux, -, CLI, ,, sed, awk]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, Razahn, >, Thank, you, very, much, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, fahadsadah, >, mado, :, Not, really]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, fahadsadah, >, Because, recovery, mode, is, basically, that, shell, prompt, you, saw, there]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, Linux, -, CLI, >, But, awk, is, a, whole, programming, language, !]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 23 with text: \n",
      " \t\t[<, mado, >, uhuu, -, >, so, what, does, \", rootdelay=90, \", help, ?, fahadsadah, ..., ..., i, 'm,\n",
      "\t\ttrying, to, learn, more]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, fahadsadah, >, mado, :, It, waits, a, fixed, amount, of, time, for, your, drive]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, fahadsadah, >, I, think, it, 's, 2, seconds]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, fahadsadah, >, You, have, a, slow, drive]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, mado, >, a, slow, one, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, fahadsadah, >, So, it, will, wait, up, to, 90, seconds]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, fahadsadah, >, Actually, ,, a, slow, drive, controller]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, mado, >, are, you, talking, about, the, \", rpm, \", ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, mado, >, and, er, ..., can, i, do, something, about, the, slow, thing, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, mado, >, can, i, make, it, faster, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, TheCash, >, strwgr]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, Zilu54, >, active, out, there, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, MacMiller, >, hello]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, fahadsadah, >, mado, :, No, ,, just, initialisation, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, MacMiller, >, anyone, her, has, installed, kubuntu, on, a, dell, inspirom, 9400]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, mado, >, fahadsadah, ,, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, mado, >, i, ca, n't, save, the, correction]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, iceroot, >, !, anyone, |, MacMiller]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 40 with text: \n",
      " \t\t[<, ubottu, >, MacMiller, :, A, large, amount, of, the, first, questions, asked, in, this, channel,\n",
      "\t\tstart, with, \", Does, anyone, /, anybody, ..., \", Why, not, ask, your, next, question, (, the, real,\n",
      "\t\tone, ), and, find, out, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, mado, >, it, does, n't, let, me, fahadsadah]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, fahadsadah, >, Alt+F2, ,, and, type, ,, \", gksu, gedit, \"]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, mado, >, it, says, i, only, have, read, -, access]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, iceroot, >, mado, :, you, have, a, ubuntu, -, support, question, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, MacMiller, >, hmm]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, MacMiller, >, i, m, off]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, MacMiller, >, see, ya]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, fahadsadah, >, You, 'll, be, asked, for, a, password, ,, and, then, you, 'll, have, r, /, w,\n",
      "\t\taccess]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, mado, >, iceroot, ,, pardon, me, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, TheCash, >, my, comptuer, supports, 1280x1024(on, windows, that, is, what, I, used, ), but, i,\n",
      "\t\tcan, only, go, to, 1024x768]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, iceroot, >, mado, :, i, did, nt, tought, that, fahadsadah, is, a, name, ,, i, thought, your,\n",
      "\t\tkeyboard, is, broken, :)]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, constantine7, >, someone]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, constantine7, >, help, me]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, Linux, -, CLI, >, ctmjr, :, I, installed, mesa, -, common, -, dev]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, part, _, >, cpu[2, x, AMD, Phenom(tm, ), II, X2, 550, Processor, (, AuthenticAMD, ), @, 800MHz,\n",
      "\t\tw/, 512, KB, L2, Cache, ]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, constantine7, >, with, ubuntu]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, thevishy, >, tell, ur, problem, constantine7]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, thevishy, >, !, carriage]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, part, _, >, szent]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 37 with text: \n",
      " \t\t[<, mado, >, iceroot, ,, nope, :), ..., but, when, you, look, at, it, ..., is, \", mado, \", a, name,\n",
      "\t\t?, (, yes, it, is, just, four, letters, of, my, real, name, ), ..., ..., ...]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, iceroot, >, constantine7, :, not, possible, without, details, or, what, do, you, think, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, mado, >, fahadsadah, ,, it, still, does, n't, work]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, part, _, >, cpu[2, x, AMD, Phenom(tm, ), II, X2, 550, Processor, (, AuthenticAMD, ), @, 3.10GHz,\n",
      "\t\tw/, 512, KB, L2, Cache, ]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, constantine7, >, ok, i, ca, nt, see, me, password, in, the, terminal]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, iceroot, >, mado, :, but, did, nt, look, look, like, a, broken, keyboard]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, thevishy, >, nobody, can, see, password, in, terminal]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, iceroot, >, constantine7, :, that, s, normal]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, mado, >, ok, :)]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, bazhang, >, constantine7, ,, that, is, normal]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, Zilu54, >, constantine7, its, usual]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, constantine7, >, why]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, part, _, >, netdata[eth0, :, 184.6, MB, Recieved, ,, 26.8, MB, Sent, ]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, bazhang, >, security, constantine7]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, iceroot, >, constantine7, :, because, others, can, see, the, password, then, when, you, type,\n",
      "\t\tit, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, thevishy, >, yes, security]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, part, _, >, ether[Realtek, Semiconductor, Co., ,, Ltd., RTL8111/8168B, PCI, Express, Gigabit,\n",
      "\t\tEthernet, controller, ]]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, bazhang, >, part, _, ,, please, stop, that]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, Zilu54, >, just, type, your, password, then, push, enter, :)]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, part, _, >, okok]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, mado, >, how, come, i, ca, n't, save, the, correction, fahadsadah, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, mado, >, i, 'm, \", root, \", ..., are, n't, i, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, part, _, >, bazhang, then, where, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, iceroot, >, mado, :, with, gksudo, ,, yes]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, iceroot, >, !, paste, |, part, _]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 52 with text: \n",
      " \t\t[<, ubottu, >, part, _, :, For, posting, multi, -, line, texts, into, the, channel, ,, please, use,\n",
      "\t\thttp://paste.ubuntu.com, |, To, post, !, screenshots, use, http://tinyurl.com/imagebin, |, !,\n",
      "\t\tpastebinit, to, paste, directly, from, command, line, |, Make, sure, you, give, us, the, URL, for,\n",
      "\t\tyour, paste, -, see, also, the, channel, topic]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, bazhang, >, part, _, ,, was, there, a, question, with, that, ?, paste.ubuntu.com, if, so]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, lycan, >, have, yo, ever, use, fedora, ?, ?, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, mado, >, iceroot, ,, well, ..., looks, like, there, is, another, root, with, more, access, than,\n",
      "\t\tme, then, ...]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, iceroot, >, mado, :, no]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, mado, >, because, i, ca, n't, save, the, correction, in, the, file]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, Zilu54, >, i, have, a, question, /, help]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, iceroot, >, mado, :, to, what, file, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, bazhang, >, lycan, ,, try, #, ubuntu, -, offtopic, ,, here, is, Ubuntu, support, only]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, iceroot, >, !, ask, |, Zilu54]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 51 with text: \n",
      " \t\t[<, ubottu, >, Zilu54, :, Please, do, n't, ask, to, ask, a, question, ,, simply, ask, the, question,\n",
      "\t\t(, all, on, ONE, line, and, in, the, channel, ,, so, that, others, can, read, and, follow, it,\n",
      "\t\teasily, ), ., If, anyone, knows, the, answer, they, will, most, likely, reply, ., :-)]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, mado, >, iceroot, -, >, /boot, /, grub, /, grub.cfg]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, TheCash, >, my, comptuer, supports, 1280x1024(on, windows, that, is, what, I, used, ), but, i,\n",
      "\t\tcan, only, go, to, 1024x768]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, part, _, >, thanks, bazhang, iceroot, ubottu]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, Zilu54, >, how, can, i, add, gmail, notifier, on, my, docky, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, iceroot, >, mado, :, gksudo, gedit, /boot, /, grub, /, grub.cfg]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 4 with text: \n",
      " \t\t[<, kaushal, >, hi]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, Zilu54, >, i, m, currently, using, gnome, -, do]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, lycan, >, the, cash, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, mado, >, tried, it, already, ..., three, times, iceroot]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 5 with text: \n",
      " \t\t[<, TheCash, >, yes, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, iceroot, >, mado, :, and, the, error, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, iceroot, >, mado, :, using, a, live, -, cd, ?, is, it, mounted, with, rw, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 74 with text: \n",
      " \t\t[<, Il__Matteo, >, hi, everybody, !, i, 'm, on, ubuntu, 9.10, and, lamely, trying, \", chroot, \", in,\n",
      "\t\torder, to, make, Ubuntu, mobile, work, ., i, 'm, following, this, procedure, :,\n",
      "\t\thttp://paste.ubuntu.com/335055/plain/, ., but, ,, when, i, come, up, with, the, last, step, ,,\n",
      "\t\tconsole, writes, me, back, \", chroot, :, can, not, run, command, ', /bin, /, bash, ', ., No, such,\n",
      "\t\tfile, or, directory, \", ., Can, anybody, help, ,, please, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, lycan, >, do, u, have, ati, o, nvidia, graphics, card, ?]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 31 with text: \n",
      " \t\t[<, mado, >, i, have, to, add, -, >, \", rootedelay=90, \", after, \", linux, /boot, /, vmlinuz-2.6.31,\n",
      "\t\t-, 15-generic, root, =, UUID, =, b9212eb1, -, 5f4c-4dd6-add9-d85b791ee9fb, ro, quiet, splash, \"]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, bazhang, >, iceroot, ,, DO, NOT, EDIT, THIS, FILE]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \n",
      " \t arcs: AdjacencyField of length 500\n",
      "\t\twith indices:\n",
      " \t\t[(2, 2), (3, 2), (4, 4), (5, 3), (7, 3), (8, 3), (9, 7), (10, 8), (11, 7), (12, 0), (13, 10), (14,\n",
      "\t\t9), (15, 14), (16, 14), (17, 11), (18, 18), (19, 18), (20, 14), (21, 19), (22, 14), (23, 20), (24,\n",
      "\t\t22), (25, 21), (26, 24), (27, 20), (28, 28), (29, 29), (30, 16), (31, 28), (32, 32), (33, 24), (34,\n",
      "\t\t33), (35, 34), (36, 34), (37, 33), (38, 34), (39, 38), (40, 33), (41, 41), (42, 39), (43, 40), (44,\n",
      "\t\t42), (45, 43), (46, 34), (47, 43), (48, 28), (49, 31), (50, 50), (51, 49), (52, 52), (53, 49), (54,\n",
      "\t\t52), (55, 55), (56, 50), (57, 49), (58, 58), (59, 59), (61, 57), (62, 60), (63, 50), (64, 62), (65,\n",
      "\t\t65), (66, 63), (67, 63), (68, 66), (69, 66), (70, 67), (71, 67), (72, 70), (73, 62), (74, 69), (75,\n",
      "\t\t75), (76, 67), (77, 74), (78, 75), (79, 61), (80, 71), (81, 78), (82, 80), (83, 83), (84, 83), (85,\n",
      "\t\t84), (86, 85), (87, 86), (88, 75), (89, 81), (90, 86), (91, 77), (92, 86), (93, 86), (94, 93), (95,\n",
      "\t\t91), (96, 93), (97, 86), (98, 92), (99, 95), (100, 99), (101, 101), (102, 102), (103, 102), (104,\n",
      "\t\t95), (105, 98), (106, 105), (107, 106), (108, 104), (109, 108), (110, 107), (111, 80), (112, 110),\n",
      "\t\t(113, 109), (114, 112), (115, 111), (116, 115), (117, 114), (118, 118), (119, 116), (120, 120),\n",
      "\t\t(121, 120), (122, 113), (123, 113), (124, 123), (125, 123), (126, 125), (127, 124), (128, 117),\n",
      "\t\t(129, 127), (130, 125), (131, 128), (132, 129), (133, 129), (134, 134), (135, 128), (136, 133),\n",
      "\t\t(137, 135), (138, 134), (139, 138), (140, 140), (141, 137), (142, 141), (143, 143), (144, 143),\n",
      "\t\t(145, 143), (146, 143), (147, 145), (148, 148), (149, 147), (150, 150), (151, 147), (152, 146),\n",
      "\t\t(153, 148), (154, 151), (155, 150), (156, 156), (157, 156), (158, 143), (159, 159), (160, 152),\n",
      "\t\t(161, 161), (162, 155), (163, 163), (164, 162), (165, 161), (166, 160), (167, 163), (168, 138),\n",
      "\t\t(169, 167), (170, 165), (171, 156), (172, 172), (173, 170), (174, 171), (175, 175), (176, 173),\n",
      "\t\t(177, 175), (178, 178), (179, 179), (180, 176), (181, 142), (182, 179), (183, 181), (184, 182),\n",
      "\t\t(185, 184), (186, 178), (187, 166), (188, 187), (189, 189), (190, 190), (191, 190), (192, 190),\n",
      "\t\t(193, 193), (194, 182), (195, 194), (196, 190), (197, 194), (198, 192), (198, 191), (199, 193),\n",
      "\t\t(200, 198), (201, 193), (202, 199), (203, 203), (204, 193), (205, 171), (206, 201), (207, 206),\n",
      "\t\t(208, 208), (209, 203), (210, 150), (211, 209), (212, 206), (213, 205), (214, 212), (215, 215),\n",
      "\t\t(216, 211), (217, 213), (218, 206), (219, 216), (220, 214), (221, 206), (222, 222), (223, 203),\n",
      "\t\t(224, 220), (225, 223), (226, 220), (227, 226), (228, 225), (229, 222), (230, 230), (231, 231),\n",
      "\t\t(232, 226), (233, 230), (234, 231), (235, 234), (236, 232), (237, 235), (238, 238), (239, 232),\n",
      "\t\t(240, 239), (241, 229), (242, 238), (243, 239), (244, 244), (245, 245), (246, 245), (247, 242),\n",
      "\t\t(248, 241), (249, 232), (250, 247), (251, 249), (252, 233), (253, 250), (254, 251), (255, 255),\n",
      "\t\t(256, 253), (257, 254), (258, 257), (259, 252), (260, 255), (261, 258), (262, 260), (263, 259),\n",
      "\t\t(264, 210), (265, 264), (266, 264), (267, 257), (268, 262), (269, 263), (270, 268), (271, 267),\n",
      "\t\t(272, 272), (273, 264), (274, 269), (275, 271), (276, 274), (277, 274), (278, 276), (279, 278),\n",
      "\t\t(280, 280), (281, 279), (282, 273), (283, 283), (284, 284), (285, 279), (286, 285), (287, 285),\n",
      "\t\t(288, 282), (289, 19), (290, 284), (291, 290), (292, 292), (293, 289), (294, 292), (295, 294), (296,\n",
      "\t\t294), (297, 297), (298, 284), (299, 298), (300, 299), (301, 301), (302, 296), (303, 288), (304,\n",
      "\t\t301), (305, 296), (306, 304), (307, 306), (308, 289), (309, 308), (310, 298), (311, 309), (312,\n",
      "\t\t311), (313, 312), (314, 305), (315, 303), (316, 314), (317, 310), (318, 313), (319, 319), (320,\n",
      "\t\t318), (321, 314), (322, 306), (323, 322), (324, 317), (325, 318), (326, 320), (327, 326), (328,\n",
      "\t\t326), (329, 328), (330, 328), (331, 323), (332, 323), (333, 330), (334, 333), (335, 334), (336,\n",
      "\t\t315), (337, 335), (338, 337), (339, 331), (340, 335), (341, 332), (342, 342), (343, 340), (344,\n",
      "\t\t338), (345, 344), (346, 342), (347, 346), (348, 346), (348, 347), (349, 344), (350, 342), (351,\n",
      "\t\t341), (352, 350), (353, 349), (354, 352), (355, 350), (356, 332), (356, 351), (357, 353), (358,\n",
      "\t\t356), (359, 358), (360, 360), (361, 356), (362, 357), (363, 360), (364, 360), (365, 362), (366,\n",
      "\t\t365), (367, 360), (368, 336), (369, 342), (370, 367), (371, 366), (372, 367), (373, 372), (374,\n",
      "\t\t374), (375, 374), (376, 360), (377, 375), (378, 368), (379, 371), (380, 378), (381, 380), (382,\n",
      "\t\t379), (383, 369), (384, 380), (385, 379), (386, 383), (387, 385), (388, 383), (389, 388), (389,\n",
      "\t\t383), (390, 383), (391, 387), (392, 384), (393, 391), (394, 393), (395, 395), (396, 393), (397,\n",
      "\t\t396), (398, 392), (399, 396), (400, 399), (401, 400), (402, 401), (403, 395), (404, 402), (405,\n",
      "\t\t376), (406, 403), (407, 404), (408, 407), (409, 405), (410, 408), (411, 410), (412, 411), (413,\n",
      "\t\t412), (414, 413), (415, 414), (416, 415), (417, 416), (418, 417), (419, 418), (420, 420), (421,\n",
      "\t\t421), (422, 422), (423, 419), (424, 424), (425, 423), (426, 425), (427, 424), (428, 424), (428,\n",
      "\t\t427), (429, 426), (430, 429), (431, 430), (432, 431), (433, 433), (434, 433), (435, 434), (436,\n",
      "\t\t431), (437, 432), (438, 292), (439, 437), (440, 440), (441, 441), (442, 398), (443, 443), (444,\n",
      "\t\t441), (445, 444), (446, 446), (447, 447), (448, 439), (449, 444), (450, 430), (451, 443), (452,\n",
      "\t\t449), (453, 448), (454, 452), (455, 452), (456, 453), (457, 452), (458, 452), (459, 457), (459,\n",
      "\t\t458), (459, 454), (459, 455), (460, 451), (461, 459), (462, 459), (463, 459), (463, 461), (464,\n",
      "\t\t460), (465, 464), (466, 459), (467, 465), (468, 436), (469, 468), (470, 465), (471, 468), (472,\n",
      "\t\t470), (473, 472), (473, 470), (474, 470), (475, 475), (476, 471), (477, 476), (478, 476), (479,\n",
      "\t\t479), (480, 478), (481, 475), (482, 479), (483, 482), (483, 479), (484, 480), (485, 292), (486,\n",
      "\t\t472), (486, 473), (486, 474), (487, 487), (488, 484), (489, 489), (490, 487), (491, 485), (492,\n",
      "\t\t488), (493, 491), (494, 492), (495, 494), (496, 496), (497, 493), (498, 495), (499, 488)]\n",
      "\n",
      "\t\tand labels:\n",
      " \t\tNone\n",
      " \t\tin namespace: 'labels'. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "i0 = train_instances[0]\n",
    "print(i0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros: 0\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for n,i in enumerate(train_instances):\n",
    "    nbarcs = len(i[\"arcs\"].indices)\n",
    "    if nbarcs==0: \n",
    "        c+=1 \n",
    "        print(n)\n",
    "print(\"zeros:\",c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance max\n",
    "#for instance in train_instances:\n",
    "#    maxl = max([abs(j-i) for (i,j) in instance[\"arcs\"].indices])\n",
    "#    print(maxl)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "400000it [00:07, 53679.01it/s]\n"
     ]
    }
   ],
   "source": [
    "turn_encoder_cfg = Params({\"type\":\"gru\",'input_size': 300, 'hidden_size': 100, 'num_layers': 1,\n",
    "                  'dropout': 0.25, 'bidirectional': True\n",
    "})\n",
    "#can be changed dynamically encoder_cfg[\"type\"] = \"lstm\"\n",
    "# warning: if bidirectional, state output dimension is hidden_size x 2 -> model doesn't know that\n",
    "\n",
    "turn_encoder = Seq2VecEncoder.from_params(turn_encoder_cfg)\n",
    "turn_encoder.hidden_size = turn_encoder_cfg[\"hidden_size\"]\n",
    "\n",
    "\n",
    "chat_encoder_cfg = Params({\"type\":\"gru\",'input_size': 200, 'hidden_size': 100, 'num_layers': 2,\n",
    "                  'dropout': 0.25, 'bidirectional': False\n",
    "})\n",
    "chat_encoder = Seq2SeqEncoder.from_params(chat_encoder_cfg)\n",
    "chat_encoder.hidden_size = chat_encoder_cfg[\"hidden_size\"]\n",
    "\n",
    "\n",
    "\n",
    "glove_text_field_embedder = Embedding.from_params(vocab,Params({\"pretrained_file\": \"https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.300d.txt.gz\",\n",
    "                                                          \"embedding_dim\": 300,\n",
    "                                                          \"trainable\": False\n",
    "}))\n",
    "\n",
    "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "                            embedding_dim=300)\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chat_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from biaffine parser, another config (not used)\n",
    "chat_encoder_cfg =  Params({\n",
    "            \"type\": \"stacked_bidirectional_lstm\",\n",
    "            \"hidden_size\": 400,\n",
    "            \"input_size\": 200,\n",
    "            \"num_layers\": 3,\n",
    "            \"recurrent_dropout_probability\": 0.3,\n",
    "            \"use_highway\": True\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models import Model\n",
    "from typing import Dict, List, Iterable\n",
    "from allennlp.modules import TimeDistributed\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models import Model\n",
    "from allennlp.common.checks import check_dimensions_match, ConfigurationError\n",
    "from allennlp.data import Vocabulary\n",
    "from allennlp.modules import Seq2SeqEncoder, TextFieldEmbedder, Embedding, InputVariationalDropout\n",
    "from allennlp.modules.matrix_attention.bilinear_matrix_attention import BilinearMatrixAttention\n",
    "from allennlp.modules import FeedForward\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.nn import InitializerApplicator, Activation\n",
    "#???? TODO from allennlp.nn.util import min_value_of_dtype -> only allennlp >= 1.0\n",
    "def min_value_of_dtype(dtype: torch.dtype):\n",
    "    \"\"\"\n",
    "    Returns the minimum value of a given PyTorch data type. Does not allow torch.bool.\n",
    "    \"\"\"\n",
    "    return info_value_of_dtype(dtype).min\n",
    "def info_value_of_dtype(dtype: torch.dtype):\n",
    "    \"\"\"\n",
    "    Returns the `finfo` or `iinfo` object of a given PyTorch data type. Does not allow torch.bool.\n",
    "    \"\"\"\n",
    "    if dtype == torch.bool:\n",
    "        raise TypeError(\"Does not support torch.bool\")\n",
    "    elif dtype.is_floating_point:\n",
    "        return torch.finfo(dtype)\n",
    "    else:\n",
    "        return torch.iinfo(dtype)\n",
    "\n",
    "\n",
    "from allennlp.nn.util import get_text_field_mask\n",
    "from allennlp.nn.util import get_lengths_from_binary_sequence_mask\n",
    "from allennlp.training.metrics import F1Measure\n",
    "\n",
    "import copy\n",
    "from overrides import overrides\n",
    "import torch\n",
    "from torch.nn.modules import Dropout\n",
    "import numpy\n",
    "\n",
    "class ChatGraphParser(Model):\n",
    "    \"\"\"\n",
    "    A Parser for arbitrary graph structures.\n",
    "\n",
    "    Registered as a `Model` with name \"graph_parser\".\n",
    "\n",
    "    # Parameters\n",
    "\n",
    "    vocab : `Vocabulary`, required\n",
    "        A Vocabulary, required in order to compute sizes for input/output projections.\n",
    "    text_field_embedder : `TextFieldEmbedder`, required\n",
    "        Used to embed the `tokens` `TextField` we get as input to the model.\n",
    "    encoder : `Seq2SeqEncoder`\n",
    "        The encoder (with its own internal stacking) that we will use to generate representations\n",
    "        of tokens.\n",
    "    tag_representation_dim : `int`, required.\n",
    "        The dimension of the MLPs used for arc tag prediction.\n",
    "    arc_representation_dim : `int`, required.\n",
    "        The dimension of the MLPs used for arc prediction.\n",
    "    tag_feedforward : `FeedForward`, optional, (default = None).\n",
    "        The feedforward network used to produce tag representations.\n",
    "        By default, a 1 layer feedforward network with an elu activation is used.\n",
    "    arc_feedforward : `FeedForward`, optional, (default = None).\n",
    "        The feedforward network used to produce arc representations.\n",
    "        By default, a 1 layer feedforward network with an elu activation is used.\n",
    "    pos_tag_embedding : `Embedding`, optional.\n",
    "        Used to embed the `pos_tags` `SequenceLabelField` we get as input to the model.\n",
    "    dropout : `float`, optional, (default = 0.0)\n",
    "        The variational dropout applied to the output of the encoder and MLP layers.\n",
    "    input_dropout : `float`, optional, (default = 0.0)\n",
    "        The dropout applied to the embedded text input.\n",
    "    edge_prediction_threshold : `int`, optional (default = 0.5)\n",
    "        The probability at which to consider a scored edge to be 'present'\n",
    "        in the decoded graph. Must be between 0 and 1.\n",
    "    initializer : `InitializerApplicator`, optional (default=`InitializerApplicator()`)\n",
    "        Used to initialize the model parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab: Vocabulary,\n",
    "        text_field_embedder: TextFieldEmbedder,\n",
    "        turn_encoder: Seq2VecEncoder, \n",
    "        chat_encoder: Seq2SeqEncoder,\n",
    "        arc_representation_dim: int,\n",
    "        arc_feedforward: FeedForward = None,\n",
    "        dropout: float = 0.0,\n",
    "        input_dropout: float = 0.0,\n",
    "        edge_prediction_threshold: float = 0.5,\n",
    "        positive_class_weight = 40,\n",
    "        prediction_window = 13, # dont predict edge further apart\n",
    "        initializer: InitializerApplicator = InitializerApplicator(),\n",
    "        debug = False,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(vocab, **kwargs)\n",
    "        \n",
    "        self.text_field_embedder = text_field_embedder\n",
    "        self.turn_encoder = TimeDistributed(turn_encoder)\n",
    "        self.chat_encoder = chat_encoder\n",
    "        \n",
    "        self.edge_prediction_threshold = edge_prediction_threshold\n",
    "        if not 0 < edge_prediction_threshold < 1:\n",
    "            raise ConfigurationError(\n",
    "                f\"edge_prediction_threshold must be between \"\n",
    "                f\"0 and 1 (exclusive) but found {edge_prediction_threshold}.\"\n",
    "            )\n",
    "\n",
    "        encoder_dim = chat_encoder.get_output_dim()\n",
    "\n",
    "        self.head_arc_feedforward = arc_feedforward or FeedForward(\n",
    "            encoder_dim, 1, arc_representation_dim, Activation.by_name(\"elu\")()\n",
    "        )\n",
    "        self.child_arc_feedforward = copy.deepcopy(self.head_arc_feedforward)\n",
    "\n",
    "        self.arc_attention = BilinearMatrixAttention(\n",
    "            arc_representation_dim, arc_representation_dim, use_input_biases=True\n",
    "        )\n",
    "\n",
    "        self._dropout = InputVariationalDropout(dropout)\n",
    "        self._input_dropout = Dropout(input_dropout)\n",
    "\n",
    "        representation_dim = turn_encoder.get_output_dim()\n",
    "\n",
    "        self._unlabelled_f1 = F1Measure(positive_label=1)\n",
    "        #  with weight favoring recall of positive class \n",
    "        self._arc_loss = torch.nn.BCEWithLogitsLoss(reduction=\"none\",\n",
    "                                                    pos_weight=torch.tensor([positive_class_weight]))\n",
    "        \n",
    "        self.prediction_window = prediction_window\n",
    "        initializer(self)\n",
    "        # useful for debugging\n",
    "        self.iter_count = 0 \n",
    "        self.debug = debug\n",
    "    # init done\n",
    "        \n",
    "    # todo \n",
    "    @overrides\n",
    "    def forward(\n",
    "        self,  # type: ignore\n",
    "        lines,\n",
    "        arcs: torch.LongTensor = None,\n",
    "        metadata: List[Dict[str, Any]] = None,\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "\n",
    "        \"\"\"\n",
    "        # Parameters\n",
    "\n",
    "        lines: the chat as a list of turns, each being a list of token\n",
    "        TODO: add metadata to instances\n",
    "        metadata : List[Dict[str, Any]], optional (default = None)\n",
    "            A dictionary of metadata for each batch element which has keys:\n",
    "                tokens : `List[str]`, required.\n",
    "                    The original string tokens in the sentence.\n",
    "        arcs : a tensor containing the adjacency matrix for the instance dependencies between turns\n",
    "            Has shape `(batch_size, sequence_length, sequence_length)`.\n",
    "\n",
    "        # Returns\n",
    "\n",
    "        An output dictionary.\n",
    "        \"\"\"\n",
    "        #########\n",
    "        # this is the part where chat is encoded as sequence of turn encodings\n",
    "        #########\n",
    "        # mask for each turn of each chat of the batch: shape = (batch_size x max_turns x tokens)\n",
    "        token_mask = get_text_field_mask(lines,num_wrapping_dims=1)\n",
    "\n",
    "        # chat turns fetching embedding\n",
    "        # turns_embedding tensor is (batch_size x turns x max tokens x token embedding size)\n",
    "        turns_embeddings = self.text_field_embedder(lines,num_wrapping_dims=1)\n",
    "      \n",
    "        # encoding turns\n",
    "        # turn_h has shape (batch_size x turns x encoder_output_size) \n",
    "        turn_h = self.turn_encoder(turns_embeddings,token_mask)\n",
    "        \n",
    "        # mask for chats is now nb of turns; beware weird return type of torch.max (tuple) \n",
    "        chat_mask = token_mask.max(axis=2)[0]\n",
    "        \n",
    "        # renaming to mask -> easier to transpose the rest of graph_parser\n",
    "        mask = chat_mask\n",
    "        \n",
    "        # graph parser goes on\n",
    "        # leave input dropout for now\n",
    "        # embedded_text_input = turn_h equivalent in hierarchical sequence -> renaming \n",
    "        #embedded_text_input = self._input_dropout(embedded_text_input)\n",
    "        embedded_text_input = turn_h\n",
    "        # we keep graph parser original name for now\n",
    "        # encoded_text = encoded chat = self.chat_encoder(turn_h,chat_mask) equivalent in hierarchical sequence\n",
    "        encoded_text = self.chat_encoder(embedded_text_input, mask)\n",
    "\n",
    "        encoded_text = self._dropout(encoded_text)\n",
    "\n",
    "        # shape (batch_size, sequence_length, arc_representation_dim)\n",
    "        head_arc_representation = self._dropout(self.head_arc_feedforward(encoded_text))\n",
    "        child_arc_representation = self._dropout(self.child_arc_feedforward(encoded_text))\n",
    "\n",
    "        # shape (batch_size, sequence_length, tag_representation_dim)\n",
    "        #head_tag_representation = self._dropout(self.head_tag_feedforward(encoded_text))\n",
    "        #child_tag_representation = self._dropout(self.child_tag_feedforward(encoded_text))\n",
    "        \n",
    "        # shape (batch_size, sequence_length, sequence_length)\n",
    "        arc_scores = self.arc_attention(head_arc_representation, child_arc_representation)\n",
    "        \n",
    "        # shape (batch_size, num_tags, sequence_length, sequence_length)\n",
    "        #arc_tag_logits = self.tag_bilinear(head_tag_representation, child_tag_representation)\n",
    "        # Switch to (batch_size, sequence_length, sequence_length, num_tags)\n",
    "        #arc_tag_logits = arc_tag_logits.permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "        # Since we'll be doing some additions, using the min value will cause underflow\n",
    "        # CHAT: unncessary since we dont have a loss for labels\n",
    "        #minus_mask = ~mask * min_value_of_dtype(arc_scores.dtype) / 10\n",
    "        #arc_scores = arc_scores + minus_mask.unsqueeze(2) + minus_mask.unsqueeze(1)\n",
    "\n",
    "        self.iter_count += 1\n",
    "        # Debugging every 10 epochs\n",
    "        if self.debug and self.iter_count%(153*2)==0:\n",
    "            breakpoint()\n",
    "            \n",
    "        arc_probs = self._greedy_decode(arc_scores, mask,self.prediction_window)\n",
    "\n",
    "        output_dict = {\"arc_probs\": arc_probs, \"mask\": mask}\n",
    "\n",
    "        if metadata:\n",
    "            output_dict[\"tokens\"] = [meta[\"tokens\"] for meta in metadata]\n",
    "\n",
    "        arc_tags = arcs # gold labels -> here just the adjacency matrix 0/1 ? \n",
    "        if arc_tags is not None:\n",
    "            arc_nll= self._construct_loss(\n",
    "                arc_scores=arc_scores, arc_tags=arc_tags, mask=mask\n",
    "            )\n",
    "            # same here with no arc relations ; keep all anyway to prevent ubgs downstream (TODO: coherent renaming)\n",
    "            output_dict[\"loss\"] = arc_nll \n",
    "            output_dict[\"arc_loss\"] = arc_nll\n",
    "            \n",
    "\n",
    "            # Make the arc tags not have negative values anywhere\n",
    "            # (by default, no edge is indicated with -1).\n",
    "            # NB re chat: probably not useful, but kept as a precaution\n",
    "            arc_indices = (arc_tags != -1).float()\n",
    "            tag_mask = mask.unsqueeze(1) & mask.unsqueeze(2)\n",
    "            one_minus_arc_probs = 1 - arc_probs\n",
    "            # We stack scores here because the f1 measure expects a\n",
    "            # distribution, rather than a single value.\n",
    "            self._unlabelled_f1(\n",
    "                torch.stack([one_minus_arc_probs, arc_probs], -1), arc_indices, tag_mask\n",
    "            )\n",
    "        \n",
    "        \n",
    "        return output_dict\n",
    "    # modified / untested\n",
    "    \n",
    "    def _construct_loss(\n",
    "        self,\n",
    "        arc_scores: torch.Tensor,\n",
    "        arc_tags: torch.Tensor,\n",
    "        mask: torch.BoolTensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Computes the arc and tag loss for an adjacency matrix.\n",
    "\n",
    "        # Parameters\n",
    "\n",
    "        arc_scores : `torch.Tensor`, required.\n",
    "            A tensor of shape (batch_size, sequence_length, sequence_length) used to generate a\n",
    "            binary classification decision for whether an edge is present between two words.\n",
    "        #####arc_tag_logits : `torch.Tensor`, required.\n",
    "        #####    A tensor of shape (batch_size, sequence_length, sequence_length, num_tags) used to generate\n",
    "        #####    a distribution over edge tags for a given edge.\n",
    "        arc_tags : `torch.Tensor`, required.\n",
    "            A tensor of shape (batch_size, sequence_length, sequence_length).\n",
    "            The labels for every arc.\n",
    "        mask : `torch.BoolTensor`, required.\n",
    "            A mask of shape (batch_size, sequence_length), denoting unpadded\n",
    "            elements in the sequence.\n",
    "\n",
    "        # Returns\n",
    "\n",
    "        arc_nll : `torch.Tensor`, required.\n",
    "            The negative log likelihood from the arc loss.\n",
    "        tag_nll : `torch.Tensor`, required.\n",
    "            The negative log likelihood from the arc tag loss.\n",
    "        \"\"\"\n",
    "        arc_indices = (arc_tags != -1).float()\n",
    "        # Make the arc tags not have negative values anywhere\n",
    "        # (by default, no edge is indicated with -1).\n",
    "        arc_tags = arc_tags * arc_indices\n",
    "        arc_nll = self._arc_loss(arc_scores, arc_indices) * mask.unsqueeze(1) * mask.unsqueeze(2)\n",
    "        # We want the mask for the tags to only include the unmasked words\n",
    "        # and we only care about the loss with respect to the gold arcs.\n",
    "        tag_mask = mask.unsqueeze(1) * mask.unsqueeze(2) * arc_indices\n",
    "\n",
    "        #batch_size, sequence_length, _, num_tags = arc_tag_logits.size()\n",
    "        #original_shape = [batch_size, sequence_length, sequence_length]\n",
    "        #reshaped_logits = arc_tag_logits.view(-1, num_tags)\n",
    "        reshaped_tags = arc_tags.view(-1)\n",
    "        #tag_nll = (\n",
    "        #    self._tag_loss(reshaped_logits, reshaped_tags.long()).view(original_shape) * tag_mask\n",
    "        #)\n",
    "\n",
    "        valid_positions = tag_mask.sum()\n",
    "\n",
    "        arc_nll = arc_nll.sum() / valid_positions.float()\n",
    "        #tag_nll = tag_nll.sum() / valid_positions.float()\n",
    "        return arc_nll#, tag_nll\n",
    "    # modified/untested\n",
    "\n",
    "    @staticmethod\n",
    "    def _greedy_decode(\n",
    "        arc_scores: torch.Tensor, \n",
    "        mask: torch.BoolTensor,\n",
    "        prediction_window: int,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Decodes the head and head tag predictions by decoding the unlabeled arcs\n",
    "        independently for each word and then again, predicting the head tags of\n",
    "        these greedily chosen arcs independently.\n",
    "\n",
    "        # Parameters\n",
    "\n",
    "        arc_scores : `torch.Tensor`, required.\n",
    "            A tensor of shape (batch_size, sequence_length, sequence_length) used to generate\n",
    "            a distribution over attachments of a given word to all other words.\n",
    "        ###arc_tag_logits : `torch.Tensor`, required.\n",
    "        ###    A tensor of shape (batch_size, sequence_length, sequence_length, num_tags) used to\n",
    "        ###    generate a distribution over tags for each arc.\n",
    "        mask : `torch.BoolTensor`, required.\n",
    "            A mask of shape (batch_size, sequence_length).\n",
    "\n",
    "        # Returns\n",
    "\n",
    "        arc_probs : `torch.Tensor`\n",
    "            A tensor of shape (batch_size, sequence_length, sequence_length) representing the\n",
    "            probability of an arc being present for this edge.\n",
    "        ####arc_tag_probs : `torch.Tensor`\n",
    "        ####    A tensor of shape (batch_size, sequence_length, sequence_length, sequence_length)\n",
    "        ####    representing the distribution over edge tags for a given edge.\n",
    "        \"\"\"\n",
    "        # Mask the diagonal, because we don't self edges.\n",
    "        # WARNING: might not be the case for chats ? -> should be an option\n",
    "        inf_diagonal_mask = torch.diag(arc_scores.new(mask.size(1)).fill_(-numpy.inf))\n",
    "        # no edges going backwards\n",
    "        triangle_upper_mask = torch.triu(arc_scores.new(mask.size(1),mask.size(1)).fill_(-numpy.inf))\n",
    "        # prevent edges between turns more than CONSTANT turns appart\n",
    "        up = 1-torch.triu(arc_scores.new(mask.size(1),mask.size(1)).fill_(1),diagonal=prediction_window)\n",
    "        down = 1-torch.tril(arc_scores.new(mask.size(1),mask.size(1)).fill_(1),diagonal=-prediction_window)\n",
    "        diag_mask = numpy.log(((up+down)-1))\n",
    "        # up_mask = torch.triu(arc_scores.new_zeros(mask.size(1),mask.size(1),diagonal=-15)\n",
    "        # down_mask = torch.tril(arc_scores.new_zeros(mask.size(1),mask.size(1),diagonal=15)\n",
    "        # away_mask = (up_mask == down_mask)\n",
    "        arc_scores = arc_scores + inf_diagonal_mask + diag_mask + triangle_upper_mask\n",
    "        # shape (batch_size, sequence_length, sequence_length, num_tags)\n",
    "        #arc_tag_logits = arc_tag_logits + inf_diagonal_mask.unsqueeze(0).unsqueeze(-1)\n",
    "        # Mask padded tokens, because we only want to consider actual word -> word edges.\n",
    "        # CHAT: this is the wrong torch version lol this does not work/ confusion int/bools\n",
    "        # minus_mask = ~mask.unsqueeze(2)\n",
    "        # CHAT: this should work with torch>1.4\n",
    "        #minus_mask = (mask<1).unsqueeze(2)\n",
    "        minus_mask = (mask.unsqueeze(1) & mask.unsqueeze(2))<1\n",
    "        \n",
    "        arc_scores.masked_fill_(minus_mask, -numpy.inf)\n",
    "        # \n",
    "        \n",
    "        #arc_tag_logits.masked_fill_(minus_mask.unsqueeze(-1), -numpy.inf)\n",
    "        # shape (batch_size, sequence_length, sequence_length)\n",
    "        arc_probs = arc_scores.sigmoid()\n",
    "        # shape (batch_size, sequence_length, sequence_length, num_tags)\n",
    "        #arc_tag_probs = torch.nn.functional.softmax(arc_tag_logits, dim=-1)\n",
    "        return arc_probs#, arc_tag_probs\n",
    "    # modified / untested\n",
    "    \n",
    "    @overrides\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        metrics = {}\n",
    "        precision, recall, f1_measure = self._unlabelled_f1.get_metric(reset)\n",
    "        metrics[\"precision\"] = precision\n",
    "        metrics[\"recall\"] = recall\n",
    "        metrics[\"f1\"] = f1_measure\n",
    "        return metrics\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = HierarchicalChatSequenceClassification(vocab,word_embeddings,turn_encoder,chat_encoder)\n",
    "\n",
    "if False:\n",
    "    reader = ChatReader(\n",
    "        tokenizer=tokenizer,\n",
    "        token_indexers=token_indexers,\n",
    "        raw = True,\n",
    "        #sample = 50, \n",
    "        #clip = 200\n",
    "        )\n",
    "    train_instances = reader.read(\"../data/train\")\n",
    "    vocab = Vocabulary.from_instances(train_instances)\n",
    "\n",
    "\n",
    "arc_representation_dim = 50 \n",
    "model = ChatGraphParser(vocab,word_embeddings,\n",
    "                        turn_encoder,chat_encoder,arc_representation_dim,\n",
    "                        prediction_window = 2,\n",
    "                        positive_class_weight = 1000,\n",
    "                        debug=True,\n",
    "                        edge_prediction_threshold=0.5)\n",
    "\n",
    "\n",
    "from allennlp.training.optimizers import Optimizer \n",
    "trainer_cfg = Params({\n",
    "        \"cuda_device\": 1,\n",
    "        \"grad_norm\": 5,\n",
    "        \"num_epochs\": 100,\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"dense_sparse_adam\",\n",
    "            \"betas\": [\n",
    "                0.9,\n",
    "                0.9\n",
    "            ]\n",
    "        },\n",
    "        \"patience\": 50,\n",
    "})\n",
    "opt_cfg = trainer_cfg.pop(\"optimizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# not tested\n",
    "#optimizer = Optimizer.from_params(model_parameters=model.parameters(),\n",
    "#                                  params=opt_cfg)\n",
    "\n",
    "iterator = BucketIterator(batch_size=4,\n",
    "                          sorting_keys=[(\"lines\",\"list_num_tokens\")])\n",
    "iterator.index_with(vocab)\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  optimizer=optimizer,\n",
    "                  iterator=iterator,\n",
    "                  num_epochs=100,\n",
    "                  grad_norm=5,\n",
    "                  patience=10,\n",
    "                  cuda_device = -1,\n",
    "                  train_dataset=train_instances,\n",
    "                  validation_dataset=dev_instances,\n",
    "                  should_log_parameter_statistics = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1860, recall: 0.1742, f1: 0.1799, loss: 958.1749 ||: 100%|██████████| 39/39 [02:06<00:00,  2.28s/it] \n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1824, f1: 0.1842, loss: 935.6593 ||: 100%|██████████| 39/39 [02:01<00:00,  3.14s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1824, f1: 0.1842, loss: 931.8195 ||: 100%|██████████| 39/39 [02:01<00:00,  2.74s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1824, f1: 0.1842, loss: 943.0659 ||: 100%|██████████| 39/39 [01:58<00:00,  2.72s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1824, f1: 0.1842, loss: 930.5951 ||: 100%|██████████| 39/39 [01:55<00:00,  2.54s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1824, f1: 0.1842, loss: 932.5371 ||: 100%|██████████| 39/39 [01:55<00:00,  3.12s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1824, f1: 0.1842, loss: 928.1766 ||: 100%|██████████| 39/39 [01:58<00:00,  2.03s/it] \n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1891, recall: 0.1851, f1: 0.1870, loss: 914.6318 ||:  82%|████████▏ | 32/39 [01:39<00:22,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-14-6a0c67557269>(215)forward()\n",
      "-> arc_probs = self._greedy_decode(arc_scores, mask,self.prediction_window)\n",
      "(Pdb) arc_probs\n",
      "*** NameError: name 'arc_probs' is not defined\n",
      "(Pdb) next\n",
      "> <ipython-input-14-6a0c67557269>(217)forward()\n",
      "-> output_dict = {\"arc_probs\": arc_probs, \"mask\": mask}\n",
      "(Pdb) arc_probs\n",
      "tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.6122, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6327, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.6232, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6430, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.6570, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6466, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.6495, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.7078, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.6280, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.7202, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "(Pdb) arc_probs>0.5\n",
      "tensor([[[False, False, False,  ..., False, False, False],\n",
      "         [ True, False, False,  ..., False, False, False],\n",
      "         [False,  True, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [ True, False, False,  ..., False, False, False],\n",
      "         [False,  True, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [ True, False, False,  ..., False, False, False],\n",
      "         [False,  True, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ...,  True, False, False],\n",
      "         [False, False, False,  ..., False,  True, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [ True, False, False,  ..., False, False, False],\n",
      "         [False,  True, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]]])\n",
      "(Pdb) (arc_probs>0.5).sum()\n",
      "tensor(2159)\n",
      "(Pdb) (arc_probs>0.4).sum()\n",
      "tensor(2168)\n",
      "(Pdb) (arc_probs>0.2).sum()\n",
      "tensor(2168)\n",
      "(Pdb) arc_probs.size()\n",
      "torch.Size([4, 673, 673])\n",
      "(Pdb) 2168/8\n",
      "271.0\n",
      "(Pdb) (arc_probs[0]>0.5).sum()\n",
      "tensor(499)\n",
      "(Pdb) (arc_probs[0]>0.2).sum()\n",
      "tensor(499)\n",
      "(Pdb) (arc_probs[0]>0.75).sum()\n",
      "tensor(116)\n",
      "(Pdb) (arc_probs[0]>0.65).sum()\n",
      "tensor(350)\n",
      "(Pdb) (arc_probs[0]>0.55).sum()\n",
      "tensor(490)\n",
      "(Pdb) arc\n",
      "*** NameError: name 'arc' is not defined\n",
      "(Pdb) arc_tags\n",
      "*** NameError: name 'arc_tags' is not defined\n",
      "(Pdb) arcs\n",
      "tensor([[[ 1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1.,  1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[ 1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1.,  1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [ 1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]])\n",
      "(Pdb) arcs[0]>1\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "(Pdb) (arcs[0]>0).sum()\n",
      "tensor(514)\n",
      "(Pdb) arcs[0].tril(k=2)\n",
      "*** TypeError: tril() got an unexpected keyword argument 'k'\n",
      "(Pdb) arcs[0].tril()\n",
      "tensor([[ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [-1., -1.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [-1.,  1., -1.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [-1., -1., -1.,  ..., -1.,  0.,  0.],\n",
      "        [-1., -1., -1.,  ..., -1., -1.,  0.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n",
      "(Pdb) arcs[0].tril(2)\n",
      "tensor([[ 1., -1., -1.,  ...,  0.,  0.,  0.],\n",
      "        [-1., -1., -1.,  ...,  0.,  0.,  0.],\n",
      "        [-1.,  1., -1.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n",
      "(Pdb) arcs[0].tril(-2)\n",
      "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [-1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [-1., -1., -1.,  ...,  0.,  0.,  0.],\n",
      "        [-1., -1., -1.,  ...,  0.,  0.,  0.],\n",
      "        [-1., -1., -1.,  ..., -1.,  0.,  0.]])\n",
      "(Pdb) arcs[0].tril()\n",
      "tensor([[ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [-1., -1.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [-1.,  1., -1.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [-1., -1., -1.,  ..., -1.,  0.,  0.],\n",
      "        [-1., -1., -1.,  ..., -1., -1.,  0.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n",
      "(Pdb) continue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision: 0.1865, recall: 0.1823, f1: 0.1844, loss: 913.5578 ||: 100%|██████████| 39/39 [07:44<00:00, 14.96s/it] \n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1880, recall: 0.1818, f1: 0.1848, loss: 884.4699 ||: 100%|██████████| 39/39 [01:59<00:00,  4.24s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1873, recall: 0.1820, f1: 0.1846, loss: 861.3255 ||: 100%|██████████| 39/39 [02:01<00:00,  4.17s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1887, recall: 0.1815, f1: 0.1850, loss: 826.0029 ||: 100%|██████████| 39/39 [02:00<00:00,  2.57s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1889, recall: 0.1813, f1: 0.1850, loss: 771.8855 ||: 100%|██████████| 39/39 [01:56<00:00,  2.83s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1876, recall: 0.1818, f1: 0.1846, loss: 692.9313 ||: 100%|██████████| 39/39 [01:55<00:00,  2.62s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1866, recall: 0.1823, f1: 0.1844, loss: 621.4472 ||: 100%|██████████| 39/39 [02:01<00:00,  2.91s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1865, recall: 0.1823, f1: 0.1843, loss: 578.2503 ||: 100%|██████████| 39/39 [01:57<00:00,  3.03s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1840, recall: 0.1795, f1: 0.1817, loss: 554.1026 ||:  67%|██████▋   | 26/39 [01:22<00:40,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-14-6a0c67557269>(215)forward()\n",
      "-> arc_probs = self._greedy_decode(arc_scores, mask,self.prediction_window)\n",
      "(Pdb) self.debug=False\n",
      "(Pdb) continue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision: 0.1865, recall: 0.1822, f1: 0.1843, loss: 542.6287 ||: 100%|██████████| 39/39 [10:51<00:00,  5.20s/it] \n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1866, recall: 0.1822, f1: 0.1844, loss: 507.5445 ||: 100%|██████████| 39/39 [01:55<00:00,  3.25s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1864, recall: 0.1821, f1: 0.1842, loss: 468.3121 ||: 100%|██████████| 39/39 [01:58<00:00,  3.45s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1819, f1: 0.1840, loss: 432.5802 ||: 100%|██████████| 39/39 [01:57<00:00,  3.42s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1819, f1: 0.1840, loss: 408.4536 ||: 100%|██████████| 39/39 [02:00<00:00,  3.58s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1820, f1: 0.1841, loss: 395.3875 ||: 100%|██████████| 39/39 [01:58<00:00,  3.33s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1822, f1: 0.1842, loss: 378.2964 ||: 100%|██████████| 39/39 [01:55<00:00,  3.02s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1822, f1: 0.1841, loss: 361.5381 ||: 100%|██████████| 39/39 [01:59<00:00,  2.46s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1822, f1: 0.1841, loss: 352.9671 ||: 100%|██████████| 39/39 [01:53<00:00,  2.54s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1821, f1: 0.1841, loss: 343.3297 ||: 100%|██████████| 39/39 [01:59<00:00,  3.03s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1822, f1: 0.1841, loss: 336.3261 ||: 100%|██████████| 39/39 [01:59<00:00,  2.72s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1822, f1: 0.1841, loss: 325.0188 ||: 100%|██████████| 39/39 [02:00<00:00,  2.98s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1822, f1: 0.1841, loss: 313.4986 ||: 100%|██████████| 39/39 [01:57<00:00,  2.86s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1822, f1: 0.1842, loss: 306.9440 ||: 100%|██████████| 39/39 [01:58<00:00,  3.06s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1822, f1: 0.1841, loss: 306.9312 ||: 100%|██████████| 39/39 [01:55<00:00,  2.43s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1822, f1: 0.1842, loss: 296.4856 ||: 100%|██████████| 39/39 [01:54<00:00,  2.96s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1822, f1: 0.1842, loss: 295.0990 ||: 100%|██████████| 39/39 [02:01<00:00,  3.06s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1821, f1: 0.1841, loss: 287.6496 ||: 100%|██████████| 39/39 [01:58<00:00,  2.52s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1823, f1: 0.1842, loss: 285.0249 ||: 100%|██████████| 39/39 [01:59<00:00,  2.52s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1822, f1: 0.1841, loss: 282.4739 ||: 100%|██████████| 39/39 [02:00<00:00,  3.16s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1822, f1: 0.1842, loss: 273.8928 ||: 100%|██████████| 39/39 [01:56<00:00,  2.82s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 270.6733 ||: 100%|██████████| 39/39 [02:00<00:00,  3.38s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 264.1252 ||: 100%|██████████| 39/39 [01:57<00:00,  2.88s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 261.6814 ||: 100%|██████████| 39/39 [01:56<00:00,  2.29s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1823, f1: 0.1842, loss: 257.9012 ||: 100%|██████████| 39/39 [02:02<00:00,  3.85s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 249.3843 ||: 100%|██████████| 39/39 [01:55<00:00,  2.62s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1861, recall: 0.1822, f1: 0.1842, loss: 252.0233 ||: 100%|██████████| 39/39 [01:56<00:00,  2.80s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 246.7062 ||: 100%|██████████| 39/39 [01:56<00:00,  2.55s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 246.6451 ||: 100%|██████████| 39/39 [02:01<00:00,  2.43s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 238.9331 ||: 100%|██████████| 39/39 [01:56<00:00,  3.18s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 239.6788 ||: 100%|██████████| 39/39 [01:57<00:00,  2.53s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 236.3571 ||: 100%|██████████| 39/39 [01:58<00:00,  2.92s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 230.3367 ||: 100%|██████████| 39/39 [01:55<00:00,  3.95s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 232.7720 ||: 100%|██████████| 39/39 [01:57<00:00,  2.87s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 223.5491 ||: 100%|██████████| 39/39 [01:57<00:00,  3.03s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 229.5669 ||: 100%|██████████| 39/39 [01:56<00:00,  3.12s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 218.4992 ||: 100%|██████████| 39/39 [01:59<00:00,  3.07s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 217.9892 ||: 100%|██████████| 39/39 [01:57<00:00,  2.33s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 212.1679 ||: 100%|██████████| 39/39 [02:01<00:00,  3.23s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 216.4585 ||: 100%|██████████| 39/39 [01:59<00:00,  2.50s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 212.1155 ||: 100%|██████████| 39/39 [01:57<00:00,  2.52s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 211.6754 ||: 100%|██████████| 39/39 [01:55<00:00,  2.47s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 210.4368 ||: 100%|██████████| 39/39 [01:57<00:00,  1.97s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 204.5564 ||: 100%|██████████| 39/39 [01:58<00:00,  2.16s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 206.1807 ||: 100%|██████████| 39/39 [02:00<00:00,  2.88s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 199.6610 ||: 100%|██████████| 39/39 [02:00<00:00,  2.49s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1843, loss: 198.3338 ||: 100%|██████████| 39/39 [01:57<00:00,  2.96s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1843, loss: 196.7794 ||: 100%|██████████| 39/39 [02:00<00:00,  4.41s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1843, loss: 195.5404 ||: 100%|██████████| 39/39 [01:59<00:00,  3.16s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 193.2120 ||: 100%|██████████| 39/39 [01:56<00:00,  2.27s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 191.5742 ||: 100%|██████████| 39/39 [02:02<00:00,  3.67s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 188.6342 ||: 100%|██████████| 39/39 [01:56<00:00,  3.79s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1862, recall: 0.1823, f1: 0.1842, loss: 189.9129 ||: 100%|██████████| 39/39 [01:58<00:00,  2.75s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]/home/muller/miniconda3/envs/allennlp2/lib/python3.7/site-packages/ipykernel_launcher.py:342: RuntimeWarning: divide by zero encountered in log\n",
      "precision: 0.1686, recall: 0.1635, f1: 0.1660, loss: 211.5035 ||:   8%|▊         | 3/39 [00:11<02:05,  3.49s/it]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([0.1,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor([[1, 1, 1, 0],\n",
    "        [1, 1, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = numpy.inf \n",
    "arc_scores = torch.tensor([[[  -inf, 0.1252, 0.1161, 0.0475],\n",
    "         [0.0977,   -inf, 0.1015, 0.0373],\n",
    "         [0.1541, 0.1673,   -inf, 0.0934],\n",
    "         [0.0563, 0.0730, 0.0623,   -inf]],\n",
    "\n",
    "        [[  -inf, 0.0947, 0.1048, 0.1114],\n",
    "         [0.1385,   -inf, 0.1681, 0.1755],\n",
    "         [0.1114, 0.1310,   -inf, 0.1448],\n",
    "         [0.1274, 0.1454, 0.1537,   -inf]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_mask = (mask<1).unsqueeze(2)    \n",
    "arc_scores.masked_fill_(minus_mask, -numpy.inf)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_probs = arc_scores.sigmoid()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_mask = (mask.unsqueeze(1) & mask.unsqueeze(2))<1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_scores.masked_fill_(minus_mask, -numpy.inf)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mask<1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
