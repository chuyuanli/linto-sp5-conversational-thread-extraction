{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "\n",
    "I) version base\n",
    "- (done)  reprendre classifieur de chat hiérarchique, remplacer encodeur seq2vec par un seq2seq (stacked lstm eg)\n",
    "    cf HierarchicalChatSequenceClassification\n",
    "- (done)  ajouter séquence de labels / comme si arbre ou forêt (possible ds graph_parser ?)\n",
    "\n",
    "- (done) sousclasser graph_parser / modifs\n",
    "    [pas la peine] plus facile en forcant label unique sur les arcs ? à voir\n",
    "- (done/untested) brancher données réelles\n",
    "      \n",
    "      \n",
    "/home/muller/anaconda3/envs/allennlp/lib/python3.7/site-packages/allennlp/data/dataset_readers/semantic_dependency_parsing.py\n",
    "\n",
    "\n",
    "améliorations: \n",
    "- encodeur tour -> bert\n",
    "- preprocessing des chats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import logging\n",
    "from typing import Any, Tuple, Dict, List, Iterable\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
    "from allennlp.data.fields import Field, LabelField, TextField, ListField, SequenceLabelField\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token, Tokenizer, WordTokenizer, PretrainedTransformerTokenizer\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "\n",
    "from allennlp.modules import Seq2VecEncoder, Seq2SeqEncoder\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "\n",
    "from allennlp.training.trainer import Trainer\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.common import Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from dummy_chat_reader import ChatReader\n",
    "from irc_chat_reader import ChatReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "153it [00:13, 10.94it/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 175.90it/s]\n"
     ]
    }
   ],
   "source": [
    "token_indexers = {\"tokens\": SingleIdTokenIndexer()}\n",
    "\n",
    "tokenizer_cfg = Params({\"word_splitter\": {\"language\": \"en\"}})\n",
    "\n",
    "tokenizer = Tokenizer.from_params(tokenizer_cfg)\n",
    "\n",
    "\n",
    "reader = ChatReader(\n",
    "    tokenizer=tokenizer,\n",
    "    token_indexers=token_indexers,\n",
    "    raw = False,\n",
    "    sample = 2, \n",
    "    clip = 30\n",
    "    )\n",
    "train_instances = reader.read(\"../data/train\")\n",
    "vocab = Vocabulary.from_instances(train_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_fields': 505, 'list_num_tokens': 100, 'list_tokens_length': 100}\n",
      "{'num_fields': 504, 'list_num_tokens': 81, 'list_tokens_length': 81}\n",
      "{'num_fields': 502, 'list_num_tokens': 79, 'list_tokens_length': 79}\n",
      "{'num_fields': 532, 'list_num_tokens': 109, 'list_tokens_length': 109}\n",
      "{'num_fields': 500, 'list_num_tokens': 102, 'list_tokens_length': 102}\n",
      "{'num_fields': 546, 'list_num_tokens': 107, 'list_tokens_length': 107}\n",
      "{'num_fields': 116, 'list_num_tokens': 95, 'list_tokens_length': 95}\n",
      "{'num_fields': 502, 'list_num_tokens': 94, 'list_tokens_length': 94}\n",
      "{'num_fields': 539, 'list_num_tokens': 104, 'list_tokens_length': 104}\n",
      "{'num_fields': 504, 'list_num_tokens': 96, 'list_tokens_length': 96}\n",
      "{'num_fields': 505, 'list_num_tokens': 96, 'list_tokens_length': 96}\n",
      "{'num_fields': 517, 'list_num_tokens': 102, 'list_tokens_length': 102}\n",
      "{'num_fields': 509, 'list_num_tokens': 110, 'list_tokens_length': 110}\n",
      "{'num_fields': 216, 'list_num_tokens': 77, 'list_tokens_length': 77}\n",
      "{'num_fields': 505, 'list_num_tokens': 82, 'list_tokens_length': 82}\n",
      "{'num_fields': 516, 'list_num_tokens': 89, 'list_tokens_length': 89}\n",
      "{'num_fields': 1513, 'list_num_tokens': 109, 'list_tokens_length': 109}\n",
      "{'num_fields': 513, 'list_num_tokens': 82, 'list_tokens_length': 82}\n",
      "{'num_fields': 317, 'list_num_tokens': 98, 'list_tokens_length': 98}\n",
      "{'num_fields': 525, 'list_num_tokens': 61, 'list_tokens_length': 61}\n",
      "{'num_fields': 572, 'list_num_tokens': 74, 'list_tokens_length': 74}\n",
      "{'num_fields': 511, 'list_num_tokens': 90, 'list_tokens_length': 90}\n",
      "{'num_fields': 185, 'list_num_tokens': 103, 'list_tokens_length': 103}\n",
      "{'num_fields': 1546, 'list_num_tokens': 104, 'list_tokens_length': 104}\n",
      "{'num_fields': 525, 'list_num_tokens': 95, 'list_tokens_length': 95}\n",
      "{'num_fields': 713, 'list_num_tokens': 114, 'list_tokens_length': 114}\n",
      "{'num_fields': 519, 'list_num_tokens': 95, 'list_tokens_length': 95}\n",
      "{'num_fields': 354, 'list_num_tokens': 104, 'list_tokens_length': 104}\n",
      "{'num_fields': 500, 'list_num_tokens': 54, 'list_tokens_length': 54}\n",
      "{'num_fields': 514, 'list_num_tokens': 97, 'list_tokens_length': 97}\n",
      "{'num_fields': 503, 'list_num_tokens': 82, 'list_tokens_length': 82}\n",
      "{'num_fields': 530, 'list_num_tokens': 98, 'list_tokens_length': 98}\n",
      "{'num_fields': 501, 'list_num_tokens': 64, 'list_tokens_length': 64}\n",
      "{'num_fields': 517, 'list_num_tokens': 96, 'list_tokens_length': 96}\n",
      "{'num_fields': 351, 'list_num_tokens': 95, 'list_tokens_length': 95}\n",
      "{'num_fields': 529, 'list_num_tokens': 100, 'list_tokens_length': 100}\n",
      "{'num_fields': 1522, 'list_num_tokens': 97, 'list_tokens_length': 97}\n",
      "{'num_fields': 694, 'list_num_tokens': 84, 'list_tokens_length': 84}\n",
      "{'num_fields': 508, 'list_num_tokens': 91, 'list_tokens_length': 91}\n",
      "{'num_fields': 505, 'list_num_tokens': 106, 'list_tokens_length': 106}\n",
      "{'num_fields': 531, 'list_num_tokens': 89, 'list_tokens_length': 89}\n",
      "{'num_fields': 231, 'list_num_tokens': 117, 'list_tokens_length': 117}\n",
      "{'num_fields': 515, 'list_num_tokens': 95, 'list_tokens_length': 95}\n",
      "{'num_fields': 551, 'list_num_tokens': 103, 'list_tokens_length': 103}\n",
      "{'num_fields': 525, 'list_num_tokens': 100, 'list_tokens_length': 100}\n",
      "{'num_fields': 1231, 'list_num_tokens': 97, 'list_tokens_length': 97}\n",
      "{'num_fields': 517, 'list_num_tokens': 80, 'list_tokens_length': 80}\n",
      "{'num_fields': 507, 'list_num_tokens': 100, 'list_tokens_length': 100}\n",
      "{'num_fields': 1728, 'list_num_tokens': 109, 'list_tokens_length': 109}\n",
      "{'num_fields': 170, 'list_num_tokens': 78, 'list_tokens_length': 78}\n",
      "{'num_fields': 525, 'list_num_tokens': 102, 'list_tokens_length': 102}\n",
      "{'num_fields': 1183, 'list_num_tokens': 113, 'list_tokens_length': 113}\n",
      "{'num_fields': 501, 'list_num_tokens': 93, 'list_tokens_length': 93}\n",
      "{'num_fields': 100, 'list_num_tokens': 73, 'list_tokens_length': 73}\n",
      "{'num_fields': 516, 'list_num_tokens': 75, 'list_tokens_length': 75}\n",
      "{'num_fields': 539, 'list_num_tokens': 99, 'list_tokens_length': 99}\n",
      "{'num_fields': 106, 'list_num_tokens': 85, 'list_tokens_length': 85}\n",
      "{'num_fields': 140, 'list_num_tokens': 78, 'list_tokens_length': 78}\n",
      "{'num_fields': 529, 'list_num_tokens': 83, 'list_tokens_length': 83}\n",
      "{'num_fields': 162, 'list_num_tokens': 80, 'list_tokens_length': 80}\n",
      "{'num_fields': 1213, 'list_num_tokens': 96, 'list_tokens_length': 96}\n",
      "{'num_fields': 528, 'list_num_tokens': 98, 'list_tokens_length': 98}\n",
      "{'num_fields': 100, 'list_num_tokens': 81, 'list_tokens_length': 81}\n",
      "{'num_fields': 512, 'list_num_tokens': 70, 'list_tokens_length': 70}\n",
      "{'num_fields': 989, 'list_num_tokens': 125, 'list_tokens_length': 125}\n",
      "{'num_fields': 506, 'list_num_tokens': 79, 'list_tokens_length': 79}\n",
      "{'num_fields': 1119, 'list_num_tokens': 108, 'list_tokens_length': 108}\n",
      "{'num_fields': 518, 'list_num_tokens': 112, 'list_tokens_length': 112}\n",
      "{'num_fields': 527, 'list_num_tokens': 65, 'list_tokens_length': 65}\n",
      "{'num_fields': 501, 'list_num_tokens': 92, 'list_tokens_length': 92}\n",
      "{'num_fields': 489, 'list_num_tokens': 98, 'list_tokens_length': 98}\n",
      "{'num_fields': 752, 'list_num_tokens': 90, 'list_tokens_length': 90}\n",
      "{'num_fields': 1011, 'list_num_tokens': 86, 'list_tokens_length': 86}\n",
      "{'num_fields': 502, 'list_num_tokens': 84, 'list_tokens_length': 84}\n",
      "{'num_fields': 1095, 'list_num_tokens': 141, 'list_tokens_length': 141}\n",
      "{'num_fields': 309, 'list_num_tokens': 100, 'list_tokens_length': 100}\n",
      "{'num_fields': 483, 'list_num_tokens': 74, 'list_tokens_length': 74}\n",
      "{'num_fields': 949, 'list_num_tokens': 87, 'list_tokens_length': 87}\n",
      "{'num_fields': 126, 'list_num_tokens': 83, 'list_tokens_length': 83}\n",
      "{'num_fields': 696, 'list_num_tokens': 105, 'list_tokens_length': 105}\n",
      "{'num_fields': 1241, 'list_num_tokens': 87, 'list_tokens_length': 87}\n",
      "{'num_fields': 956, 'list_num_tokens': 111, 'list_tokens_length': 111}\n",
      "{'num_fields': 513, 'list_num_tokens': 107, 'list_tokens_length': 107}\n",
      "{'num_fields': 881, 'list_num_tokens': 112, 'list_tokens_length': 112}\n",
      "{'num_fields': 1758, 'list_num_tokens': 100, 'list_tokens_length': 100}\n",
      "{'num_fields': 524, 'list_num_tokens': 87, 'list_tokens_length': 87}\n",
      "{'num_fields': 514, 'list_num_tokens': 97, 'list_tokens_length': 97}\n",
      "{'num_fields': 569, 'list_num_tokens': 103, 'list_tokens_length': 103}\n",
      "{'num_fields': 506, 'list_num_tokens': 77, 'list_tokens_length': 77}\n",
      "{'num_fields': 510, 'list_num_tokens': 113, 'list_tokens_length': 113}\n",
      "{'num_fields': 809, 'list_num_tokens': 102, 'list_tokens_length': 102}\n",
      "{'num_fields': 501, 'list_num_tokens': 100, 'list_tokens_length': 100}\n",
      "{'num_fields': 1096, 'list_num_tokens': 90, 'list_tokens_length': 90}\n",
      "{'num_fields': 2107, 'list_num_tokens': 92, 'list_tokens_length': 92}\n",
      "{'num_fields': 503, 'list_num_tokens': 80, 'list_tokens_length': 80}\n",
      "{'num_fields': 509, 'list_num_tokens': 82, 'list_tokens_length': 82}\n",
      "{'num_fields': 106, 'list_num_tokens': 83, 'list_tokens_length': 83}\n",
      "{'num_fields': 540, 'list_num_tokens': 90, 'list_tokens_length': 90}\n",
      "{'num_fields': 506, 'list_num_tokens': 91, 'list_tokens_length': 91}\n",
      "{'num_fields': 1173, 'list_num_tokens': 97, 'list_tokens_length': 97}\n",
      "{'num_fields': 102, 'list_num_tokens': 74, 'list_tokens_length': 74}\n",
      "{'num_fields': 513, 'list_num_tokens': 103, 'list_tokens_length': 103}\n",
      "{'num_fields': 509, 'list_num_tokens': 61, 'list_tokens_length': 61}\n",
      "{'num_fields': 702, 'list_num_tokens': 101, 'list_tokens_length': 101}\n",
      "{'num_fields': 120, 'list_num_tokens': 108, 'list_tokens_length': 108}\n",
      "{'num_fields': 896, 'list_num_tokens': 90, 'list_tokens_length': 90}\n",
      "{'num_fields': 504, 'list_num_tokens': 87, 'list_tokens_length': 87}\n",
      "{'num_fields': 192, 'list_num_tokens': 54, 'list_tokens_length': 54}\n",
      "{'num_fields': 508, 'list_num_tokens': 88, 'list_tokens_length': 88}\n",
      "{'num_fields': 519, 'list_num_tokens': 89, 'list_tokens_length': 89}\n",
      "{'num_fields': 838, 'list_num_tokens': 100, 'list_tokens_length': 100}\n",
      "{'num_fields': 368, 'list_num_tokens': 89, 'list_tokens_length': 89}\n",
      "{'num_fields': 506, 'list_num_tokens': 113, 'list_tokens_length': 113}\n",
      "{'num_fields': 671, 'list_num_tokens': 73, 'list_tokens_length': 73}\n",
      "{'num_fields': 1298, 'list_num_tokens': 97, 'list_tokens_length': 97}\n",
      "{'num_fields': 253, 'list_num_tokens': 36, 'list_tokens_length': 36}\n",
      "{'num_fields': 194, 'list_num_tokens': 87, 'list_tokens_length': 87}\n",
      "{'num_fields': 560, 'list_num_tokens': 85, 'list_tokens_length': 85}\n",
      "{'num_fields': 979, 'list_num_tokens': 89, 'list_tokens_length': 89}\n",
      "{'num_fields': 581, 'list_num_tokens': 58, 'list_tokens_length': 58}\n",
      "{'num_fields': 501, 'list_num_tokens': 90, 'list_tokens_length': 90}\n",
      "{'num_fields': 248, 'list_num_tokens': 98, 'list_tokens_length': 98}\n",
      "{'num_fields': 505, 'list_num_tokens': 107, 'list_tokens_length': 107}\n",
      "{'num_fields': 502, 'list_num_tokens': 116, 'list_tokens_length': 116}\n",
      "{'num_fields': 513, 'list_num_tokens': 106, 'list_tokens_length': 106}\n",
      "{'num_fields': 1474, 'list_num_tokens': 104, 'list_tokens_length': 104}\n",
      "{'num_fields': 163, 'list_num_tokens': 81, 'list_tokens_length': 81}\n",
      "{'num_fields': 654, 'list_num_tokens': 99, 'list_tokens_length': 99}\n",
      "{'num_fields': 500, 'list_num_tokens': 119, 'list_tokens_length': 119}\n",
      "{'num_fields': 737, 'list_num_tokens': 104, 'list_tokens_length': 104}\n",
      "{'num_fields': 500, 'list_num_tokens': 112, 'list_tokens_length': 112}\n",
      "{'num_fields': 559, 'list_num_tokens': 97, 'list_tokens_length': 97}\n",
      "{'num_fields': 500, 'list_num_tokens': 98, 'list_tokens_length': 98}\n",
      "{'num_fields': 1352, 'list_num_tokens': 106, 'list_tokens_length': 106}\n",
      "{'num_fields': 503, 'list_num_tokens': 94, 'list_tokens_length': 94}\n",
      "{'num_fields': 138, 'list_num_tokens': 70, 'list_tokens_length': 70}\n",
      "{'num_fields': 780, 'list_num_tokens': 69, 'list_tokens_length': 69}\n",
      "{'num_fields': 164, 'list_num_tokens': 94, 'list_tokens_length': 94}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_fields': 642, 'list_num_tokens': 102, 'list_tokens_length': 102}\n",
      "{'num_fields': 459, 'list_num_tokens': 112, 'list_tokens_length': 112}\n",
      "{'num_fields': 510, 'list_num_tokens': 61, 'list_tokens_length': 61}\n",
      "{'num_fields': 506, 'list_num_tokens': 105, 'list_tokens_length': 105}\n",
      "{'num_fields': 1179, 'list_num_tokens': 99, 'list_tokens_length': 99}\n",
      "{'num_fields': 506, 'list_num_tokens': 97, 'list_tokens_length': 97}\n",
      "{'num_fields': 515, 'list_num_tokens': 68, 'list_tokens_length': 68}\n",
      "{'num_fields': 721, 'list_num_tokens': 95, 'list_tokens_length': 95}\n",
      "{'num_fields': 533, 'list_num_tokens': 87, 'list_tokens_length': 87}\n",
      "{'num_fields': 1140, 'list_num_tokens': 91, 'list_tokens_length': 91}\n",
      "{'num_fields': 506, 'list_num_tokens': 77, 'list_tokens_length': 77}\n",
      "{'num_fields': 506, 'list_num_tokens': 64, 'list_tokens_length': 64}\n",
      "{'num_fields': 1028, 'list_num_tokens': 96, 'list_tokens_length': 96}\n",
      "{'num_fields': 64, 'list_num_tokens': 80, 'list_tokens_length': 80}\n",
      "{'num_fields': 503, 'list_num_tokens': 90, 'list_tokens_length': 90}\n"
     ]
    }
   ],
   "source": [
    "for i in train_instances:\n",
    "    #print(i)\n",
    "    i[\"lines\"].index(vocab)\n",
    "    i[\"arcs\"].index(vocab)\n",
    "    print(i[\"lines\"].get_padding_lengths())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance with fields:\n",
      " \t lines: ListField of 503 TextFields : \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, i, mean, the, uefi, ,, not, uf, :p, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, ubuntu, 14.04, comes, with, gcc, 4.8.2, that, is, fully, c++11, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, URL, /, http:/, URL, /, gcc.gnu.org/, <, unk#a./, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, is, he, here, ?, who, is, he, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, not, here, ,, at, ubuntu, forums, ., <, unka, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 48 with text: \n",
      " \t\t[<, s, >, URL, /, http:/, URL, /, paste.ubuntu.com/, <, unk#a/, >, anyone, know, why, this, package,\n",
      "\t\tis, being, selected, ?, 1.1, is, in, trusty, -, updates, but, i, do, n't, have, that, in, my,\n",
      "\t\tsources, list, ....., idk, where, it, 's, coming, from, :(, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 57 with text: \n",
      " \t\t[<, s, >, <, user, >, :, i, using, <, unka, :, >, and, compiler, gcc, ., i, used, <, unka, `, >,\n",
      "\t\tbut, editor, saying, :, \", warning, :, identifier, <, unka, ', >, is, a, keyword, in, c++11, ,,\n",
      "\t\terror, :, <, unka, ', >, was, not, declared, in, this, scope, \", <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, anything, else, maybe, causing, the, problem, with, bad, password, ?, <,\n",
      "\t\t/s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, s, >, <, user, >, :, my, gcc, version, :, 4, .., 8.2, -, null, pointer, constant, min, version,\n",
      "\t\t:, 4.6, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, s, >, hi, people, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, s, >, hi, tick, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 29 with text: \n",
      " \t\t[<, s, >, since, i, upgraded, to, ubuntu, 14, (, from, ubunto, 12, ), ,, i, ca, nt, run, the, x, <,\n",
      "\t\tunka, >, anymore, :/, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 74 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, the, only, thing, that, causes, troubles, for, me, is, \", <, unka-, >, \",\n",
      "\t\tfeature, of, google, ,, where, we, need, to, generate, an, \", application, password, \", for,\n",
      "\t\tspecific, applications, like, chat, clients, ., if, you, have, n't, enabled, <, unk#a-, >, ,, i, ca,\n",
      "\t\tn't, guess, what, else, could, be, causing, the, error, (, apart, from, a, typo, of, course, ), .,\n",
      "\t\t<, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, i, now, only, have, the, tty, to, use, my, ubuntu, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 48 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, i, am, not, sure, about, the, 2, step, thing, ,, if, i, have, that,\n",
      "\t\tenabled, what, am, i, supposed, to, put, in, when, it, asked, for, my, <, unka, _, >,\n",
      "\t\tADDRESS_@gmail.com, password, other, than, my, password, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 46 with text: \n",
      " \t\t[<, s, >, hey, guys, ,, one, question, :, if, i, was, looking, something, nice, ,, stable, ,, with,\n",
      "\t\ta, <, unka, >, support, for, a, laptop, (, 4, gb, ram, ), ,, dual, core, intel, 2.1, ,, what, would,\n",
      "\t\tyou, suggest, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, s, >, <, user, >, :, you, may, need, to, know, if, you, have, <, unk#a-, >, verification, <, /s,\n",
      "\t\t>]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, <, user, >, :, a, table, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 33 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, if, you, 're, not, sure, ,, then, you, do, n't, have, it, enabled, .,\n",
      "\t\tgoogle, enables, it, only, if, <, unka-, >, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, <, user, >, thx, i, did, it, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 40 with text: \n",
      " \t\t[<, s, >, <, user, >, :, <, unka, ', >, support, ', is, code, for, \", i, will, be, lazy, to, the,\n",
      "\t\tpoint, of, not, updating, for, longer, than, five, whole, years, \", ,, right, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 29 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, lets, assume, i, have, it, because, i, really, do, nt, remember, one, way,\n",
      "\t\tor, the, other, ,, then, what, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, <, user, >, :, i, would, suggest, debian, wheezy, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 31 with text: \n",
      " \t\t[<, s, >, <, user, >, :, ok, ,, i, found, ., i, checked, checkbox, in, <, unka, :, >, ., ide, fail,\n",
      "\t\t:, d, ., thank, you, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, user, >, :, what, graphics, card, do, you, have, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, i, fixed, no, more, problem, :), <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 26 with text: \n",
      " \t\t[<, s, >, <, user, >, :, if, you, do, have, <, unk#a-, >, ,, then, you, need, to, get, an,\n",
      "\t\tapplication, login, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, <, user, >, :, nvidia, gtx, 660, ti, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, great, ,, i, was, looking, for, something, simular, too, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, <, user, >, URL, /, http:/, URL, /, pastebin.ubuntu.com/, <, unk#a/, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 35 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, 2, step, means, i, have, to, do, two, things, everytime, i, log, in, ?, if,\n",
      "\t\tthat, s, the, case, then, i, do, nt, have, that, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, but, who, will, see, the, txt, now, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 54 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, in, this, kind, of, verification, ,, you, can, authenticate, specific,\n",
      "\t\tsystems, so, that, you, can, log, into, google, account, only, from, those, systems, ., if, you,\n",
      "\t\ttry, to, log, on, from, another, system, ,, google, sends, you, a, verification, code, on, your,\n",
      "\t\tmobile, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, <, user, >, how, i, got, answer, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, unka, >, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 23 with text: \n",
      " \t\t[<, s, >, hi, sorry, i, ', m, a, noob, -, but, can, i, install, ubuntu, on, windows, 8, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 23 with text: \n",
      " \t\t[<, s, >, <, user, >, :, no, ,, but, you, do, need, to, authorize, google, to, use, each, app, <,\n",
      "\t\t/s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, ok, ,, i, have, that, for, ms, but, not, for, gmail, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 23 with text: \n",
      " \t\t[<, s, >, can, someone, please, send, me, a, link, on, how, can, i, make, the, xrandr,\n",
      "\t\tcustomization, permanent, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, unka, >, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, taking, a, look, at, the, report, now, ...., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, <, user, >, u, are, the, one, who, did, it, ?, ok, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, s, >, <, user, >, :, do, you, know, how, to, get, to, your, security, settings, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, alessandro, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, in, gmail, ?, yes, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 90 with text: \n",
      " \t\t[<, s, >, <, user, >, :, i, could, probably, get, to, it, once, a, year, ,, but, would, need,\n",
      "\t\tsomething, that, 's, definitely, not, <, unka-, >, ., debian, ,, opensuse, ,, ubuntu, ,, i, ', m,\n",
      "\t\tlooking, into, the, options, ., but, i, know, holding, on, for, too, long, with, upgrading, is,\n",
      "\t\tunrealistic, ., as, i, 'll, either, get, a, newer, phone, which, i, 'll, need, to, load, ,, or, a,\n",
      "\t\tnewer, <, unka-, >, which, calibre, wo, n't, be, able, to, do, :, d, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, s, >, <, user, >, :, ok, ,, when, you, get, to, that, page, ,, go, to, the, security, tab, <,\n",
      "\t\t/s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 68 with text: \n",
      " \t\t[<, s, >, hello, ,, i, just, went, from, dualboot, to, a, clean, <, unka, >, ., the, problem, i, m,\n",
      "\t\thaving, is, that, grub, is, finding, some, loaders, other, than, the, current, install, on, other,\n",
      "\t\tharddrives, ., this, means, i, have, to, wait, for, grub, each, boot, ,, i, do, nt, want, that, !,\n",
      "\t\thow, do, i, make, it, just, boot, this, installation, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, s, >, <, user, >, :, i, think, there, is, a, windows, installer, ..., wubi, or, something, ., <,\n",
      "\t\t/s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, hhm, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, !, wubi, |, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 78 with text: \n",
      " \t\t[<, s, >, <, user, >, :, wubi, allows, you, to, install, or, uninstall, ubuntu, 12.04, lts, from,\n",
      "\t\twithin, windows, (, version, 7, or, earlier, ), in, a, simple, and, safe, way, ., wubi, is,\n",
      "\t\tincompatible, with, uefi, ,, windows, 8, certified, computers, ,, and, windows, raid, arrays, .,\n",
      "\t\tURL, /, https:/, URL, /, wiki.ubuntu.com/, URL, /, wubiguide/, for, more, information, ., file,\n",
      "\t\twubi, bugs, at, URL, /, http:/, URL, /, launchpad.net/, URL, /, wubi/+filebug/, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, wubi, wo, nt, work, for, windows, 8, then, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, :, do, you, have, the, nvidia, -, current, package, installed, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, s, >, <, user, >, :, apparently, not, !, what, are, you, trying, to, do, ?, dual, -, boot, ?, <,\n",
      "\t\t/s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 23 with text: \n",
      " \t\t[<, s, >, has, anyone, worked, around, the, problem, that, wine, and, cuda, 6.5, ca, n't, be,\n",
      "\t\tinstalled, together, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, 'cause, i, need, both, things, installed, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, ah, it, seem, to, have, disappear, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 33 with text: \n",
      " \t\t[<, s, >, <, user, >, :, when, you, are, on, that, page, ,, you, see, the, password, section, ,,\n",
      "\t\tyou, should, see, <, unk#a-, >, verification, enable, or, not, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, <, user, >, :, also, try, #, wine, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, can, someone, please, tell, me, how, can, i, make, the, xrandr, customization, permanent,\n",
      "\t\t?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 61 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, the, issue, is, this, ..., on, one, computer, evolution, has, a, pop, up,\n",
      "\t\tsaying, password, for, gmail, and, i, put, it, in, and, it, works, fine, ,, on, the, 2nd, comp,\n",
      "\t\tsame, password, says, incorrect, password, ..., i, am, doing, this, via, ubuntu, -, gnome, <, unka/,\n",
      "\t\t>, <, unka, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 36 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, please, try, -, \", sudo, modprobe, -v, ath5k, \", ., if, you, get, any,\n",
      "\t\terrors, while, executing, that, ,, post, back, the, error, you, get, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, :, yeah, ,, had, the, same, issue, when, i, upgraded, ..., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, s, >, <, user, >, :, did, you, get, to, the, security, tab, on, your, account, settings, ?, <,\n",
      "\t\t/s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 31 with text: \n",
      " \t\t[<, s, >, <, user, >, :, thanks, for, your, patience, !, if, anyone, knows, how, to, help, they,\n",
      "\t\t'll, respond, asap, ., sorry, for, the, wait, ..., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, s, >, <, user, >, :, you, might, need, the, build, -, essentials, package, too, ,, if, i,\n",
      "\t\tremeber, correctly, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 23 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, that, is, obviously, not, at, issue, since, its, a, difference, between,\n",
      "\t\tthese, computers, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 68 with text: \n",
      " \t\t[<, s, >, hello, ,, i, just, went, from, dualboot, to, a, clean, <, unka, >, ., the, problem, i, m,\n",
      "\t\thaving, is, that, grub, is, finding, some, loaders, other, than, the, current, install, on, other,\n",
      "\t\tharddrives, ., this, means, i, have, to, wait, for, grub, each, boot, ,, i, do, nt, want, that, !,\n",
      "\t\thow, do, i, make, it, just, boot, this, installation, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, s, >, <, user, >, :, just, checking, to, see, if, you, have, <, unk#a-, >, enabled, or, not,\n",
      "\t\tfirst, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, thx, a, lot, ,, wireless, work, now, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, no, i, do, not, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, thank, you, <, user, >, :), <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, <, user, >, got, to, go, now, ,, bye, thx, a, lot, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, congrats, !, although, it, is, a, bit, confusing, why, it, did, n't, load,\n",
      "\t\tautomatically, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, s, >, <, user, >, :, so, for, the, online, accounts, ,, it, will, not, accept, the, password,\n",
      "\t\tat, all, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, i, installed, the, nvidia, -, current, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 33 with text: \n",
      " \t\t[<, s, >, <, user, >, :, when, i, put, in, my, google, account, ,, it, will, accept, my, pass, ,,\n",
      "\t\tbut, then, i, need, to, grant, access, after, that, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, :, and, it, returned, an, error, during, the, pre, -, removal, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 79 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, first, a, window, pop, up, occurs, saying, all, the, google, stuff, it,\n",
      "\t\twants, access, to, ,, i, put, in, the, password, there, and, click, accept, and, everything, seems,\n",
      "\t\tto, work, ,, then, a, 2nd, system, pop, up, happens, asking, for, my, <, unka, _, >, <, unka@, _, >,\n",
      "\t\tpassword, ,, put, that, in, in, 1, comp, ,, no, issues, ,, 2nd, comp, ,, rejects, it, as, wrong,\n",
      "\t\tpassword, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, there, must, be, errors, in, my, source, list, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, can, i, restore, it, to, a, default, source, list, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, :, not, sure, then, ,, i, have, never, tested, that, before, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, <, user, >, :, sorry, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, s, >, <, user, >, :, i, did, nt, find, the, build, -, essentials, in, apt, -, get, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, s, >, <, user, >, :, build, -, essential, without, an, s, on, the, end, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 52 with text: \n",
      " \t\t[<, s, >, so, i, m, doing, a, tasksel, of, \", ubuntu, -, desktop, \", and, \", xubuntu, -, desktop, \",\n",
      "\t\tbut, there, s, a, package, in, xubuntu, -, desktop, that, 's, at, a, higher, version, than, what,\n",
      "\t\t's, needed, in, ubuntu, -, desktop, and, the, install, is, failing, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, any, way, to, fix, this, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, <, user, >, :, ok, ,, it, seems, to, be, already, there, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, <, user, >, :, the, error, is, on, nvidia-331-updates, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, :, what, error, do, you, get, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, when, i, run, startx, ..., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, s, >, there, are, some, timeouts, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, and, the, xorg, sever, refuses, the, connec, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, <, user, >, :, do, nt, run, startx, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, <, user, >, :, start, the, lightdm, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, s, >, it, says, DIR, /, usr/, DIR, /, bin/, DIR, /, x/, not, found, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, maybe, you, do, n't, have, x, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 28 with text: \n",
      " \t\t[<, s, >, hi, ., does, anyone, know, where, to, download, the, eds, data, integration, addon, for,\n",
      "\t\tthunderbird, that, comes, with, some, ubuntu, versions, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, s, >, lightdm, failed, to, start, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 56 with text: \n",
      " \t\t[<, s, >, on, 14.04, ,, i, installed, kubuntu, ,, but, then, installed, ubuntu, -, desktop, .,\n",
      "\t\teverything, works, fine, ,, but, my, menu, 's, are, a, bit, difficult, to, read, (, see, URL, /,\n",
      "\t\thttp:/, URL, /, ibin.co/, <, unk#a/, >, ), and, i, ca, n't, find, a, way, to, resolve, this, <, /s,\n",
      "\t\t>]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, <, user, >, :, yes, ,, it, has, disappeard, during, the, upgrade, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, <, user, >, :, for, evolution, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 33 with text: \n",
      " \t\t[<, s, >, <, user, >, :, on, ubuntu, you, do, nt, use, startx, ,, you, start, the, *, dm, and, that,\n",
      "\t\twill, manage, all, the, x, stuff, for, you, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, s, >, yes, <, user, >, ,, and, the, job, ca, nt, be, started, despite, lightdm, being,\n",
      "\t\tinstalled, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, s, >, <, user, >, :, yes, ., there, is, a, plugin, that, enables, thunderbird, to, access,\n",
      "\t\tevolution, 's, contacts, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, :, what, ubuntu, is, that, exactly, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, 14.04, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 38 with text: \n",
      " \t\t[<, s, >, <, user, >, :, but, their, website, URL, /, https:/, URL, /, launchpad.net/, <, unka-/, >,\n",
      "\t\thas, no, downloads, ,, although, i, already, saw, a, ubuntu, installation, having, this, addon,\n",
      "\t\tinstalled, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, <, user, >, :, which, desktop, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, previously, i, had, unity, ,, xfce, ,, and, kde, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, and, now, ,, nothing, :, d, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, lets, setup, ubuntu, -, desktop, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, is, lightdm, your, actual, dm, ?, is, it, running, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, :, try, \", apt, -, get, install, ubuntu, -, desktop, \", <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, s, >, see, dmesg, what, happens, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, k, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, s, >, is, it, true, that, ubuntu, developer, summit, occurs, after, every, new, release, ?, <,\n",
      "\t\t/s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 68 with text: \n",
      " \t\t[<, s, >, hello, ,, i, just, went, from, dualboot, to, a, clean, <, unka, >, ., the, problem, i, m,\n",
      "\t\thaving, is, that, grub, is, finding, some, loaders, other, than, the, current, install, on, other,\n",
      "\t\tharddrives, ., this, means, i, have, to, wait, for, grub, each, boot, ,, i, do, nt, want, that, !,\n",
      "\t\thow, do, i, make, it, just, boot, this, installation, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, has, anyone, tried, arandr, ?, URL, /, http:/, URL, /, www.ubuntugeek.com/, <, unka-./, >,\n",
      "\t\t<, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, :, ok, and, then, how, do, i, start, the, desktop, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, user, >, :, did, that, install, any, new, packages, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, yes, ,, it, installed, <, unk#a, >, of, new, package, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, :, try, \", service, lightdm, restart, \", <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 33 with text: \n",
      " \t\t[<, s, >, <, user, >, :, iirc, it, happens, <, unka, >, happens, every, 3, months, ., at, least,\n",
      "\t\tthat, was, what, it, was, doing, when, they, started, it, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 30 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, and, is, there, something, named, \", ubuntu, summit, \", without, \",\n",
      "\t\tdeveloper, \", or, it, is, the, same, thing, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 23 with text: \n",
      " \t\t[<, s, >, when, running, \", top, \", i, noticed, that, chromium, is, eating, up, a, lot, cpu, power,\n",
      "\t\t., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 30 with text: \n",
      " \t\t[<, s, >, <, user, >, :, i, believe, there, are, different, <, unka, >, (, or, maybe, i, ', m,\n",
      "\t\tthinking, of, <, unka, >, ), <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, you, have, many, bookmarks, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, s, >, <, user, >, :, did, that, work, ?, or, do, you, still, get, any, errors, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, s, >, i, only, have, 3, tabs, open, with, one, using, either, html5, or, flash, for, music,\n",
      "\t\tstreaming, via, soundcloud, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, yup, ,, i, wait, for, the, stuff, the, download, ,, it, is, soooo, long, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, less, than, 50, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, s, >, <, user, >, :, ok, ,, let, me, know, when, its, done, ;), <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 37 with text: \n",
      " \t\t[<, s, >, <, user, >, :, this, is, slightly, off, topic, here, ,, can, we, take, this, discussion,\n",
      "\t\tto, #, ubuntu, -, offtopic, and, you, can, describe, what, you, are, thinking, of, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, on, in, folder, \", bookmarks, folder, \", ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, sure, ., :), <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, ^^, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, user, >, _, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, if, so, move, them, to, folder, called, \", other, \", <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, there, is, something, with, bookmarks, in, 37, version, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, :, URL, /, https:/, URL, /, help.ubuntu.com/, <, unk#a#/, _, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, oh, on, my, bookmark, bar, ?, i, have, 8, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, in, my, other, bookmarks, i, have, the, others, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, try, to, move, them, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 27 with text: \n",
      " \t\t[<, s, >, i, still, get, an, error, on, this, >, button, -, >, <, unka, \", &, (, >, \", ), ), ;, <,\n",
      "\t\t/s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, sorry, man, for, this, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, it, started, recently, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, opps, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, s, >, wrong, post, on, last, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, s, >, <, user, >, :, ok, ,, ubuntu, -, desktop, installed, ,, lightdm, still, does, nt, want,\n",
      "\t\tto, start, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, errors, were, encountered, during, the, nvidia-331-updates, execution, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, user, >, :, try, \", dpkg, -, reconfigure, lightdm, \", <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, do, i, purge, this, nvidia, stuff, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, almost, all, of, my, bookmarks, go, into, a, other, folder, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, try, to, move, them, all, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, ok, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, still, does, nt, want, to, start, the, lightdm, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, s, >, <, user, >, :, your, flash, stuff, eats, a, lot, of, cpu, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 30 with text: \n",
      " \t\t[<, s, >, <, user, >, :, if, that, does, nt, help, ,, try, to, remove, all, <, unka-, >, installed,\n",
      "\t\tand, just, install, nvidia, -, current, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 77 with text: \n",
      " \t\t[<, s, >, i, entered, the, wrong, syntax, for, .profile, and, now, it, 's, in, a, login, boot, .,\n",
      "\t\tthe, problem, is, i, ca, n't, change, boot, override, so, i, can, get, to, a, command, line, now,\n",
      "\t\tas, root, but, it, wo, n't, let, me, unmount, the, file, system, to, edit, .profile, ., any, ideas,\n",
      "\t\thow, to, get, around, this, ?, it, 's, an, asus, zenbook, that, i, removed, windows, and, added,\n",
      "\t\tubuntu, too, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, s, >, <, user, >, :, and, then, try, a, \", dpkg, -, reconfigure, lightdm, \", again, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, s, >, k, lets, go, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 28 with text: \n",
      " \t\t[<, s, >, <, user, >, :, again, :, see, \", dmesg, \", what, is, going, on, there, ., i, bet, its, a,\n",
      "\t\tdrivers, issue, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, mkay, ,, removed, the, nvidia, *, things, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, dmesg, returns, a, lot, of, things, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, and, remember, to, run, <, unka-, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, now, installing, nvidia, -, current, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, s, >, <, user, >, :, also, check, if, you, have, the, \", linux, -, headers, -, generic, \",\n",
      "\t\tpackage, installed, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 39 with text: \n",
      " \t\t[<, s, >, hi, guys, ., is, there, a, supported, way, of, installing, <, unka, >, server, on, 14.04,\n",
      "\t\t?, it, 's, not, in, the, repos, ., i, assume, it, was, removed, because, of, apparmor, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, k, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, URL, /, https:/, URL, /, drive.google.com/, <, unk#a/=, ?, _, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, s, >, hey, guyz, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, :, thx, !, think, i, made, it, work, ', reboot, ', <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, k, i, did, nt, had, the, headers, generic, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, s, >, adding, it, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 28 with text: \n",
      " \t\t[<, s, >, <, user, >, :, you, might, need, to, do, a, \", dpkg, -, reconfigure, nvidia, -, current,\n",
      "\t\t\", after, installing, it, ..., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, k, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, s, >, ok, done, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, user, >, :, then, try, \", service, lightdm, restart, \", <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, :, it, worked, !, <, unka, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, s, >, stop, :, unknown, <, unka, >, :, start, :, job, failed, to, start, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, <, user, >, :, good, to, hear, !, :), <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, s, >, unknown, instance, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 23 with text: \n",
      " \t\t[<, s, >, have, a, look, at, this, >, URL, /, https:/, URL, /, drive.google.com/, <, unk#a/=, ?, _,\n",
      "\t\t>, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, :, \", dpkg, -, reconfigure, lightdm, \", <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, shows, how, many, instances, of, chromium, are, running, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, i, do, have, hangouts, running, in, the, background, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, s, >, <, user, >, :, is, there, a, question, that, goes, with, this, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, user, >, :, after, reconfiguring, ,, still, failing, to, start, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 26 with text: \n",
      " \t\t[<, s, >, please, help, me, ,, looks, like, something, goes, wring, very, bad, URL, /, http:/, URL,\n",
      "\t\t/, pastebin.com/, <, unk#a/, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, maybe, i, need, to, reboot, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, s, >, why, this, happened, ?, why, all, my, packages, which, i, are, deleted, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, s, >, <, user, >, :, what, <, unka-, >, do, you, have, installed, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, what, was, that, ?, o_o, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, s, >, bug, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, :, might, be, easier, to, ask, in, #, ubuntu, -, ru, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, after, <, unka, >, all, nvidia, ,, just, the, nvidia, current, ,, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, s, >, guys, how, can, i, revert, everything, that, got, installed, in, apt, -, get, upgrade, ?,\n",
      "\t\t<, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, s, >, anyone, have, a, suggestion, how, to, get, it, to, boot, to, liveusb, around, boot,\n",
      "\t\toverride, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, <, user, >, :, just, nvidia, -, current, now, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 29 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, wanted, to, know, why, is, chromium, taking, up, so, much, cpu, resources,\n",
      "\t\twhen, i, hardly, have, webpages, open, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, eeeeee, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, <, user, >, is, now, known, as, e, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, this, affects, the, performance, of, chromium, because, it, hangs, sometimes, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 32 with text: \n",
      " \t\t[<, s, >, <, user, >, :, give, me, a, sec, ..., trying, to, remeber, all, the, hops, i, had, to, go,\n",
      "\t\tthru, to, get, it, to, work, ;), <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, e, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, s, >, hey, guys, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, :), <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, <, user, >, :, try, a, clean, profile, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, sometime, pages, do, n't, fully, scroll, and, have, a, delay, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 26 with text: \n",
      " \t\t[<, s, >, the, fun, thing, is, ,, i, upgraded, on, my, laptop, ,, also, having, an, nvidia, card,\n",
      "\t\tand, nothing, went, wrong, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 26 with text: \n",
      " \t\t[<, s, >, i, want, to, learn, core, programming, an, someone, is, suggesting, red, hat, ahead, of,\n",
      "\t\tubuntu, ,, what, s, ur, say, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, where, is, my, chromium, user, profile, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, <, user, >, :, do, n't, know, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, s, >, somewhere, in, DIR/~/, probably, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, searched, nothing, there, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, though, i, found, some, stuff, @, whereis, chromium, -, browser, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, user, >, :, which, geforce, card, did, you, have, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, is, there, way, to, get, last, deleted, packages, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, user, >, :, it, is, a, geforce, gtx, 660, ti, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, s, >, log, or, something, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, <, user, >, :, DIR/~/, DIR/.config/, DIR, /, chromium/, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 69 with text: \n",
      " \t\t[<, s, >, hi, !, i, ', m, trying, to, re, -, install, grub, ,, but, i, ca, n't, seem, to, get, the,\n",
      "\t\ton, -, screen, keyboard, (, onboard, or, anything, like, it, ), to, start, ,, which, makes, that,\n",
      "\t\trather, difficult, ., is, there, any, clever, trick, to, start, onboard, ?, (, this, is, on, a, <,\n",
      "\t\tunka-, >, snapshot, from, last, week, ., ), <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, s, >, need, this, option, badly, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, s, >, !, utopic, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 48 with text: \n",
      " \t\t[<, s, >, ubuntu, 14.10, (, utopic, unicorn, ), is, the, next, development, release, of, ubuntu,\n",
      "\t\tdue, for, release, in, october, 2014, ., support, in, #, ubuntu+1, ., for, more, info, ,, see, the,\n",
      "\t\tannouncement, at, URL, /, http:/, URL, /, www.markshuttleworth.com/, <, unk#a/, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, s, >, <, user, >, :, that, release, is, not, final, yet, ,, discussion, in, #, ubuntu+1, <, /s,\n",
      "\t\t>]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, s, >, <, user, >, :, my, apologies, for, spamming, the, wrong, channel, ,, and, thanks, !, <,\n",
      "\t\t/s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, owner, _, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, s, >, not, a, problem, :), <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 28 with text: \n",
      " \t\t[<, s, >, <, user, >, :, i, should, be, able, to, start, the, x, server, even, without, the, nvidia,\n",
      "\t\tdrivers, is, nt, it, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, URL, /, http:/, URL, /, pastebin.com/, <, unka/, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, s, >, anyone, will, help, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, thanks, man, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, lot, of, junk, in, there, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, what, is, diference, of, ubuntu, gnome, adn, ubuntu, desktop, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, ah, there, 's, the, almighty, \", <, unka, _, >, \", folder, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, ubuntu, desktop, is, unity, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, a, custom, desktop, environment, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, guyz, pls, does, vb, net, work, on, ubuntu, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, gnome, is, another, desktop, environment, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, <, user, >, :, yes, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, pretty, much, it, comes, down, to, personal, preference, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, though, unity, is, more, cross, device, (, unity, phone, ,, tablets, ), <,\n",
      "\t\t/s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, !, unity, |, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 42 with text: \n",
      " \t\t[<, s, >, <, user, >, :, unity, is, the, default, ui, since, ubuntu, 11.04, ., unity, is, a, shell,\n",
      "\t\tfor, gnome, ., see, URL, /, http:/, URL, /, unity.ubuntu.com./, for, a, gnome, 2-like, experience,\n",
      "\t\t,, see, !, notunity, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, s, >, that, 's, right, ,, unity, ,, which, is, a, shell, for, gnome, ..., is, more, cross,\n",
      "\t\tdevice, :p, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, s, >, <, user, >, :, that, depends, of, you, x, -, server, is, set, to, use, the, nvidia,\n",
      "\t\tdrivers, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, :, try, to, do, a, \", sudo, nvidia, -, xconfig, \", <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, s, >, <, unka, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, s, >, <, user, >, :, then, you, should, be, able, to, start, x, again, (, service, lightdm,\n",
      "\t\trestart, \", <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 23 with text: \n",
      " \t\t[<, s, >, unable, to, parse, x.org, version, string, ,, backed, up, file, xorg.conf, ,, new, x,\n",
      "\t\tconfig, file, written, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, still, not, willing, to, start, lightdm, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, i, wait, for, the, apt, -, get, upgrade, to, finish, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, :, that, 's, not, finished, yet, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, s, >, i, ran, it, some, minutes, ago, ,, there, is, 200, mo, to, upgrade, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 32 with text: \n",
      " \t\t[<, s, >, <, user, >, :, that, might, be, why, then, ,, some, package, still, not, installed, ..,\n",
      "\t\twait, until, all, packages, are, installed, and, then, try, again, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, s, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, is, there, something, similiar, to, mock, under, ubuntu, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, s, >, need, to, build, wine, from, sources, ,, but, is, is, too, complicated, under, working,\n",
      "\t\tsystem, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, s, >, lets, wait, :, d, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, want, make, something, like, chroot, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, luckybunny, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, <, user, >, :, i, understand, ,, thank, you, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, <, user, >, :, but, ubuntu, desktop, is, builded, by, ubuntu, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 33 with text: \n",
      " \t\t[<, s, >, <, user, >, :, ok, i, rebooted, ,, the, prompt, says, that, my, current, hardware,\n",
      "\t\tenablement, stack, hwe, is, no, longer, supported, since, <, unk#-, >, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 30 with text: \n",
      " \t\t[<, s, >, how, do, i, correct, package, dependency, problems, when, doing, a, tasksel, of, <,\n",
      "\t\tunka-/, >, and, one, creates, a, problem, for, the, other, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, ubntu, gnome, i, mean, however, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, user, >, :, and, <, unka, >, does, n't, starts, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, s, >, i, try, installing, xfce, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 27 with text: \n",
      " \t\t[<, s, >, <, user, >, :, can, you, paste, the, exact, error, message, for, the, \", stack, hwe, is,\n",
      "\t\tno, longer, supported, \", <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 54 with text: \n",
      " \t\t[<, s, >, i, do, n't, get, any, panel, after, login, already, reinstalled, lightdm, ,, unity, ,,\n",
      "\t\tubuntu, -, desktop, ..., no, avail, ,, already, deleted, DIR/~/, DIR/.config/, ,, does, n't, change,\n",
      "\t\tanything, ., i, can, start, ccsm, but, it, has, no, <, unka-, >, ., over, tty1, unity, is,\n",
      "\t\tactivated, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, how, to, fix, that, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, hm, i, will, not, find, the, message, back, ,, this, terminal, is, very, raw, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, ciao, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, <, user, >, :, kinda, lost, on, ideas, here, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, :/, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, s, >, it, is, xubuntu, 14.04, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 33 with text: \n",
      " \t\t[<, s, >, i, am, running, ubuntu, 14.04, ., can, i, run, a, self, <, user, >, in, ', disks, ',\n",
      "\t\twhile, i, ', m, logged, into, ubuntu, ?, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, user, >, :, disk, tests, are, best, from, live, sesion, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, s, >, +, s, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 42 with text: \n",
      " \t\t[<, s, >, <, user, >, :, afaik, ,, no, ., good, reason, to, have, a, boot, up, usb, to, run, those,\n",
      "\t\ttests, ., i, 'd, recommend, parted, magic, ,, but, that, 's, a, pay, for, app, now, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, s, >, <, user, >, :, the, message, is, like, this, one, URL, /, http:/, URL, /, askubuntu.com/,\n",
      "\t\t<, unk#a-/, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, s, >, <, user, >, :, how, long, will, those, tests, take, for, a, 1, tb, hdd, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, unka, >, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, unka, >, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, <, user, >, :, how, long, is, a, piece, of, string, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, <, unka, >, string, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, :, can, you, try, answer, #, 4, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 46 with text: \n",
      " \t\t[<, s, >, just, installing, xfce, desktop, on, my, ubuntu, unity, ,, and, ripped, off, the, unity,\n",
      "\t\tdesktop, ,, and, now, my, ubuntu, turns, xubuntu, ,, but, i, have, a, lil, problem, with, uget, ,,\n",
      "\t\tit, ai, nt, working, anymore, ,, any, solution, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, what, did, you, exactly, remove, ?, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, s, >, <, user, >, :, URL, /, https:/, URL, /, sites.google.com/, <, unka/, >, ,, read, the, c,\n",
      "\t\t., cleanup, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, <, user, >, :, i, installed, some, things, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, now, i, can, see, the, login, screen, in, graphic, mode, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, but, i, still, ca, n't, login, for, real, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, <, user, >, :, you, ca, nt, login, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, qwerty, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, s, >, when, i, login, and, type, password, ,, the, screen, goes, black, ,, and, goes, back, to,\n",
      "\t\tlogin, choice, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, some, of, the, packages, listed, on, the, askubuntu, page, do, not, seem, to, exist, <,\n",
      "\t\t/s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, s, >, and, i, can, not, copy, and, paste, them, with, the, computer, who, needs, that, :, d, <,\n",
      "\t\t/s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, :, but, x, now, works, ?, did, you, reboot, it, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, x, works, ,, just, for, login, screen, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, s, >, deluge, does, nt, start, anymore, for, me, ,, how, do, uninstall, and, reinstall, a,\n",
      "\t\tprogram, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 29 with text: \n",
      " \t\t[<, s, >, how, long, will, it, take, to, run, a, self, <, user, >, from, ', disks, ', for, a, 1, tb,\n",
      "\t\thdd, ?, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 34 with text: \n",
      " \t\t[<, s, >, <, user, >, :, maybe, autoremove, removed, something, else, ,, you, also, did, n't, need,\n",
      "\t\tto, remove, unity, ,, let, it, alone, or, better, do, a, fresh, install, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, i, know, i, have, one, bad, sector, ..., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, <, user, >, :, ^, ups, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, rebooting, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, <, user, >, :, ok, good, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, s, >, <, user, >, :, still, ,, i, did, a, reinstalling, of, uget, but, it, wo, nt, work, too, <,\n",
      "\t\t/s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, nope, ,, still, the, same, error, after, login, with, x, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 41 with text: \n",
      " \t\t[<, s, >, <, user, >, :, ', how, long, is, a, piece, of, <, unka, ', >, means, ', i, have, no, idea,\n",
      "\t\tand, nobody, else, does, <, unka, ', >, ., share, your, smartctl, output, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, s, >, <, user, >, :, URL, /, http:/, URL, /, askubuntu.com/, <, unk#a-/, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, unka, >, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, s, >, <, user, >, :, i, think, answer, #, 9, will, be, most, helpful, for, you, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 27 with text: \n",
      " \t\t[<, s, >, <, unka, >, ,, now, i, have, logged, in, ,, but, i, have, no, icons, ,, working, bar, or,\n",
      "\t\tprograms, launched, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, just, the, background, and, the, cursor, working, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, hi, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, user, >, :, and, you, moved, the, .xauthority, file, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, i, moved, it, to, <, unka, ., >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, anyone, here, can, help, plz, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, :, at, least, one, step, closer, ..., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, dude, can, help, plz, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, !, ask, |, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 62 with text: \n",
      " \t\t[<, s, >, <, user, >, :, please, do, n't, ask, to, ask, a, question, ,, simply, ask, the, question,\n",
      "\t\t(, all, on, one, line, and, in, the, channel, ,, so, that, others, can, read, and, follow, it,\n",
      "\t\teasily, ), ., if, anyone, knows, the, answer, they, will, most, likely, reply, ., :, -, ), see,\n",
      "\t\talso, !, patience, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, unka, >, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, s, >, <, user, >, :, sudo, chmod, -x, DIR, /, usr/, DIR, /, bin/, <, unka/, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, i, am, doing, a, dist, upgrade, as, in, answer, #, 9, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, so, ,, i, get, busybox, failed, to, mount, something, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, s, >, dammit, 100kb, /, s, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 40 with text: \n",
      " \t\t[<, s, >, hi, everyone, ,, i, ', m, interested, in, a, minimal, ubuntu, install, and, noticed, the,\n",
      "\t\tubuntu, minimal, image, does, n't, contain, efi, support, ., would, using, ubuntu, server, as, a,\n",
      "\t\tbase, be, ok, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, s, >, how, to, fix, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, s, >, <, user, >, :, here, 's, the, output, for, smartctl, URL, /, http:/, URL, /,\n",
      "\t\tpaste.ubuntu.com/, <, unk#a/, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, user, >, :, check, .xsession, -, errors, for, any, clues, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 28 with text: \n",
      " \t\t[<, s, >, <, user, >, :, and, what, 's, the, story, behind, what, 's, leading, you, to, want, to,\n",
      "\t\tperform, a, disk, check, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, :, what, problem, do, you, have, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, user, >, :, i, do, n't, have, an, .xsession, file, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, s, >, <, user, >, :, that, depends, ,, do, you, want, a, server, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, i, get, something, like, this, ,, is, my, data, damaged, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, URL, /, http:/, URL, /, askubuntu.com/, <, unk#a-/, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, no, it, 's, for, a, minimalist, desktop, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 26 with text: \n",
      " \t\t[<, s, >, <, user, >, :, in, your, home, directory, ,, you, do, nt, have, a, file, called,\n",
      "\t\t.xsession, -, errors, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, nop, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, :, boot, a, live, session, to, investigate, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, damn, ,, yes, i, do, have, one, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, <, user, >, :, =, ), <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, why, the, auto, complete, does, n't, show, it, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, did, you, autocomplete, for, a, hidden, file, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 27 with text: \n",
      " \t\t[<, s, >, i, was, getting, input, /, output, error, while, accessing, a, folder, ..., ran, disks,\n",
      "\t\t...., there, 's, one, bad, sector, .., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, <, user, >, :, ^, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, <, unka, >, :, d, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 39 with text: \n",
      " \t\t[<, s, >, <, user, >, :, yeah, it, 's, still, pending, and, has, n't, been, reallocated, yet, ., i,\n",
      "\t\twould, backup, the, data, ,, then, use, a, manufacturer, utility, to, zero, fill, the, entire, disk,\n",
      "\t\t<, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, the, xsession, -, errors, has, few, lines, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, s, >, <, user, >, :, if, the, disk, is, in, warranty, ,, you, could, rma, it, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, s, >, <, user, >, :, well, if, my, disk, is, about, to, die, ,, live, session, will, kill, it,\n",
      "\t\t<, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, :, no, ,, no, it, wo, n't, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 26 with text: \n",
      " \t\t[<, s, >, <, unka, >, :, connect, :, no, file, or, folder, like, this, ,, can, not, connect, to,\n",
      "\t\tbrltty, at, :0, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, <, user, >, :, <, unka, >, ot, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 33 with text: \n",
      " \t\t[<, s, >, <, user, >, :, what, part, of, booting, a, live, session, from, a, dvd, or, usb, flash,\n",
      "\t\tdrive, do, you, consider, to, affect, a, hard, disk, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, s, >, it, turns, on, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 42 with text: \n",
      " \t\t[<, s, >, <, user, >, :, that, 's, not, how, it, works, ., boot, a, live, session, ,, install,\n",
      "\t\tsmartmontools, and, pastebinit, ,, then, run, \", sudo, smartctl, -a, DIR, /, dev/, DIR, /, sda/, |,\n",
      "\t\tpastebinit, \", <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 44 with text: \n",
      " \t\t[<, s, >, <, user, >, :, check, \", dpkg, --get, -, selections, |, grep, ubuntu, -, session, \", if,\n",
      "\t\tthat, is, installed, do, a, dpkg, -, reconfigure, on, it, .., if, its, is, not, installed, ,,\n",
      "\t\tinstall, it, =, ), <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, ok, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, unka, >, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 66 with text: \n",
      " \t\t[<, s, >, is, there, anyone, who, knows, how, these, things, with, munich, city, and, <, unka, >, (,\n",
      "\t\tforked, from, ubuntu, ), finished, ., i, know, that, they, decided, to, call, it, staff, to,\n",
      "\t\treconsider, using, linux, since, many, of, the, users, complained, ., i, ca, n't, find, what,\n",
      "\t\thappened, ., is, there, anyone, who, knows, more, recent, details, about, this, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, hah, ,, no, problem, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, s, >, <, user, >, :, this, channel, is, for, ubuntu, support, ,, nothing, to, do, with,\n",
      "\t\tanything, beyond, that, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, thanks, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, unka, _, >, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, s, >, <, user, >, :, URL, /, http:/, URL, /, pastebin.com/, <, unk#a/, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, unka, _, >, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 61 with text: \n",
      " \t\t[<, s, >, <, user, >, :, you, have, 1, pending, sector, and, 2, reallocated, ,, as, per, lines, 58,\n",
      "\t\tand, 59, ., no, way, of, telling, if, that, happened, now, ,, but, i, would, backup, the, data, ,,\n",
      "\t\tzero, the, entire, drive, with, a, manufacturer, tool, (, or, use, ', dd, ', ), then, restore, your,\n",
      "\t\tbackup, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, alessandro, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, disk, or, not, broken, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, s, >, disk, is, not, *, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, it, could, have, problems, in, the, future, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, backup, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 27 with text: \n",
      " \t\t[<, s, >, ubuntu, 14.04, software, center, hung, applying, changes, i, tried, xkill, and, i, ca,\n",
      "\t\tn't, shut, it, down, to, remove, and, reinstall, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 26 with text: \n",
      " \t\t[<, s, >, <, user, >, :, not, hugely, ,, but, it, could, carry, on, and, get, worse, ., no, way, of,\n",
      "\t\tknowing, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 28 with text: \n",
      " \t\t[<, s, >, <, user, >, :, ah, actually, i, do, n't, like, the, raw, read, error, rate, ,, line, <,\n",
      "\t\tunk, #, #, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, s, >, <, user, >, :, backup, and, consider, replacing, ,, that, thing, is, tiny, and, old, <,\n",
      "\t\t/s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 27 with text: \n",
      " \t\t[<, s, >, ubuntu, 14.04, software, center, hung, applying, changes, i, tried, xkill, and, i, ca,\n",
      "\t\tn't, shut, it, down, to, remove, and, reinstall, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, how, do, i, shut, it, off, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, s, >, are, there, ubuntu, images, that, fit, on, cds, anymore, ?, i, ca, n't, find, them, <, /s,\n",
      "\t\t>]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, i, need, help, installing, ubuntu, from, a, dvd, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, the, mini, or, lubuntu, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, :, those, are, my, only, options, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, s, >, <, user, >, :, no, ,, but, lubuntu, still, fits, on, a, cd, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, lxde, is, so, ugly, ,, so, i, 'll, go, with, mini, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 27 with text: \n",
      " \t\t[<, s, >, after, i, pull, up, the, purple, menu, and, select, the, try, ubuntu, option, ,, it, just,\n",
      "\t\tgoes, to, a, blank, screen, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, with, ubuntu, and, a, cd, load, yes, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 33 with text: \n",
      " \t\t[<, s, >, <, user, >, :, how, long, have, it, been, hung, ?, have, you, checked, top, to, see, if,\n",
      "\t\tthere, is, any, process, that, hogs, the, cpu, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, :, <, user, >, :, thanks, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 6 with text: \n",
      " \t\t[<, s, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, s, >, i, have, linux, mint, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 23 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, if, you, have, grub, now, you, can, boot, the, iso, from, it, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, in, case, you, need, it, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 8 with text: \n",
      " \t\t[<, s, >, the, info, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, !, mint, |, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 30 with text: \n",
      " \t\t[<, s, >, <, user, >, :, linux, mint, is, not, a, supported, derivative, of, ubuntu, ., please,\n",
      "\t\tseek, support, in, #, linuxmint, -, help, on, irc.spotchat.org, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, root, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 27 with text: \n",
      " \t\t[<, s, >, ubuntu, 14.04, software, center, hung, applying, changes, i, tried, xkill, and, i, ca,\n",
      "\t\tn't, shut, it, down, to, remove, and, reinstall, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 27 with text: \n",
      " \t\t[<, s, >, ubuntu, 14.04, software, center, hung, applying, changes, i, tried, xkill, and, i, ca,\n",
      "\t\tn't, shut, it, down, to, remove, and, reinstall, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, well, i, am, trying, to, replace, it, with, ubuntu, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, how, do, i, shut, it, off, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, ah, sorry, ,, did, n't, see, that, part, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, !, nomodeset, |, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 54 with text: \n",
      " \t\t[<, s, >, <, user, >, :, a, common, kernel, (, boot)parameter, is, nomodeset, ,, which, is, needed,\n",
      "\t\tfor, some, graphic, cards, that, otherwise, boot, into, a, black, screen, or, show, corrupted,\n",
      "\t\tsplash, screen, ., see, URL, /, http:/, URL, /, ubuntuforums.org/, URL, /,\n",
      "\t\tshowthread.php?t=1613132/, on, how, to, use, this, parameter, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, s, >, anyone, know, why, i, ', m, getting, \", no, talloc, <, unka, >, \", errors, on, my,\n",
      "\t\t14.04.1, server, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, also, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, s, >, from, what, i, remember, ,, it, had, something, to, do, with, the, samba, server,\n",
      "\t\timplementation, in, this, version, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, <, user, >, :, bug, <, unk, #, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 43 with text: \n",
      " \t\t[<, s, >, bug, <, unk, #, >, in, samba, (, ubuntu, trusty, ), \", memory, leakage, messages, (, no,\n",
      "\t\ttalloc, <, unka, >, ), \", [, high, ,, triaged, ], URL, /, https:/, URL, /, launchpad.net/, <,\n",
      "\t\tunk#a/, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, success, !, !, !, !, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, that, just, saved, my, dad, about, $, 50, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, wait, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, after, the, splash, it, turned, blank, again, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 10 with text: \n",
      " \t\t[<, s, >, drive, is, still, spinning, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 29 with text: \n",
      " \t\t[<, s, >, if, you, 're, booting, from, dvd, ,, which, is, horrible, in, 2014, btw, ,, it, 's,\n",
      "\t\tprobably, going, to, take, a, while, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, lol, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, i, 'll, try, this, again, with, the, 64-bit, image, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, shortly, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 56 with text: \n",
      " \t\t[<, s, >, on, 14.04, ,, i, installed, kubuntu, ,, but, then, installed, ubuntu, -, desktop, .,\n",
      "\t\teverything, works, fine, ,, but, my, menu, 's, are, a, bit, difficult, to, read, (, see, URL, /,\n",
      "\t\thttp:/, URL, /, ibin.co/, <, unk#a/, >, ), and, i, ca, n't, find, a, way, to, resolve, this, <, /s,\n",
      "\t\t>]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 22 with text: \n",
      " \t\t[<, s, >, uhhh, ,, where, can, i, get, a, cross, compiler, compatible, for, <, unka, >, 2.1, ?, <,\n",
      "\t\t/s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, <, user, >, :, and, usb, flash, drive, ,, please, !, :), <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, i, do, n't, think, that, my, pc, can, usb, boot, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 29 with text: \n",
      " \t\t[<, s, >, <, user, >, :, ahh, !, yes, !, so, ,, what, <, unka, >, should, i, expect, from, removing,\n",
      "\t\tlibpam, -, smbpass, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, and, it, has, booted, !, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, :, how, old, is, this, machine, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, s, >, or, should, i, look, at, removing, smb, server, alltogether, ?, i, ', m, definetly, not,\n",
      "\t\tusing, it, ..., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, 2009, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, unka-, _, >, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 39 with text: \n",
      " \t\t[<, s, >, <, user, >, :, ok, that, 's, not, the, end, of, it, ,, ideally, you, need, to, identify,\n",
      "\t\twhat, graphics, hardware, it, uses, and, install, proper, drivers, (, if, needed, ), after,\n",
      "\t\tinstalling, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 49 with text: \n",
      " \t\t[<, s, >, <, user, >, :, what, do, you, mean, by, hard, to, read, ., in, that, picture, some,\n",
      "\t\toptions, like, \", full, screen, \", are, \", greyed, out, \", and, that, is, why, it, looks, like,\n",
      "\t\tthat, ., you, can, not, select, that, option, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 42 with text: \n",
      " \t\t[<, s, >, <, user, >, :, yeah, if, you, are, not, using, it, ,, there, are, n't, any, problems,\n",
      "\t\treally, ,, the, bug, has, a, few, comments, detailing, the, issues, it, can, cause, if, you, are,\n",
      "\t\tusing, it, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, :, i, removed, it, months, ago, just, to, stop, the, message, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, i, can, tell, you, the, model, of, computer, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, hp, pavilion, <, unk#a, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 28 with text: \n",
      " \t\t[<, s, >, <, user, >, :, the, thing, is, ,, they, are, n't, \", greyed, out, \", ,, i, can, totally,\n",
      "\t\tselect, that, option, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, switching, to, 64, bit, image, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, :, awesome, ., uninstalling, now, ., thanks, for, the, help, !, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 27 with text: \n",
      " \t\t[<, s, >, <, user, >, :, i, do, n't, have, time, to, assist, further, now, unfortunately, ,, get,\n",
      "\t\tit, installed, then, come, back, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, ok, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 25 with text: \n",
      " \t\t[<, s, >, <, user, >, :, hmm, ..., have, you, made, any, other, changes, ?, like, installed, any,\n",
      "\t\tnew, themes, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, no, ,, just, installed, ubuntu, -, desktop, from, kubuntu, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, :, you, 're, using, kubuntu, and, installed, ubuntu, -, desktop, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, :, yes, ,, i, switched, to, ubuntu, -, desktop, from, kubuntu, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 33 with text: \n",
      " \t\t[<, s, >, <, user, >, :, <, user, >, here, is, another, image, showing, how, it, 's, difficult, to,\n",
      "\t\tsee, URL, /, http:/, URL, /, ibin.co/, <, unk#a/, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 38 with text: \n",
      " \t\t[<, s, >, <, user, >, :, understand, that, this, is, the, ubuntu, support, room, and, kubuntu,\n",
      "\t\tsupport, is, #, kubuntu, ., since, you, 're, using, ubuntu, -, desktop, in, kubuntu, your, mileage,\n",
      "\t\tmay, vary, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 26 with text: \n",
      " \t\t[<, s, >, <, user, >, :, but, i, ', m, not, using, kubuntu, ,, i, ', m, using, ubuntu, -, desktop,\n",
      "\t\tnow, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, <, user, >, :, what, was, the, base, system, you, installed, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, kubuntu, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, right, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 34 with text: \n",
      " \t\t[<, s, >, <, user, >, :, kubuntu, is, just, ubuntu, with, kde, installed, by, default, instead, of,\n",
      "\t\tunity, ., <, user, >, is, in, the, right, place, for, support, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 39 with text: \n",
      " \t\t[<, s, >, <, user, >, :, you, do, realize, that, kubuntu, is, just, a, base, ubuntu, install, with,\n",
      "\t\tkde, and, such, packages, ., while, ubuntu, is, a, base, ubuntu, install, with, unity, and, such,\n",
      "\t\tpackages, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 32 with text: \n",
      " \t\t[<, s, >, <, user, >, :, i, ', ve, previously, been, yelled, at, for, suggesting, that, so, i,\n",
      "\t\tapologise, ,, i, must, just, be, behind, the, policy, here, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 15 with text: \n",
      " \t\t[<, s, >, <, user, >, :, i, understand, the, differences, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, s, >, <, user, >, :, check, if, you, have, gnome, -, icon, -, theme, <, unka-, >, installed,\n",
      "\t\t..., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 34 with text: \n",
      " \t\t[<, s, >, <, user, >, :, looks, like, i, do, n't, have, <, unka-, >, ., some, further,\n",
      "\t\tinvestigation, indicates, it, 's, just, an, issue, with, the, unity, ambiance, theme, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, <, user, >, :, ok, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, i, missed, stuff, from, here, thanks, to, a, blackout, and, net, disconnect, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 39 with text: \n",
      " \t\t[<, s, >, help, ,, why, do, i, get, this, error, ?, bash, :, can, not, create, temp, file, for, <,\n",
      "\t\tunka-, >, :, no, space, left, on, device, ., i, have, lots, of, free, space, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 65 with text: \n",
      " \t\t[<, s, >, hello, there, ladies, and, gents, ., i, am, currently, in, the, installation, process, of,\n",
      "\t\tubuntu, on, my, windows, 8.1, pc, ., i, have, created, a, bootable, usb, drive, ., i, am, at, the,\n",
      "\t\tstage, where, it, is, asking, me, to, partition, my, drive, ., how, do, i, keep, my, windows,\n",
      "\t\tpartition, and, create, a, new, area, for, ubuntu, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, s, >, why, can, i, not, connect, to, sourceforge, using, wget, through, a, beaglebone, black, ?,\n",
      "\t\tcan, anyone, help, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 7 with text: \n",
      " \t\t[<, s, >, hi, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, michael, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, can, anyone, help, me, with, dual, booting, and, partitioning, ,, please, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, literally, first, hit, on, google, URL, /, http:/, URL, /, itsfoss.com/, <, unk#a-/, >, <,\n",
      "\t\t/s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 84 with text: \n",
      " \t\t[<, s, >, hey, ,, i, wonder, if, anyone, can, help, me, ,, i, have, just, done, an, install, of,\n",
      "\t\t12.04, lts, 5, ,, and, are, trying, to, install, <, unka-, >, amongst, other, packages, .,\n",
      "\t\tinitially, thought, maybe, that, package, was, renamed, ,, but, it, seems, even, irssi, ca, nt, be,\n",
      "\t\tinstalled, ., why, is, every, package, i, try, to, use, coming, up, as, \", e, :, package, <, unka,\n",
      "\t\t', [, ], >, has, no, installation, candidate, \", ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 33 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, you, should, resize, widows, with, it, 's, disk, manager, leaving, a,\n",
      "\t\tunallocated, for, ubuntu, ,, follow, the, <, unka, >, if, needed, ., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 20 with text: \n",
      " \t\t[<, s, >, <, user, >, thank, you, ,, i, was, following, a, different, guide, on, ubuntu, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, best, website, to, guide, you, on, securing, ubuntu, and, your, browser, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, <, user, >, :, does, sudo, apt, -, get, update, work, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 23 with text: \n",
      " \t\t[<, s, >, <, user, >, :, there, is, no, best, ., but, there, are, thousands, of, howtos, out, there,\n",
      "\t\t<, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, s, >, why, can, i, not, connect, to, sourceforge, using, wget, through, a, beaglebone, black, ?,\n",
      "\t\tcan, anyone, help, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 33 with text: \n",
      " \t\t[<, s, >, <, user, >, :, sort, of, ,, it, comes, at, the, end, with, some, signature, error, ,, i,\n",
      "\t\tshall, re, -, run, it, to, get, exact, message, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, unka[|, >, ], is, now, known, as, <, user, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, :, what, os, are, you, running, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, <, user, >, :, ubuntu, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 11 with text: \n",
      " \t\t[<, s, >, lots, of, hash, mismatches, !, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 18 with text: \n",
      " \t\t[<, s, >, all, urls, listed, seem, to, be, all, my, entries, in, sources.lst, too, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, user, >, :, can, you, wget, any, other, site, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 47 with text: \n",
      " \t\t[<, s, >, <, user, >, :, lots, of, horrible, ones, too, ., lol, maybe, this, a, good, places, to,\n",
      "\t\tstart, ?, URL, /, https:/, URL, /, wiki.ubuntu.com/, <, unka/, >, then, maybe, here, ?, URL, /,\n",
      "\t\thttp:/, <, unka./, >, <, unka-/, >, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 9 with text: \n",
      " \t\t[<, s, >, i, wonder, ..., <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, perhaps, it, is, isp, censoring, it, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 24 with text: \n",
      " \t\t[<, s, >, <, user, >, :, nope, ,, i, am, using, ssh, to, connect, to, the, beaglebone, if, that,\n",
      "\t\thelps, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 30 with text: \n",
      " \t\t[<, s, >, <, user, >, :, i, would, start, with, the, question, :, what, do, you, want, to, secure,\n",
      "\t\t?, and, why, do, you, want, it, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 17 with text: \n",
      " \t\t[<, s, >, <, user, >, :, does, dig, sourceforge.net, provide, any, records, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 35 with text: \n",
      " \t\t[<, s, >, error, reading, block, <, unk, #, >, (, <, unka, >, to, read, block, from, filesystem,\n",
      "\t\tresulted, in, short, read, ), ., ignore, <, unka, <, >, >, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 21 with text: \n",
      " \t\t[<, s, >, i, did, yes, ., now, i, get, :, force, <, unka, <, >, >, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, ,, that, s, just, a, bad, idea, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 16 with text: \n",
      " \t\t[<, s, >, <, user, >, :, it, says, dig, command, not, found, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 12 with text: \n",
      " \t\t[<, s, >, <, user, >, :, what, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 19 with text: \n",
      " \t\t[<, s, >, is, there, a, way, to, let, ubuntu, pass, alt, modifier, to, chrome, ?, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 13 with text: \n",
      " \t\t[<, s, >, running, fs, checks, on, a, failing, drive, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t TextField of length 14 with text: \n",
      " \t\t[<, s, >, you, re, begging, for, more, sectors, to, fail, <, /s, >]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \n",
      " \t arcs: AdjacencyField of length 503\n",
      "\t\twith indices:\n",
      " \t\t[(3, 0), (4, 3), (5, 5), (6, 1), (7, 0), (8, 1), (9, 9), (10, 10), (11, 11), (12, 7), (13, 11), (14,\n",
      "\t\t12), (15, 15), (16, 14), (17, 15), (18, 14), (19, 18), (20, 15), (21, 18), (22, 15), (23, 1), (24,\n",
      "\t\t22), (25, 23), (26, 21), (27, 24), (28, 25), (29, 18), (30, 26), (31, 29), (32, 30), (33, 32), (34,\n",
      "\t\t34), (35, 35), (36, 30), (37, 32), (38, 38), (39, 39), (40, 33), (41, 40), (42, 37), (43, 43), (44,\n",
      "\t\t42), (45, 22), (46, 44), (47, 47), (48, 35), (49, 45), (50, 35), (51, 35), (51, 50), (52, 50), (53,\n",
      "\t\t49), (54, 52), (55, 55), (56, 55), (57, 53), (58, 44), (59, 55), (60, 60), (61, 58), (62, 41), (63,\n",
      "\t\t57), (64, 61), (65, 60), (66, 63), (67, 64), (68, 68), (69, 67), (70, 62), (71, 69), (72, 65), (73,\n",
      "\t\t62), (74, 73), (75, 71), (76, 66), (77, 75), (78, 66), (79, 77), (80, 66), (81, 81), (82, 79), (83,\n",
      "\t\t82), (84, 66), (85, 80), (86, 86), (87, 86), (88, 66), (89, 88), (90, 89), (91, 90), (92, 91), (93,\n",
      "\t\t92), (94, 91), (95, 94), (96, 94), (97, 96), (98, 98), (99, 95), (100, 100), (101, 97), (102, 98),\n",
      "\t\t(103, 96), (104, 103), (105, 102), (106, 104), (107, 106), (108, 102), (109, 107), (110, 109), (111,\n",
      "\t\t110), (112, 111), (113, 110), (114, 110), (115, 113), (116, 114), (117, 117), (118, 118), (119,\n",
      "\t\t119), (120, 114), (121, 120), (122, 121), (123, 122), (124, 117), (125, 124), (126, 126), (127,\n",
      "\t\t125), (128, 126), (129, 122), (130, 128), (131, 129), (132, 131), (133, 131), (134, 125), (135,\n",
      "\t\t135), (136, 134), (137, 132), (138, 138), (139, 137), (140, 139), (141, 118), (142, 137), (143,\n",
      "\t\t142), (144, 142), (145, 144), (146, 145), (147, 145), (148, 147), (149, 148), (150, 133), (151,\n",
      "\t\t150), (152, 150), (153, 152), (154, 147), (155, 154), (156, 153), (157, 156), (158, 154), (159,\n",
      "\t\t157), (160, 160), (161, 159), (162, 159), (163, 157), (164, 163), (165, 164), (166, 166), (167,\n",
      "\t\t165), (168, 164), (169, 169), (170, 168), (171, 158), (172, 172), (173, 141), (174, 168), (175,\n",
      "\t\t174), (176, 174), (177, 176), (178, 177), (179, 177), (180, 173), (181, 179), (182, 180), (183,\n",
      "\t\t181), (184, 171), (185, 183), (186, 184), (187, 186), (188, 184), (189, 185), (190, 190), (191,\n",
      "\t\t191), (192, 189), (193, 191), (194, 192), (195, 193), (196, 195), (197, 191), (198, 194), (199,\n",
      "\t\t199), (200, 200), (201, 194), (202, 197), (203, 203), (204, 204), (205, 202), (206, 201), (207,\n",
      "\t\t207), (208, 208), (209, 206), (210, 205), (211, 210), (212, 206), (213, 212), (214, 211), (215,\n",
      "\t\t214), (216, 216), (217, 216), (218, 217), (219, 212), (220, 220), (221, 219), (222, 220), (223,\n",
      "\t\t218), (224, 224), (225, 220), (226, 226), (227, 226), (228, 224), (229, 228), (230, 230), (231,\n",
      "\t\t229), (232, 219), (233, 233), (234, 233), (235, 223), (236, 235), (237, 237), (238, 236), (239,\n",
      "\t\t237), (240, 237), (241, 241), (242, 237), (243, 241), (244, 242), (245, 244), (246, 237), (247,\n",
      "\t\t237), (247, 246), (248, 245), (249, 232), (250, 249), (251, 249), (252, 251), (253, 252), (254,\n",
      "\t\t253), (255, 254), (256, 253), (257, 256), (258, 257), (259, 259), (260, 260), (261, 260), (262,\n",
      "\t\t258), (263, 261), (264, 264), (265, 246), (266, 265), (267, 258), (268, 268), (269, 266), (270,\n",
      "\t\t267), (271, 270), (272, 267), (273, 273), (274, 273), (275, 272), (276, 276), (277, 275), (278,\n",
      "\t\t277), (279, 278), (280, 280), (281, 280), (282, 281), (283, 280), (284, 277), (285, 281), (286,\n",
      "\t\t286), (287, 287), (288, 285), (289, 288), (290, 284), (291, 291), (292, 291), (293, 292), (294,\n",
      "\t\t290), (295, 294), (296, 295), (297, 294), (298, 298), (299, 297), (300, 299), (301, 300), (302,\n",
      "\t\t299), (303, 302), (304, 304), (305, 288), (306, 292), (307, 305), (308, 306), (309, 303), (310,\n",
      "\t\t309), (311, 308), (312, 310), (313, 289), (314, 312), (315, 315), (316, 312), (317, 316), (318,\n",
      "\t\t317), (319, 319), (320, 317), (321, 320), (322, 322), (323, 321), (324, 324), (325, 322), (326,\n",
      "\t\t325), (326, 322), (327, 327), (328, 321), (329, 328), (330, 330), (331, 329), (332, 332), (333,\n",
      "\t\t330), (334, 313), (335, 329), (336, 334), (337, 322), (338, 335), (339, 332), (340, 340), (341,\n",
      "\t\t340), (342, 339), (343, 338), (344, 343), (345, 341), (346, 343), (347, 346), (348, 347), (349,\n",
      "\t\t348), (350, 336), (351, 350), (352, 349), (353, 350), (354, 352), (355, 351), (356, 345), (357,\n",
      "\t\t356), (358, 354), (359, 357), (360, 359), (361, 360), (362, 361), (363, 358), (364, 362), (365,\n",
      "\t\t365), (366, 366), (367, 263), (368, 366), (369, 368), (370, 370), (371, 371), (372, 372), (373,\n",
      "\t\t362), (374, 374), (375, 375), (376, 373), (377, 377), (378, 376), (379, 378), (380, 380), (381,\n",
      "\t\t380), (382, 382), (383, 378), (384, 383), (385, 384), (386, 382), (387, 386), (388, 388), (389,\n",
      "\t\t389), (390, 388), (391, 390), (392, 388), (393, 390), (394, 394), (395, 391), (396, 387), (397,\n",
      "\t\t395), (398, 394), (399, 398), (400, 397), (401, 399), (402, 401), (403, 399), (404, 403), (404,\n",
      "\t\t399), (405, 405), (406, 382), (407, 382), (408, 403), (409, 382), (410, 408), (411, 408), (412,\n",
      "\t\t411), (412, 408), (413, 413), (414, 414), (415, 413), (416, 413), (417, 416), (418, 411), (419,\n",
      "\t\t418), (420, 419), (421, 420), (422, 421), (423, 422), (424, 423), (425, 424), (426, 425), (427,\n",
      "\t\t427), (428, 428), (429, 426), (430, 429), (431, 416), (432, 430), (433, 430), (434, 431), (435,\n",
      "\t\t433), (436, 436), (437, 435), (438, 427), (439, 434), (440, 439), (441, 437), (442, 441), (443,\n",
      "\t\t438), (444, 444), (445, 442), (446, 440), (447, 445), (448, 447), (449, 443), (450, 449), (451,\n",
      "\t\t450), (452, 451), (453, 449), (454, 452), (455, 454), (456, 455), (457, 456), (458, 457), (459,\n",
      "\t\t458), (460, 458), (461, 459), (462, 460), (463, 460), (464, 463), (465, 464), (466, 466), (467,\n",
      "\t\t467), (468, 468), (469, 469), (470, 470), (471, 471), (472, 472), (473, 472), (474, 474), (475,\n",
      "\t\t472), (476, 475), (477, 477), (478, 478), (479, 474), (480, 477), (481, 469), (482, 479), (483,\n",
      "\t\t483), (484, 469), (485, 484), (486, 482), (487, 486), (488, 485), (489, 480), (490, 487), (491,\n",
      "\t\t490), (492, 488), (493, 489), (494, 492), (495, 495), (496, 495), (497, 495), (498, 494), (499,\n",
      "\t\t497), (500, 500), (501, 499), (502, 499)]\n",
      "\n",
      "\t\tand labels:\n",
      " \t\tNone\n",
      " \t\tin namespace: 'labels'. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muller/anaconda3/envs/allennlp/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "400000it [00:02, 133390.46it/s]\n"
     ]
    }
   ],
   "source": [
    "turn_encoder_cfg = Params({\"type\":\"gru\",'input_size': 100, 'hidden_size': 50, 'num_layers': 1,\n",
    "                  'dropout': 0.25, 'bidirectional': False\n",
    "})\n",
    "#can be changed dynamically encoder_cfg[\"type\"] = \"lstm\"\n",
    "# warning: if bidirectional, state output dimension is hidden_size x 2 -> model doesn't know that\n",
    "\n",
    "turn_encoder = Seq2VecEncoder.from_params(turn_encoder_cfg)\n",
    "turn_encoder.hidden_size = turn_encoder_cfg[\"hidden_size\"]\n",
    "\n",
    "\n",
    "chat_encoder_cfg = Params({\"type\":\"gru\",'input_size': 50, 'hidden_size': 50, 'num_layers': 1,\n",
    "                  'dropout': 0.25, 'bidirectional': False\n",
    "})\n",
    "chat_encoder = Seq2SeqEncoder.from_params(chat_encoder_cfg)\n",
    "chat_encoder.hidden_size = chat_encoder_cfg[\"hidden_size\"]\n",
    "\n",
    "\n",
    "\n",
    "glove_text_field_embedder = Embedding.from_params(vocab,Params({\"pretrained_file\": \"https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz\",\n",
    "                                                          \"embedding_dim\": 100,\n",
    "                                                          \"trainable\": False\n",
    "}))\n",
    "\n",
    "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "                            embedding_dim=100)\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chat_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from biaffine parser, another config (not used)\n",
    "chat_encoder_cfg =  {\n",
    "            \"type\": \"stacked_bidirectional_lstm\",\n",
    "            \"hidden_size\": 400,\n",
    "            \"input_size\": 200,\n",
    "            \"num_layers\": 3,\n",
    "            \"recurrent_dropout_probability\": 0.3,\n",
    "            \"use_highway\": True\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models import Model\n",
    "from typing import Dict, List, Iterable\n",
    "from allennlp.modules import TimeDistributed\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models import Model\n",
    "from allennlp.common.checks import check_dimensions_match, ConfigurationError\n",
    "from allennlp.data import Vocabulary\n",
    "from allennlp.modules import Seq2SeqEncoder, TextFieldEmbedder, Embedding, InputVariationalDropout\n",
    "from allennlp.modules.matrix_attention.bilinear_matrix_attention import BilinearMatrixAttention\n",
    "from allennlp.modules import FeedForward\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.nn import InitializerApplicator, Activation\n",
    "#???? TODO from allennlp.nn.util import min_value_of_dtype -> only allennlp >= 1.0\n",
    "def min_value_of_dtype(dtype: torch.dtype):\n",
    "    \"\"\"\n",
    "    Returns the minimum value of a given PyTorch data type. Does not allow torch.bool.\n",
    "    \"\"\"\n",
    "    return info_value_of_dtype(dtype).min\n",
    "def info_value_of_dtype(dtype: torch.dtype):\n",
    "    \"\"\"\n",
    "    Returns the `finfo` or `iinfo` object of a given PyTorch data type. Does not allow torch.bool.\n",
    "    \"\"\"\n",
    "    if dtype == torch.bool:\n",
    "        raise TypeError(\"Does not support torch.bool\")\n",
    "    elif dtype.is_floating_point:\n",
    "        return torch.finfo(dtype)\n",
    "    else:\n",
    "        return torch.iinfo(dtype)\n",
    "\n",
    "\n",
    "from allennlp.nn.util import get_text_field_mask\n",
    "from allennlp.nn.util import get_lengths_from_binary_sequence_mask\n",
    "from allennlp.training.metrics import F1Measure\n",
    "\n",
    "import copy\n",
    "from overrides import overrides\n",
    "import torch\n",
    "from torch.nn.modules import Dropout\n",
    "import numpy\n",
    "\n",
    "class ChatGraphParser(Model):\n",
    "    \"\"\"\n",
    "    A Parser for arbitrary graph structures.\n",
    "\n",
    "    Registered as a `Model` with name \"graph_parser\".\n",
    "\n",
    "    # Parameters\n",
    "\n",
    "    vocab : `Vocabulary`, required\n",
    "        A Vocabulary, required in order to compute sizes for input/output projections.\n",
    "    text_field_embedder : `TextFieldEmbedder`, required\n",
    "        Used to embed the `tokens` `TextField` we get as input to the model.\n",
    "    encoder : `Seq2SeqEncoder`\n",
    "        The encoder (with its own internal stacking) that we will use to generate representations\n",
    "        of tokens.\n",
    "    tag_representation_dim : `int`, required.\n",
    "        The dimension of the MLPs used for arc tag prediction.\n",
    "    arc_representation_dim : `int`, required.\n",
    "        The dimension of the MLPs used for arc prediction.\n",
    "    tag_feedforward : `FeedForward`, optional, (default = None).\n",
    "        The feedforward network used to produce tag representations.\n",
    "        By default, a 1 layer feedforward network with an elu activation is used.\n",
    "    arc_feedforward : `FeedForward`, optional, (default = None).\n",
    "        The feedforward network used to produce arc representations.\n",
    "        By default, a 1 layer feedforward network with an elu activation is used.\n",
    "    pos_tag_embedding : `Embedding`, optional.\n",
    "        Used to embed the `pos_tags` `SequenceLabelField` we get as input to the model.\n",
    "    dropout : `float`, optional, (default = 0.0)\n",
    "        The variational dropout applied to the output of the encoder and MLP layers.\n",
    "    input_dropout : `float`, optional, (default = 0.0)\n",
    "        The dropout applied to the embedded text input.\n",
    "    edge_prediction_threshold : `int`, optional (default = 0.5)\n",
    "        The probability at which to consider a scored edge to be 'present'\n",
    "        in the decoded graph. Must be between 0 and 1.\n",
    "    initializer : `InitializerApplicator`, optional (default=`InitializerApplicator()`)\n",
    "        Used to initialize the model parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab: Vocabulary,\n",
    "        text_field_embedder: TextFieldEmbedder,\n",
    "        turn_encoder: Seq2VecEncoder, \n",
    "        chat_encoder: Seq2SeqEncoder,\n",
    "        arc_representation_dim: int,\n",
    "        arc_feedforward: FeedForward = None,\n",
    "        dropout: float = 0.0,\n",
    "        input_dropout: float = 0.0,\n",
    "        edge_prediction_threshold: float = 0.5,\n",
    "        initializer: InitializerApplicator = InitializerApplicator(),\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(vocab, **kwargs)\n",
    "        \n",
    "        self.text_field_embedder = text_field_embedder\n",
    "        self.turn_encoder = TimeDistributed(turn_encoder)\n",
    "        self.chat_encoder = chat_encoder\n",
    "        \n",
    "        self.edge_prediction_threshold = edge_prediction_threshold\n",
    "        if not 0 < edge_prediction_threshold < 1:\n",
    "            raise ConfigurationError(\n",
    "                f\"edge_prediction_threshold must be between \"\n",
    "                f\"0 and 1 (exclusive) but found {edge_prediction_threshold}.\"\n",
    "            )\n",
    "\n",
    "        encoder_dim = chat_encoder.get_output_dim()\n",
    "\n",
    "        self.head_arc_feedforward = arc_feedforward or FeedForward(\n",
    "            encoder_dim, 1, arc_representation_dim, Activation.by_name(\"elu\")()\n",
    "        )\n",
    "        self.child_arc_feedforward = copy.deepcopy(self.head_arc_feedforward)\n",
    "\n",
    "        self.arc_attention = BilinearMatrixAttention(\n",
    "            arc_representation_dim, arc_representation_dim, use_input_biases=True\n",
    "        )\n",
    "\n",
    "        self._dropout = InputVariationalDropout(dropout)\n",
    "        self._input_dropout = Dropout(input_dropout)\n",
    "\n",
    "        representation_dim = turn_encoder.get_output_dim()\n",
    "\n",
    "        self._unlabelled_f1 = F1Measure(positive_label=1)\n",
    "        self._arc_loss = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "        initializer(self)\n",
    "        # useful for debugging\n",
    "        self.iter_count = 0 \n",
    "        \n",
    "    # init done\n",
    "        \n",
    "    # todo \n",
    "    @overrides\n",
    "    def forward(\n",
    "        self,  # type: ignore\n",
    "        lines,\n",
    "        arcs: torch.LongTensor = None,\n",
    "        metadata: List[Dict[str, Any]] = None,\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "\n",
    "        \"\"\"\n",
    "        # Parameters\n",
    "\n",
    "        lines: the chat as a list of turns, each being a list of token\n",
    "        TODO: add metadata to instances\n",
    "        metadata : List[Dict[str, Any]], optional (default = None)\n",
    "            A dictionary of metadata for each batch element which has keys:\n",
    "                tokens : `List[str]`, required.\n",
    "                    The original string tokens in the sentence.\n",
    "        arcs : a tensor containing the adjacency matrix for the instance dependencies between turns\n",
    "            Has shape `(batch_size, sequence_length, sequence_length)`.\n",
    "\n",
    "        # Returns\n",
    "\n",
    "        An output dictionary.\n",
    "        \"\"\"\n",
    "        #########\n",
    "        # this is the part where chat is encoded as sequence of turn encodings\n",
    "        #########\n",
    "        # mask for each turn of each chat of the batch: shape = (batch_size x max_turns x tokens)\n",
    "        token_mask = get_text_field_mask(lines,num_wrapping_dims=1)\n",
    "\n",
    "        # chat turns fetching embedding\n",
    "        # turns_embedding tensor is (batch_size x turns x max tokens x token embedding size)\n",
    "        turns_embeddings = self.text_field_embedder(lines,num_wrapping_dims=1)\n",
    "      \n",
    "        # encoding turns\n",
    "        # turn_h has shape (batch_size x turns x encoder_output_size) \n",
    "        turn_h = self.turn_encoder(turns_embeddings,token_mask)\n",
    "        \n",
    "        # mask for chats is now nb of turns; beware weird return type of torch.max (tuple) \n",
    "        chat_mask = token_mask.max(axis=2)[0]\n",
    "        \n",
    "        # renaming to mask -> easier to transpose the rest of graph_parser\n",
    "        mask = chat_mask\n",
    "        \n",
    "        # graph parser goes on\n",
    "        # leave input dropout for now\n",
    "        # embedded_text_input = turn_h equivalent in hierarchical sequence -> renaming \n",
    "        #embedded_text_input = self._input_dropout(embedded_text_input)\n",
    "        embedded_text_input = turn_h\n",
    "        # we keep graph parser original name for now\n",
    "        # encoded_text = encoded chat = self.chat_encoder(turn_h,chat_mask) equivalent in hierarchical sequence\n",
    "        encoded_text = self.chat_encoder(embedded_text_input, mask)\n",
    "\n",
    "        encoded_text = self._dropout(encoded_text)\n",
    "\n",
    "        # shape (batch_size, sequence_length, arc_representation_dim)\n",
    "        head_arc_representation = self._dropout(self.head_arc_feedforward(encoded_text))\n",
    "        child_arc_representation = self._dropout(self.child_arc_feedforward(encoded_text))\n",
    "\n",
    "        # shape (batch_size, sequence_length, tag_representation_dim)\n",
    "        #head_tag_representation = self._dropout(self.head_tag_feedforward(encoded_text))\n",
    "        #child_tag_representation = self._dropout(self.child_tag_feedforward(encoded_text))\n",
    "        \n",
    "        # shape (batch_size, sequence_length, sequence_length)\n",
    "        arc_scores = self.arc_attention(head_arc_representation, child_arc_representation)\n",
    "        \n",
    "        # shape (batch_size, num_tags, sequence_length, sequence_length)\n",
    "        #arc_tag_logits = self.tag_bilinear(head_tag_representation, child_tag_representation)\n",
    "        # Switch to (batch_size, sequence_length, sequence_length, num_tags)\n",
    "        #arc_tag_logits = arc_tag_logits.permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "        # Since we'll be doing some additions, using the min value will cause underflow\n",
    "        # CHAT: unncessary since we dont have a loss for labels\n",
    "        #minus_mask = ~mask * min_value_of_dtype(arc_scores.dtype) / 10\n",
    "        #arc_scores = arc_scores + minus_mask.unsqueeze(2) + minus_mask.unsqueeze(1)\n",
    "\n",
    "        \n",
    "        #breakpoint()\n",
    "        arc_probs = self._greedy_decode(arc_scores, mask)\n",
    "\n",
    "        output_dict = {\"arc_probs\": arc_probs, \"mask\": mask}\n",
    "\n",
    "        if metadata:\n",
    "            output_dict[\"tokens\"] = [meta[\"tokens\"] for meta in metadata]\n",
    "\n",
    "        arc_tags = arcs # gold labels -> here just the adjacency matrix 0/1 ? \n",
    "        if arc_tags is not None:\n",
    "            arc_nll= self._construct_loss(\n",
    "                arc_scores=arc_scores, arc_tags=arc_tags, mask=mask\n",
    "            )\n",
    "            # same here with no arc relations ; keep all anyway to prevent ubgs downstream (TODO: coherent renaming)\n",
    "            output_dict[\"loss\"] = arc_nll \n",
    "            output_dict[\"arc_loss\"] = arc_nll\n",
    "        \n",
    "\n",
    "            # Make the arc tags not have negative values anywhere\n",
    "            # (by default, no edge is indicated with -1).\n",
    "            # NB re chat: probably not useful, but kept as a precaution\n",
    "            arc_indices = (arc_tags != -1).float()\n",
    "            tag_mask = mask.unsqueeze(1) & mask.unsqueeze(2)\n",
    "            one_minus_arc_probs = 1 - arc_probs\n",
    "            # We stack scores here because the f1 measure expects a\n",
    "            # distribution, rather than a single value.\n",
    "            self._unlabelled_f1(\n",
    "                torch.stack([one_minus_arc_probs, arc_probs], -1), arc_indices, tag_mask\n",
    "            )\n",
    "        self.iter_count += 1\n",
    "        if False and self.get_metrics()[\"f1\"]>=0.6:\n",
    "            breakpoint()\n",
    "        return output_dict\n",
    "    # modified / untested\n",
    "    \n",
    "    def _construct_loss(\n",
    "        self,\n",
    "        arc_scores: torch.Tensor,\n",
    "        arc_tags: torch.Tensor,\n",
    "        mask: torch.BoolTensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Computes the arc and tag loss for an adjacency matrix.\n",
    "\n",
    "        # Parameters\n",
    "\n",
    "        arc_scores : `torch.Tensor`, required.\n",
    "            A tensor of shape (batch_size, sequence_length, sequence_length) used to generate a\n",
    "            binary classification decision for whether an edge is present between two words.\n",
    "        #####arc_tag_logits : `torch.Tensor`, required.\n",
    "        #####    A tensor of shape (batch_size, sequence_length, sequence_length, num_tags) used to generate\n",
    "        #####    a distribution over edge tags for a given edge.\n",
    "        arc_tags : `torch.Tensor`, required.\n",
    "            A tensor of shape (batch_size, sequence_length, sequence_length).\n",
    "            The labels for every arc.\n",
    "        mask : `torch.BoolTensor`, required.\n",
    "            A mask of shape (batch_size, sequence_length), denoting unpadded\n",
    "            elements in the sequence.\n",
    "\n",
    "        # Returns\n",
    "\n",
    "        arc_nll : `torch.Tensor`, required.\n",
    "            The negative log likelihood from the arc loss.\n",
    "        tag_nll : `torch.Tensor`, required.\n",
    "            The negative log likelihood from the arc tag loss.\n",
    "        \"\"\"\n",
    "        arc_indices = (arc_tags != -1).float()\n",
    "        # Make the arc tags not have negative values anywhere\n",
    "        # (by default, no edge is indicated with -1).\n",
    "        arc_tags = arc_tags * arc_indices\n",
    "        arc_nll = self._arc_loss(arc_scores, arc_indices) * mask.unsqueeze(1) * mask.unsqueeze(2)\n",
    "        # We want the mask for the tags to only include the unmasked words\n",
    "        # and we only care about the loss with respect to the gold arcs.\n",
    "        tag_mask = mask.unsqueeze(1) * mask.unsqueeze(2) * arc_indices\n",
    "\n",
    "        #batch_size, sequence_length, _, num_tags = arc_tag_logits.size()\n",
    "        #original_shape = [batch_size, sequence_length, sequence_length]\n",
    "        #reshaped_logits = arc_tag_logits.view(-1, num_tags)\n",
    "        reshaped_tags = arc_tags.view(-1)\n",
    "        #tag_nll = (\n",
    "        #    self._tag_loss(reshaped_logits, reshaped_tags.long()).view(original_shape) * tag_mask\n",
    "        #)\n",
    "\n",
    "        valid_positions = tag_mask.sum()\n",
    "\n",
    "        arc_nll = arc_nll.sum() / valid_positions.float()\n",
    "        #tag_nll = tag_nll.sum() / valid_positions.float()\n",
    "        return arc_nll#, tag_nll\n",
    "    # modified/untested\n",
    "\n",
    "    @staticmethod\n",
    "    def _greedy_decode(\n",
    "        arc_scores: torch.Tensor, mask: torch.BoolTensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Decodes the head and head tag predictions by decoding the unlabeled arcs\n",
    "        independently for each word and then again, predicting the head tags of\n",
    "        these greedily chosen arcs independently.\n",
    "\n",
    "        # Parameters\n",
    "\n",
    "        arc_scores : `torch.Tensor`, required.\n",
    "            A tensor of shape (batch_size, sequence_length, sequence_length) used to generate\n",
    "            a distribution over attachments of a given word to all other words.\n",
    "        ###arc_tag_logits : `torch.Tensor`, required.\n",
    "        ###    A tensor of shape (batch_size, sequence_length, sequence_length, num_tags) used to\n",
    "        ###    generate a distribution over tags for each arc.\n",
    "        mask : `torch.BoolTensor`, required.\n",
    "            A mask of shape (batch_size, sequence_length).\n",
    "\n",
    "        # Returns\n",
    "\n",
    "        arc_probs : `torch.Tensor`\n",
    "            A tensor of shape (batch_size, sequence_length, sequence_length) representing the\n",
    "            probability of an arc being present for this edge.\n",
    "        ####arc_tag_probs : `torch.Tensor`\n",
    "        ####    A tensor of shape (batch_size, sequence_length, sequence_length, sequence_length)\n",
    "        ####    representing the distribution over edge tags for a given edge.\n",
    "        \"\"\"\n",
    "        # Mask the diagonal, because we don't self edges.\n",
    "        # WARNING: might not be the case for chats ? \n",
    "        inf_diagonal_mask = torch.diag(arc_scores.new(mask.size(1)).fill_(-numpy.inf))\n",
    "        arc_scores = arc_scores + inf_diagonal_mask\n",
    "        # shape (batch_size, sequence_length, sequence_length, num_tags)\n",
    "        #arc_tag_logits = arc_tag_logits + inf_diagonal_mask.unsqueeze(0).unsqueeze(-1)\n",
    "        # Mask padded tokens, because we only want to consider actual word -> word edges.\n",
    "        # CHAT: this is the wrong torch version lol this does not work/ confusion int/bools\n",
    "        # minus_mask = ~mask.unsqueeze(2)\n",
    "        # CHAT: this should work with torch>1.4\n",
    "        #minus_mask = (mask<1).unsqueeze(2)\n",
    "        minus_mask = (mask.unsqueeze(1) & mask.unsqueeze(2))<1\n",
    "        \n",
    "        arc_scores.masked_fill_(minus_mask, -numpy.inf)\n",
    "        # but shouldn'it mask both padded lines/columns ? just does lines\n",
    "        \n",
    "        #arc_tag_logits.masked_fill_(minus_mask.unsqueeze(-1), -numpy.inf)\n",
    "        # shape (batch_size, sequence_length, sequence_length)\n",
    "        arc_probs = arc_scores.sigmoid()\n",
    "        # shape (batch_size, sequence_length, sequence_length, num_tags)\n",
    "        #arc_tag_probs = torch.nn.functional.softmax(arc_tag_logits, dim=-1)\n",
    "        return arc_probs#, arc_tag_probs\n",
    "    # modified / untested\n",
    "    \n",
    "    @overrides\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        metrics = {}\n",
    "        precision, recall, f1_measure = self._unlabelled_f1.get_metric(reset)\n",
    "        metrics[\"precision\"] = precision\n",
    "        metrics[\"recall\"] = recall\n",
    "        metrics[\"f1\"] = f1_measure\n",
    "        return metrics\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = HierarchicalChatSequenceClassification(vocab,word_embeddings,turn_encoder,chat_encoder)\n",
    "\n",
    "if False:\n",
    "    reader = ChatReader(\n",
    "        tokenizer=tokenizer,\n",
    "        token_indexers=token_indexers,\n",
    "        raw = False,\n",
    "        #sample = 50, \n",
    "        #clip = 30\n",
    "        )\n",
    "    train_instances = reader.read(\"../data/train\")\n",
    "    vocab = Vocabulary.from_instances(train_instances)\n",
    "\n",
    "\n",
    "arc_representation_dim = 50 \n",
    "model = ChatGraphParser(vocab,word_embeddings,\n",
    "                        turn_encoder,chat_encoder,arc_representation_dim,\n",
    "                       edge_prediction_threshold=0.5)\n",
    "\n",
    "\n",
    "from allennlp.training.optimizers import Optimizer \n",
    "trainer_cfg = {\n",
    "        \"cuda_device\": -1,\n",
    "        \"grad_norm\": 5,\n",
    "        \"num_epochs\": 100,\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"dense_sparse_adam\",\n",
    "            \"betas\": [\n",
    "                0.9,\n",
    "                0.9\n",
    "            ]\n",
    "        },\n",
    "        \"patience\": 50,\n",
    "}\n",
    "opt_cfg = trainer_cfg.pop(\"optimizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "#does not work cos needs model parameters too\n",
    "#optimizer = Optimizer.from_params(opt_cfg)\n",
    "\n",
    "iterator = BucketIterator(batch_size=8,sorting_keys=[(\"lines\",\"list_num_tokens\")])\n",
    "iterator.index_with(vocab)\n",
    "trainer = Trainer(model=model,\n",
    "                  optimizer=optimizer,\n",
    "                  iterator=iterator,\n",
    "                  num_epochs=100,\n",
    "                  grad_norm=5,\n",
    "                  patience=10,\n",
    "                  train_dataset=train_instances,\n",
    "                  should_log_parameter_statistics = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision: 0.0000, recall: 0.0000, f1: 0.0000, loss: 42.8510 ||: 100%|██████████| 20/20 [02:08<00:00,  6.40s/it]\n",
      "precision: 0.0000, recall: 0.0000, f1: 0.0000, loss: 9.4994 ||:  20%|██        | 4/20 [00:19<01:17,  4.84s/it]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor([[1, 1, 1, 0],\n",
    "        [1, 1, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = numpy.inf \n",
    "arc_scores = torch.tensor([[[  -inf, 0.1252, 0.1161, 0.0475],\n",
    "         [0.0977,   -inf, 0.1015, 0.0373],\n",
    "         [0.1541, 0.1673,   -inf, 0.0934],\n",
    "         [0.0563, 0.0730, 0.0623,   -inf]],\n",
    "\n",
    "        [[  -inf, 0.0947, 0.1048, 0.1114],\n",
    "         [0.1385,   -inf, 0.1681, 0.1755],\n",
    "         [0.1114, 0.1310,   -inf, 0.1448],\n",
    "         [0.1274, 0.1454, 0.1537,   -inf]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_mask = (mask<1).unsqueeze(2)    \n",
    "arc_scores.masked_fill_(minus_mask, -numpy.inf)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_probs = arc_scores.sigmoid()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_mask = (mask.unsqueeze(1) & mask.unsqueeze(2))<1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_scores.masked_fill_(minus_mask, -numpy.inf)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mask<1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
